From e10db85309b560a89f14362448e3342e006410bd Mon Sep 17 00:00:00 2001
From: Phantom X <PhantomX@users.noreply.github.com>
Date: Mon, 8 Mar 2021 18:05:01 -0300
Subject: [PATCH] Revert Merge branch fh/x64-arm-jit

This reverts commits:
4d5c6e1551da4c968b9528c0752a8ce092188b77
3c8a2f23721530973cce2c9c1de65379e8eec98a
af650c7c31151dc0de4b23701e5573ae2b757750
641da3a771862f1352b66b599d0a961e84e6d178
424736961bdc279c67f005125033582ff7a17656
c99b34e60c3b7f4464f9a3d9fd53e018b39804a0
0c8815549c3ad0eccc619dd73aebbe973ac111a6
---
 CMakeLists.txt                                |   17 +-
 core/arm_emitter/E_DataOp.h                   |  658 +------
 core/build.h                                  |    2 +-
 core/hw/aica/aica.cpp                         |   35 +-
 core/hw/aica/aica_if.cpp                      |   26 +-
 core/hw/aica/aica_if.h                        |    1 -
 core/hw/aica/aica_mem.cpp                     |    2 +-
 core/hw/aica/aica_mem.h                       |    2 +-
 core/hw/aica/dsp_arm64.cpp                    |    2 +-
 core/hw/arm7/arm64.cpp                        |  525 ++++++
 core/hw/arm7/arm7.cpp                         | 1528 ++++++++++++++++-
 core/hw/arm7/arm7.h                           |   25 +-
 core/hw/arm7/arm7_rec.cpp                     |  737 --------
 core/hw/arm7/arm7_rec.h                       |  456 -----
 core/hw/arm7/arm7_rec_arm32.cpp               |  557 ------
 core/hw/arm7/arm7_rec_arm64.cpp               |  717 --------
 core/hw/arm7/arm7_rec_x64.cpp                 |  969 -----------
 core/hw/arm7/vbaARM.cpp                       |    6 +-
 core/hw/arm7/virt_arm.cpp                     |  213 +++
 core/hw/arm7/virt_arm.h                       |    7 +
 core/hw/holly/sb.h                            |    2 +-
 core/hw/mem/vmem32.cpp                        |   23 +-
 core/hw/mem/vmem32.h                          |    2 +-
 core/hw/sh4/dyna/blockmanager.cpp             |    4 +-
 core/hw/sh4/dyna/blockmanager.h               |    7 +-
 core/hw/sh4/dyna/decoder.cpp                  |  118 +-
 core/hw/sh4/dyna/decoder.h                    |    8 +-
 core/hw/sh4/dyna/driver.cpp                   |    5 +-
 core/hw/sh4/dyna/ngen.h                       |    4 +-
 core/hw/sh4/dyna/ssa.cpp                      |    2 +-
 core/hw/sh4/dyna/ssa.h                        |   45 -
 core/hw/sh4/interpr/sh4_opcodes.cpp           |   19 +-
 core/hw/sh4/modules/fastmmu.cpp               |    1 +
 core/hw/sh4/modules/wince.h                   |   11 +-
 core/hw/sh4/sh4_if.h                          |    2 +-
 core/linux/common.cpp                         |   91 +-
 core/linux/context.cpp                        |   99 +-
 .../{oslib/host_context.h => linux/context.h} |   18 +-
 core/linux/posix_vmem.cpp                     |  134 +-
 core/nullDC.cpp                               |    5 +-
 core/rec-ARM/ngen_arm.S                       |   60 +
 core/rec-ARM/rec_arm.cpp                      |  151 +-
 core/rec-ARM64/arm64_regalloc.h               |    2 +-
 core/rec-ARM64/rec_arm64.cpp                  |  268 +--
 core/rec-cpp/rec_cpp.cpp                      |    2 +-
 core/rec-x64/msvc.asm                         |   77 +
 core/rec-x64/rec_x64.cpp                      |  945 +++++-----
 core/rec-x86/rec_x86.cpp                      |    7 +-
 core/rec-x86/rec_x86.h                        |    2 +-
 core/rec-x86/x86_ops.cpp                      |   19 +-
 core/serialize.cpp                            |   15 +-
 core/types.h                                  |    3 +-
 core/windows/winmain.cpp                      |   86 +-
 .../reicast-osx.xcodeproj/project.pbxproj     |   18 +-
 shell/linux/Makefile                          |   46 +-
 tests/src/AicaArmTest.cpp                     | 1078 ------------
 tests/src/serialize_test.cpp                  |    2 +-
 tests/src/test_stubs.cpp                      |    2 -
 58 files changed, 3528 insertions(+), 6340 deletions(-)
 create mode 100644 core/hw/arm7/arm64.cpp
 delete mode 100644 core/hw/arm7/arm7_rec.cpp
 delete mode 100644 core/hw/arm7/arm7_rec.h
 delete mode 100644 core/hw/arm7/arm7_rec_arm32.cpp
 delete mode 100644 core/hw/arm7/arm7_rec_arm64.cpp
 delete mode 100644 core/hw/arm7/arm7_rec_x64.cpp
 create mode 100644 core/hw/arm7/virt_arm.cpp
 create mode 100644 core/hw/arm7/virt_arm.h
 rename core/{oslib/host_context.h => linux/context.h} (51%)
 create mode 100644 core/rec-x64/msvc.asm
 delete mode 100644 tests/src/AicaArmTest.cpp

diff --git a/CMakeLists.txt b/CMakeLists.txt
index 5a58c12..9a08784 100644
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -473,17 +473,15 @@ target_sources(${PROJECT_NAME} PRIVATE
         core/hw/aica/dsp_x86.cpp
         core/hw/aica/sgc_if.cpp
         core/hw/aica/sgc_if.h
+        core/hw/arm7/arm64.cpp
         core/hw/arm7/arm7.cpp
         core/hw/arm7/arm7.h
         core/hw/arm7/arm_mem.cpp
         core/hw/arm7/arm_mem.h
-        core/hw/arm7/arm7_rec_arm32.cpp
-        core/hw/arm7/arm7_rec_arm64.cpp
-        core/hw/arm7/arm7_rec_x64.cpp
-        core/hw/arm7/arm7_rec.cpp
-        core/hw/arm7/arm7_rec.h
         core/hw/arm7/arm-new.h
         core/hw/arm7/vbaARM.cpp
+        core/hw/arm7/virt_arm.cpp
+        core/hw/arm7/virt_arm.h
         core/hw/bba/bba.h
         core/hw/bba/bba.cpp
         core/hw/bba/rtl8139c.h
@@ -641,6 +639,7 @@ target_sources(${PROJECT_NAME} PRIVATE
 if(NOT WIN32)
     target_sources(${PROJECT_NAME} PRIVATE
             core/linux/context.cpp
+            core/linux/context.h
             core/linux/posix_vmem.cpp)
 endif()
 
@@ -694,8 +693,6 @@ target_sources(${PROJECT_NAME} PRIVATE
         core/oslib/audiobackend_sdl2.cpp
         core/oslib/audiostream.cpp
         core/oslib/audiostream.h
-        core/oslib/directory.h
-        core/oslib/host_context.h
         core/oslib/oslib.h)
 
 target_sources(${PROJECT_NAME} PRIVATE
@@ -896,6 +893,9 @@ elseif(CMAKE_SYSTEM_PROCESSOR MATCHES "i686.*|i386.*|x86.*|amd64.*|x86_64.*|AMD6
         	core/rec-x64/xbyak_base.h
         	core/rec-x64/rec_x64.cpp
         	core/rec-x64/x64_regalloc.h)
+        if(MSVC)
+            target_sources(${PROJECT_NAME} PRIVATE core/rec-x64/msvc.asm)
+        endif()
     endif()
 else()
     message(FATAL_ERROR "Unknown target processor: ${CMAKE_SYSTEM_PROCESSOR}")
@@ -971,6 +971,5 @@ if(BUILD_TESTING)
     target_sources(${PROJECT_NAME} PRIVATE
             tests/src/div32_test.cpp
             tests/src/test_stubs.cpp
-            tests/src/serialize_test.cpp
-            tests/src/AicaArmTest.cpp)
+            tests/src/serialize_test.cpp)
 endif()
diff --git a/core/arm_emitter/E_DataOp.h b/core/arm_emitter/E_DataOp.h
index e0e8a36..046327a 100755
--- a/core/arm_emitter/E_DataOp.h
+++ b/core/arm_emitter/E_DataOp.h
@@ -227,46 +227,6 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-        EAPI ADD(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x02800000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI ADD(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00800000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI ADD(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00800010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
 		EAPI ADC(eReg Rd, eReg Rn, eReg Rm, bool S, ConditionCode CC=AL)
         {
             DECL_Id(0x00A00000);
@@ -281,6 +241,11 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
+		EAPI ADC(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
+        {
+            ADC(Rd,Rn,Rm,false,CC);
+        }
+
 		EAPI ADC(eReg Rd, eReg Rn, s32 Imm8, ConditionCode CC=AL)
         {
             DECL_Id(0x02A00000);
@@ -292,45 +257,23 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-		EAPI ADC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00A00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI ADC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00A00010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-        EAPI ADC(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x02A00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
+		EAPI ADC(eReg Rd, eReg Rn, eReg Rm, bool S, ShiftOp Shift, u32 Imm8, ConditionCode CC=AL)
+		{
+			DECL_Id(0x00A00000);
+			
+			if (S)
+			I |= 1<<20;
+			
+			SET_CC;
+			I |= (Rn&15)<<16;
+			I |= (Rd&15)<<12;
+			I |= (Rm&15);
+			I |= Shift<<5;
+			I |= (Imm8&31)<<7;
+			EMIT_I;
+		}
+		
+	
 
         EAPI ADR(eReg Rd, s32 Imm8, ConditionCode CC=AL)
         {
@@ -352,6 +295,7 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
+
         EAPI ORR(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
         {
             DECL_Id(0x01800000);
@@ -374,26 +318,11 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 		
-		EAPI ORR(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x01800000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-		EAPI ORR(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rs, bool S, ConditionCode CC=AL)
+		EAPI ORR(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rs, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01800000);
 			
 			SET_CC;
-            I |= S << 20;
 			I |= (Rn&15)<<16;
 			I |= (Rd&15)<<12;
 			I |= (Rm&15);
@@ -403,18 +332,6 @@ ADD.SP.REG	0x008D0000
 			EMIT_I;
 		}
 	
-        EAPI ORR(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03800000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
 		EAPI ORR(eReg Rd, eReg Rn, eReg Rm, bool S, ShiftOp Shift, u32 Imm8, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01800000);
@@ -430,7 +347,7 @@ ADD.SP.REG	0x008D0000
 			I |= (Imm8&31)<<7;
 			EMIT_I;
 		}
-
+		
 		EAPI AND(eReg Rd, eReg Rn, eReg Rm, bool S, ConditionCode CC=AL)
         {
             DECL_Id(0x00000000);
@@ -481,35 +398,6 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-		EAPI AND(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00000000);
-
-			if (S)
-				I |= 1<<20;
-
-            SET_CC;
-            I |= (Rn&15)<<16;
-            I |= (Rd&15)<<12;
-            I |= (Rm&15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI AND(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00000010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
 
         EAPI EOR(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
         {
@@ -547,47 +435,6 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-        EAPI EOR(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x02200000);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn&15)<<16;
-            I |= (Rd&15)<<12;
-            I |= ARMImmid8r4(Imm8);  // * 12b imm is 8b imm 4b rot. spec, add rot support!
-            EMIT_I;
-        }
-
-		EAPI EOR(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00200000);
-
-			if (S)
-				I |= 1<<20;
-
-            SET_CC;
-            I |= (Rn&15)<<16;
-            I |= (Rd&15)<<12;
-            I |= (Rm&15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI EOR(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00200010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
 
 
         EAPI SUB(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
@@ -615,42 +462,12 @@ ADD.SP.REG	0x008D0000
         }
 		EAPI SUB(eReg Rd, eReg Rn, s32 Imm8, ConditionCode CC=AL) { SUB(Rd,Rn,Imm8,false,CC); }
 
-		EAPI SUB(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00400000);
-
-			if (S)
-				I |= 1<<20;
-
-            SET_CC;
-            I |= (Rn&15)<<16;
-            I |= (Rd&15)<<12;
-            I |= (Rm&15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI SUB(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00400010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
 		EAPI SBC(eReg Rd, eReg Rn, eReg Rm, bool S, ConditionCode CC=AL)
 		{
 			DECL_Id(0x00C00000);
 			
 			if (S)
-				I |= 1<<20;
+			I |= 1<<20;
 			
 			SET_CC;
 			I |= (Rn&15)<<16;
@@ -663,47 +480,7 @@ ADD.SP.REG	0x008D0000
 		{
 			SBC(Rd,Rn,Rm,false,CC);
 		}
-
-        EAPI SBC(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x02C00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI SBC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00C00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-		EAPI SBC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00C00010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
+	
         EAPI RSB(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
         {
             DECL_Id(0x00600000);
@@ -732,7 +509,7 @@ ADD.SP.REG	0x008D0000
             DECL_Id(0x02600000);
 
 			if (S)
-				I |= 1<<20;
+			I |= 1<<20;
 			
             SET_CC;
             I |= (Rn&15)<<16;
@@ -741,75 +518,6 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-		EAPI RSB(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00600000);
-
-			if (S)
-				I |= 1<<20;
-
-            SET_CC;
-            I |= (Rn&15)<<16;
-            I |= (Rd&15)<<12;
-            I |= (Rm&15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI RSB(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00600010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-        EAPI RSC(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x02E00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI RSC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x00E00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-		EAPI RSC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x00E00010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
 
         EAPI MVN(eReg Rd, eReg Rm, ConditionCode CC=AL)
         {
@@ -832,42 +540,6 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-        EAPI MVN(eReg Rd, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03E00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI MVN(eReg Rd, eReg Rm, ShiftOp Shift, u32 Imm8, bool S, ConditionCode CC=AL)
-		{
-			DECL_Id(0x01E00000);
-
-			SET_CC;
-            I |= S << 20;
-			I |= (Rd&15)<<12;
-			I |= (Rm&15);
-			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
-			EMIT_I;
-		}
-
-        EAPI MVN(eReg Rd, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01E00010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
 
         EAPI TST(eReg Rn, eReg Rm, ConditionCode CC=AL)
         {
@@ -890,81 +562,7 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-        EAPI TST(eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03100000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI TST(eReg Rn, eReg Rm, ShiftOp Shift, u32 Imm8, bool S, ConditionCode CC=AL)
-		{
-			DECL_Id(0x01100000);
-
-			SET_CC;
-            I |= S << 20;
-			I |= (Rn&15)<<16;
-			I |= (Rm&15);
-			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
-			EMIT_I;
-		}
-
-        EAPI TST(eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01100010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-        EAPI TEQ(eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03300000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI TEQ(eReg Rn, eReg Rm, ShiftOp Shift, u32 Imm8, bool S, ConditionCode CC=AL)
-		{
-			DECL_Id(0x01300000);
-
-			SET_CC;
-            I |= S << 20;
-			I |= (Rn&15)<<16;
-			I |= (Rm&15);
-			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
-			EMIT_I;
-		}
-
-        EAPI TEQ(eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01300010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-        EAPI BIC(eReg Rd, eReg Rn, s32 Imm8, ConditionCode CC=AL)
+		EAPI BIC(eReg Rd, eReg Rn, s32 Imm8, ConditionCode CC=AL)
         {
             DECL_Id(0x03C00000);
 
@@ -975,69 +573,6 @@ ADD.SP.REG	0x008D0000
             EMIT_I;
         }
 
-        EAPI BIC(eReg Rd, eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03C00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI BIC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x01C00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-			I |= Shift << 5;
-			I |= (ImmShift & 31) << 7;
-            EMIT_I;
-        }
-
-        EAPI BIC(eReg Rd, eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01C00010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-		EAPI BFC(eReg Rd, u8 lsb, u8 width, ConditionCode CC=AL)
-        {
-            DECL_Id(0x07C0001F);
-
-            SET_CC;
-            I |= (Rd & 15) << 12;
-			I |= (lsb & 31) << 7;
-		    I |= ((lsb + width - 1) & 31) << 16;
-            EMIT_I;
-        }
-
-		EAPI BFI(eReg Rd, eReg Rn, u8 lsb, u8 width, ConditionCode CC=AL)
-        {
-            DECL_Id(0x07C00010);
-
-            SET_CC;
-            I |= Rn & 15;
-            I |= (Rd & 15) << 12;
-			I |= (lsb & 31) << 7;
-		    I |= ((lsb + width - 1) & 31) << 16;
-            EMIT_I;
-        }
-
 
 		/*
 		 *
@@ -1079,19 +614,20 @@ ADD.SP.REG	0x008D0000
 			EMIT_I;
 		}
 
-		EAPI MOV(eReg Rd, eReg Rm, ShiftOp Shift, u32 Imm8, ConditionCode CC=AL)
+		EAPI MOV(eReg Rd, eReg Rm, bool S, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01A00000);
 			
+			if (S)
+				I |= 1<<20;
+			
 			SET_CC;
 			I |= (Rd&15)<<12;
 			I |= (Rm&15);
-			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
 			EMIT_I;
 		}
 		
-		EAPI MOV(eReg Rd, eReg Rm, ShiftOp Shift, eReg Rs, ConditionCode CC=AL)
+		EAPI MOV(eReg Rd, eReg Rm, ShiftOp Shift, u32 Imm8, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01A00000);
 			
@@ -1099,37 +635,23 @@ ADD.SP.REG	0x008D0000
 			I |= (Rd&15)<<12;
 			I |= (Rm&15);
 			I |= Shift<<5;
-			I |= (Rs&15)<<8;
-			I |= 1<<4;
+			I |= (Imm8&31)<<7;
 			EMIT_I;
 		}
-	
-		EAPI MOV(eReg Rd, eReg Rm, ShiftOp Shift, u32 Imm8, bool S, ConditionCode CC=AL)
+		
+		EAPI MOV(eReg Rd, eReg Rm, ShiftOp Shift, eReg Rs, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01A00000);
-
+			
 			SET_CC;
-            I |= S << 20;
 			I |= (Rd&15)<<12;
 			I |= (Rm&15);
 			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
+			I |= (Rs&15)<<8;
+			I |= 1<<4;
 			EMIT_I;
 		}
-
-        EAPI MOV(eReg Rd, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01A00010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rd & 15) << 12;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
+	
 		EAPI MOVW(eReg Rd, u32 Imm16, ConditionCode CC=AL)
 		{
 			DECL_Id(0x03000000);
@@ -1161,17 +683,9 @@ ADD.SP.REG	0x008D0000
 			I |= ARMImmid8r4(Imm8);  // * 12b imm is 8b imm 4b rot. spec, add rot support!
 			EMIT_I;
 		}
+		
+	
 
-        EAPI MOV(eReg Rd, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03A00000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rd & 15) << 12;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
 
 
 		EAPI CMP(eReg Rn, eReg Rm, ConditionCode CC=AL)
@@ -1195,23 +709,12 @@ ADD.SP.REG	0x008D0000
 			EMIT_I;
 		}
 
-        EAPI CMP(eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03500000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI CMP(eReg Rn, eReg Rm, ShiftOp Shift, eReg Rs, ConditionCode CC=AL)
+		EAPI CMP(eReg Rd, eReg Rm, ShiftOp Shift, eReg Rs, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01500000);
 			
 			SET_CC;
-			I |= (Rn&15)<<16;
+			I |= (Rd&15)<<12;
 			I |= (Rm&15);
 			I |= Shift<<5;
 			I |= (Rs&15)<<8;
@@ -1219,82 +722,19 @@ ADD.SP.REG	0x008D0000
 			EMIT_I;
 		}
 		
-		EAPI CMP(eReg Rn, eReg Rm, ShiftOp Shift, u32 Imm8, ConditionCode CC=AL)
+		EAPI CMP(eReg Rd, eReg Rm, ShiftOp Shift, u32 Imm8, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01500000);
 			
 			SET_CC;
-			I |= (Rn&15)<<16;
-			I |= (Rm&15);
-			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
-			EMIT_I;
-		}
-
-		EAPI CMP(eReg Rn, eReg Rm, ShiftOp Shift, u32 Imm8, bool S, ConditionCode CC=AL)
-		{
-			DECL_Id(0x01500000);
-
-			SET_CC;
-            I |= S << 20;
-			I |= (Rn&15)<<16;
-			I |= (Rm&15);
-			I |= Shift<<5;
-			I |= (Imm8&31)<<7;
-			EMIT_I;
-		}
-
-        EAPI CMP(eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01500010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-        EAPI CMN(eReg Rn, s32 Imm8, bool S, ConditionCode CC=AL)
-        {
-            DECL_Id(0x03600000);
-
-            SET_CC;
-			I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= ARMImmid8r4(Imm8);
-            EMIT_I;
-        }
-
-		EAPI CMN(eReg Rn, eReg Rm, ShiftOp Shift, u32 Imm8, bool S, ConditionCode CC=AL)
-		{
-			DECL_Id(0x01600000);
-
-			SET_CC;
-            I |= S << 20;
-			I |= (Rn&15)<<16;
+			I |= (Rd&15)<<12;
 			I |= (Rm&15);
 			I |= Shift<<5;
 			I |= (Imm8&31)<<7;
 			EMIT_I;
 		}
-
-        EAPI CMN(eReg Rn, eReg Rm, ShiftOp Shift, eReg Rshift, bool S, ConditionCode CC=AL)
-        {
-        	DECL_Id(0x01600010);
-
-            SET_CC;
-            I |= S << 20;
-            I |= (Rn & 15) << 16;
-            I |= (Rm & 15);
-            I |= (Rshift & 15) << 8;
-			I |= Shift << 5;
-            EMIT_I;
-        }
-
-        EAPI LSL(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
+		
+		EAPI LSL(eReg Rd, eReg Rn, eReg Rm, ConditionCode CC=AL)
 		{
 			DECL_Id(0x01A00010);
 
diff --git a/core/build.h b/core/build.h
index ab5cde6..dcfd613 100755
--- a/core/build.h
+++ b/core/build.h
@@ -213,7 +213,7 @@
 #endif
 
 #ifndef FEAT_AREC
-	#if HOST_CPU == CPU_ARM || HOST_CPU == CPU_ARM64 || HOST_CPU == CPU_X64
+	#if HOST_CPU == CPU_ARM || HOST_CPU == CPU_ARM64
 		#define FEAT_AREC DYNAREC_JIT
 	#else
 		#define FEAT_AREC DYNAREC_NONE
diff --git a/core/hw/aica/aica.cpp b/core/hw/aica/aica.cpp
index b290148..ac40b7c 100644
--- a/core/hw/aica/aica.cpp
+++ b/core/hw/aica/aica.cpp
@@ -88,7 +88,7 @@ const int AICA_TICK = 145125;	// 44.1 KHz / 32
 
 static int AicaUpdate(int tag, int c, int j)
 {
-	aicaarm::run(32);
+	arm_Run(32);
 	if (!settings.aica.NoBatch)
 		AICA_Sample32();
 
@@ -172,35 +172,40 @@ void WriteAicaReg(u32 reg,u32 data)
 	{
 	case SCIPD_addr:
 		verify(sz!=1);
-		// other bits are read-only
 		if (data & (1<<5))
 		{
 			SCIPD->SCPU=1;
 			update_arm_interrupts();
 		}
-		break;
+		//Read only
+		return;
 
 	case SCIRE_addr:
-		verify(sz != 1);
-		SCIPD->full &= ~data /*& SCIEB->full)*/;	//is the & SCIEB->full needed ? doesn't seem like it
-		update_arm_interrupts();
+		{
+			verify(sz!=1);
+			SCIPD->full&=~(data /*& SCIEB->full*/ );	//is the & SCIEB->full needed ? doesn't seem like it
+			data=0;//Write only
+			update_arm_interrupts();
+		}
 		break;
 
 	case MCIPD_addr:
-		verify(sz != 1);
-		// other bits are read-only
-		if (data & (1 << 5))
+		if (data & (1<<5))
 		{
-			MCIPD->SCPU = 1;
+			verify(sz!=1);
+			MCIPD->SCPU=1;
 			UpdateSh4Ints();
-			aicaarm::avoidRaceCondition();
 		}
-		break;
+		//Read only
+		return;
 
 	case MCIRE_addr:
-		verify(sz != 1);
-		MCIPD->full &= ~data;
-		UpdateSh4Ints();
+		{
+			verify(sz!=1);
+			MCIPD->full&=~data;
+			UpdateSh4Ints();
+			//Write only
+		}
 		break;
 
 	case TIMER_A:
diff --git a/core/hw/aica/aica_if.cpp b/core/hw/aica/aica_if.cpp
index dd3e0d7..7b48ec0 100644
--- a/core/hw/aica/aica_if.cpp
+++ b/core/hw/aica/aica_if.cpp
@@ -23,7 +23,6 @@ u32 rtc_EN;
 int dma_sched_id;
 u32 RealTimeClock;
 int rtc_schid = -1;
-u32 SB_ADST;
 
 u32 GetRTC_now()
 {
@@ -116,7 +115,7 @@ u32 ReadMem_aica_reg(u32 addr,u32 sz)
 static void ArmSetRST()
 {
 	ARMRST &= 1;
-	aicaarm::enable(ARMRST == 0);
+	arm_SetEnabled(ARMRST == 0);
 }
 
 void WriteMem_aica_reg(u32 addr,u32 data,u32 sz)
@@ -331,7 +330,7 @@ static void Write_SB_ADST(u32 addr, u32 data)
 	//0x005F7818	SB_ADST		RW	AICA:G2-DMA start
 	//0x005F781C	SB_ADSUSP	RW	AICA:G2-DMA suspend 
 	
-	if ((data & 1) == 1 && (SB_ADST & 1) == 0)
+	if (data&1)
 	{
 		if (SB_ADEN&1)
 		{
@@ -392,23 +391,6 @@ static void Write_SB_ADST(u32 addr, u32 data)
 	}
 }
 
-u32 Read_SB_ADST(u32 addr)
-{
-	// Le Mans and Looney Tunes sometimes send the same dma transfer twice after checking SB_ADST == 0.
-	// To avoid this, we pretend SB_ADST is still set when there is a pending aica-dma interrupt.
-	// This is only done once.
-	if ((SB_ISTNRM & (1 << (u8)holly_SPU_DMA)) && !(SB_ADST & 2))
-	{
-		SB_ADST |= 2;
-		return 1;
-	}
-	else
-	{
-		SB_ADST &= ~2;
-		return SB_ADST;
-	}
-}
-
 template<u32 STAG, HollyInterruptID iainterrupt, const char *LogTag>
 void Write_SB_STAG(u32 addr, u32 data)
 {
@@ -451,7 +433,7 @@ void aica_sb_Init()
 	// G2-DMA registers
 
 	// AICA
-	sb_rio_register(SB_ADST_addr, RIO_FUNC, &Read_SB_ADST, &Write_SB_ADST);
+	sb_rio_register(SB_ADST_addr, RIO_WF, nullptr, &Write_SB_ADST);
 #ifdef STRICT_MODE
 	sb_rio_register(SB_ADSTAR_addr, RIO_WF, nullptr, &Write_SB_STAR<SB_ADSTAR_addr, holly_AICA_ILLADDR, AICA_TAG>);
 	sb_rio_register(SB_ADSTAG_addr, RIO_WF, nullptr, &Write_SB_STAG<SB_ADSTAG_addr, holly_AICA_ILLADDR, AICA_TAG>);
@@ -482,8 +464,6 @@ void aica_sb_Init()
 
 void aica_sb_Reset(bool hard)
 {
-	if (hard)
-		SB_ADST = 0;
 }
 
 void aica_sb_Term()
diff --git a/core/hw/aica/aica_if.h b/core/hw/aica/aica_if.h
index 98b2676..a58888d 100644
--- a/core/hw/aica/aica_if.h
+++ b/core/hw/aica/aica_if.h
@@ -21,4 +21,3 @@ void aica_sb_Term();
 s32 libAICA_Init();
 void libAICA_Reset(bool hard);
 void libAICA_Term();
-void libAICA_TimeStep();
diff --git a/core/hw/aica/aica_mem.cpp b/core/hw/aica/aica_mem.cpp
index 060fe50..1fc538b 100644
--- a/core/hw/aica/aica_mem.cpp
+++ b/core/hw/aica/aica_mem.cpp
@@ -4,7 +4,7 @@
 #include "dsp.h"
 #include "sgc_if.h"
 
-alignas(4) u8 aica_reg[0x8000];
+u8 aica_reg[0x8000];
 
 //00000000~007FFFFF @DRAM_AREA* 
 //00800000~008027FF @CHANNEL_DATA 
diff --git a/core/hw/aica/aica_mem.h b/core/hw/aica/aica_mem.h
index 4246497..30d88eb 100644
--- a/core/hw/aica/aica_mem.h
+++ b/core/hw/aica/aica_mem.h
@@ -7,5 +7,5 @@ void libAICA_WriteReg(u32 addr,u32 data,u32 size);
 void init_mem();
 void term_mem();
 
-alignas(4) extern u8 aica_reg[0x8000];
+extern u8 aica_reg[0x8000];
 
diff --git a/core/hw/aica/dsp_arm64.cpp b/core/hw/aica/dsp_arm64.cpp
index efef4d2..a7567f6 100644
--- a/core/hw/aica/dsp_arm64.cpp
+++ b/core/hw/aica/dsp_arm64.cpp
@@ -25,7 +25,7 @@
 #include "aica.h"
 #include "aica_if.h"
 #include "hw/mem/_vmem.h"
-#include <aarch64/macro-assembler-aarch64.h>
+#include "deps/vixl/aarch64/macro-assembler-aarch64.h"
 using namespace vixl::aarch64;
 
 static u8 *pCodeBuffer;
diff --git a/core/hw/arm7/arm64.cpp b/core/hw/arm7/arm64.cpp
new file mode 100644
index 0000000..f1058c4
--- /dev/null
+++ b/core/hw/arm7/arm64.cpp
@@ -0,0 +1,525 @@
+/*
+	Copyright 2019 flyinghead
+
+	This file is part of reicast.
+
+    reicast is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 2 of the License, or
+    (at your option) any later version.
+
+    reicast is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with reicast.  If not, see <https://www.gnu.org/licenses/>.
+ */
+
+#include "build.h"
+
+#if	HOST_CPU == CPU_ARM64 && FEAT_AREC != DYNAREC_NONE
+
+#include <sstream>
+#include "arm7.h"
+#include "arm_emitter/arm_coding.h"
+#include "deps/vixl/aarch64/macro-assembler-aarch64.h"
+using namespace vixl::aarch64;
+//#include "deps/vixl/aarch32/disasm-aarch32.h"
+
+extern void vmem_platform_flush_cache(void *icache_start, void *icache_end, void *dcache_start, void *dcache_end);
+extern u32 arm_single_op(u32 opcode);
+extern "C" void arm_dispatch();
+extern "C" void arm_exit();
+
+extern u8* icPtr;
+extern u8* ICache;
+extern const u32 ICacheSize;
+extern reg_pair arm_Reg[RN_ARM_REG_COUNT];
+
+MacroAssembler *assembler;
+
+extern "C" void armFlushICache(void *bgn, void *end) {
+	vmem_platform_flush_cache(bgn, end, bgn, end);
+}
+
+static MemOperand arm_reg_operand(u32 regn)
+{
+	return MemOperand(x28, (u8*)&arm_Reg[regn].I - (u8*)&arm_Reg[0].I);
+}
+
+//helpers ...
+void LoadReg(ARM::eReg rd, u32 regn, ARM::ConditionCode cc = ARM::CC_AL)
+{
+	assembler->Ldr(Register::GetWRegFromCode(rd), arm_reg_operand(regn));
+}
+void StoreReg(ARM::eReg rd, u32 regn, ARM::ConditionCode cc = ARM::CC_AL)
+{
+	assembler->Str(Register::GetWRegFromCode(rd), arm_reg_operand(regn));
+}
+
+void *armv_start_conditional(ARM::ConditionCode cc)
+{
+	if (cc == ARM::CC_AL)
+		return NULL;
+	Label *label = new Label();
+	verify(cc <= ARM::CC_LE);
+	Condition condition = (Condition)((u32)cc ^ 1);
+	assembler->B(label, condition);
+
+	return label;
+}
+
+void armv_end_conditional(void *ref)
+{
+	if (ref != NULL)
+	{
+		Label *label = (Label *)ref;
+		assembler->Bind(label);
+		delete label;
+	}
+}
+
+//For COND
+void LoadFlags()
+{
+	//Load flags
+	LoadReg(ARM::r0, RN_PSR_FLAGS);
+	//move them to flags register
+	assembler->Msr(NZCV, x0);
+}
+
+void StoreFlags()
+{
+	//get results from flags register
+	assembler->Mrs(x1, NZCV);
+	//Store flags
+	StoreReg(ARM::r1, RN_PSR_FLAGS);
+}
+
+void armv_imm_to_reg(u32 regn, u32 imm)
+{
+	assembler->Mov(w0, imm);
+	assembler->Str(w0, arm_reg_operand(regn));
+}
+
+void armv_call(void* loc)
+{
+	ptrdiff_t offset = reinterpret_cast<uintptr_t>(loc) - assembler->GetBuffer()->GetStartAddress<uintptr_t>();
+	Label function_label;
+	assembler->BindToOffset(&function_label, offset);
+	assembler->Bl(&function_label);
+}
+
+void armv_setup()
+{
+	assembler = new MacroAssembler(icPtr, ICache + ICacheSize - icPtr);
+}
+
+void armv_intpr(u32 opcd)
+{
+	//Call interpreter
+	assembler->Mov(w0, opcd);
+	armv_call((void*)&arm_single_op);
+	assembler->Sub(w27, w27, w0);
+}
+
+void armv_end(void* codestart, u32 cycl)
+{
+	//Normal block end
+	//cycle counter rv
+
+	//pop registers & return
+	assembler->Subs(w27, w27, cycl);
+	ptrdiff_t offset = reinterpret_cast<uintptr_t>(arm_exit) - assembler->GetBuffer()->GetStartAddress<uintptr_t>();
+	Label arm_exit_label;
+	assembler->BindToOffset(&arm_exit_label, offset);
+	assembler->B(&arm_exit_label, mi);	//statically predicted as not taken
+
+	offset = reinterpret_cast<uintptr_t>(arm_dispatch) - assembler->GetBuffer()->GetStartAddress<uintptr_t>();
+	Label arm_dispatch_label;
+	assembler->BindToOffset(&arm_dispatch_label, offset);
+	assembler->B(&arm_dispatch_label);
+
+	assembler->FinalizeCode();
+	verify(assembler->GetBuffer()->GetCursorOffset() <= assembler->GetBuffer()->GetCapacity());
+	vmem_platform_flush_cache(
+		codestart, assembler->GetBuffer()->GetEndAddress<void*>(),
+		codestart, assembler->GetBuffer()->GetEndAddress<void*>());
+	icPtr += assembler->GetBuffer()->GetSizeInBytes();
+
+#if 0
+	Instruction* instr_start = (Instruction *)codestart;
+	Instruction* instr_end = assembler->GetBuffer()->GetEndAddress<Instruction*>();
+	Decoder decoder;
+	Disassembler disasm;
+	decoder.AppendVisitor(&disasm);
+	Instruction* instr;
+	for (instr = instr_start; instr < instr_end; instr += kInstructionSize) {
+		decoder.Decode(instr);
+		DEBUG_LOG(AICA_ARM, "arm64 arec\t %p:\t%s",
+				   reinterpret_cast<void*>(instr),
+				   disasm.GetOutput());
+	}
+#endif
+	delete assembler;
+	assembler = NULL;
+}
+
+//Hook cus varm misses this, so x86 needs special code
+void armv_MOV32(ARM::eReg regn, u32 imm)
+{
+	assembler->Mov(Register::GetWRegFromCode(regn), imm);
+}
+
+void armv_mov(ARM::eReg regd, ARM::eReg regn)
+{
+	assembler->Mov(Register::GetWRegFromCode(regd), Register::GetWRegFromCode(regn));
+}
+
+void armv_add(ARM::eReg regd, ARM::eReg regn, ARM::eReg regm)
+{
+	assembler->Add(Register::GetWRegFromCode(regd), Register::GetWRegFromCode(regn), Register::GetWRegFromCode(regm));
+}
+
+void armv_sub(ARM::eReg regd, ARM::eReg regn, ARM::eReg regm)
+{
+	assembler->Sub(Register::GetWRegFromCode(regd), Register::GetWRegFromCode(regn), Register::GetWRegFromCode(regm));
+}
+
+void armv_add(ARM::eReg regd, ARM::eReg regn, s32 imm)
+{
+	assembler->Add(Register::GetWRegFromCode(regd), Register::GetWRegFromCode(regn), imm);
+}
+
+void armv_lsl(ARM::eReg regd, ARM::eReg regn, u32 imm)
+{
+	assembler->Lsl(Register::GetWRegFromCode(regd), Register::GetWRegFromCode(regn), imm);
+}
+
+void armv_bic(ARM::eReg regd, ARM::eReg regn, u32 imm)
+{
+	assembler->Bic(Register::GetWRegFromCode(regd), Register::GetWRegFromCode(regn), imm);
+}
+
+class android_buf : public std::stringbuf
+{
+public:
+    virtual int sync() override {
+    	DEBUG_LOG(AICA_ARM, "ARM7: %s", this->str().c_str());
+    	str("");
+
+    	return 0;
+    }
+};
+
+void armEmit32(u32 opcode)
+{
+#if 0
+	if (opcode != 0x00011001)
+	{
+		android_buf buffer;
+		std::ostream cout(&buffer);
+		vixl::aarch32::PrintDisassembler disasm(cout, 0);
+		disasm.DecodeA32(opcode);
+		cout.flush();
+	}
+#endif
+
+	const Register& rd = Register::GetWRegFromCode((opcode >> 12) & 15);
+	const Register& rn = Register::GetWRegFromCode((opcode >> 16) & 15);
+	bool set_flags = opcode & (1 << 20);
+	Operand op2;
+	int op_type = (opcode >> 21) & 15;
+	bool logical_op = op_type == 0 || op_type == 1 || op_type == 8 || op_type == 9	// AND, EOR, TST, TEQ
+			 || op_type == 12 || op_type == 13 || op_type == 15 || op_type == 14;	// ORR, MOV, MVN, BIC
+	bool set_carry_bit = false;
+
+	ARM::ConditionCode condition = (ARM::ConditionCode)(opcode >> 28);
+	void *cond_op_label = armv_start_conditional(condition);
+
+	if (opcode & (1 << 25))
+	{
+		// op2 is imm8r4
+		u32 rotate = ((opcode >> 8) & 15) << 1;
+		u32 imm8 = opcode & 0xff;
+		op2 = Operand((imm8 >> rotate) | (imm8 << (32 - rotate)));
+	}
+	else
+	{
+		// op2 is register
+		const Register& rm = Register::GetWRegFromCode(opcode & 15);
+
+		Shift shift = (Shift)((opcode >> 5) & 3);
+
+		if (opcode & (1 << 4))
+		{
+			// shift by register
+			// FIXME Carry must be set based on shift/rotate
+			//if (set_flags && logical_op)
+			//	die("shift by register with set flags C - not implemented");
+			const Register& shift_reg = Register::GetWRegFromCode((opcode >> 8) & 15);
+
+			Label shift_by_32_label;
+
+			switch (shift)
+			{
+			case LSL:
+			case LSR:
+				assembler->Mrs(x0, NZCV);
+				assembler->Cmp(shift_reg, 32);
+				if (shift == LSL)
+					assembler->Lsl(w15, rm, shift_reg);
+				else
+					assembler->Lsr(w15, rm, shift_reg);
+				assembler->Csel(w15, 0, w15, ge);		// LSL and LSR by 32 or more gives 0
+				assembler->Msr(NZCV, x0);
+				break;
+			case ASR:
+				assembler->Mrs(x0, NZCV);
+				assembler->Cmp(shift_reg, 32);
+				assembler->Asr(w15, rm, shift_reg);
+				assembler->Sbfx(w13, rm, 31, 1);
+				assembler->Csel(w15, w13, w15, ge);		// ASR by 32 or more gives 0 or -1 depending on operand sign
+				assembler->Msr(NZCV, x0);
+				break;
+			case ROR:
+				assembler->Ror(w15, rm, shift_reg);
+				break;
+			default:
+				die("Invalid shift");
+				break;
+			}
+			op2 = Operand(w15);
+		}
+		else
+		{
+			// shift by immediate
+			u32 shift_imm = (opcode >> 7) & 0x1f;
+			if (shift != ROR && shift_imm != 0 && !(set_flags && logical_op))
+			{
+				op2 = Operand(rm, shift, shift_imm);
+			}
+			else if (shift_imm == 0)
+			{
+				if (shift == LSL)
+				{
+					op2 = Operand(rm);		// LSL 0 is a no-op
+				}
+				else
+				{
+					// Shift by 32
+					if (set_flags && logical_op)
+						set_carry_bit = true;
+					if (shift == LSR)
+					{
+						if (set_flags && logical_op)
+							assembler->Ubfx(w14, rm, 31, 1);			// w14 = rm[31]
+						assembler->Mov(w15, 0);							// w15 = 0
+					}
+					else if (shift == ASR)
+					{
+						if (set_flags && logical_op)
+							assembler->Ubfx(w14, rm, 31, 1);			// w14 = rm[31]
+						assembler->Sbfx(w15, rm, 31, 1);				// w15 = rm < 0 ? -1 : 0
+					}
+					else if (shift == ROR)
+					{
+						// RRX
+						assembler->Cset(w14, cs);						// w14 = C
+						assembler->Mov(w15, Operand(rm, LSR, 1));		// w15 = rm >> 1
+						assembler->Bfi(w15, w14, 31, 1);				// w15[31] = C
+						if (set_flags && logical_op)
+							assembler->Ubfx(w14, rm, 0, 1);				// w14 = rm[0] (new C)
+					}
+					else
+						die("Invalid shift");
+					op2 = Operand(w15);
+				}
+			}
+			else
+			{
+				// Carry must be preserved or Ror shift
+				if (set_flags && logical_op)
+					set_carry_bit = true;
+				if (shift == LSL)
+				{
+					assembler->Ubfx(w14, rm, 32 - shift_imm, 1);	// w14 = rm[lsb]
+					assembler->Lsl(w15, rm, shift_imm);				// w15 <<= shift
+				}
+				else
+				{
+					if (set_flags && logical_op)
+						assembler->Ubfx(w14, rm, shift_imm - 1, 1);	// w14 = rm[msb]
+
+					if (shift == LSR)
+						assembler->Lsr(w15, rm, shift_imm);			// w15 >>= shift
+					else if (shift == ASR)
+						assembler->Asr(w15, rm, shift_imm);
+					else if (shift == ROR)
+						assembler->Ror(w15, rm, shift_imm);
+					else
+						die("Invalid shift");
+				}
+				op2 = Operand(w15);
+			}
+		}
+	}
+	if (!set_carry_bit
+			&& (op_type == 8 || op_type == 9			// TST and TEQ always set flags
+				|| (logical_op && set_flags)))
+	{
+		// Logical ops should only affect the carry bit based on the op2 shift
+		// Here we're not shifting so the carry bit should be preserved
+		set_carry_bit = true;
+		assembler->Cset(w14, cs);
+	}
+
+	switch (op_type)
+	{
+	case 0:		// AND
+		if (set_flags)
+			assembler->Ands(rd, rn, op2);
+		else
+			assembler->And(rd, rn, op2);
+		break;
+	case 1:		// EOR
+		assembler->Eor(rd, rn, op2);
+		if (set_flags)
+			assembler->Tst(rd, rd);
+		break;
+	case 2:		// SUB
+		if (set_flags)
+			assembler->Subs(rd, rn, op2);
+		else
+			assembler->Sub(rd, rn, op2);
+		break;
+	case 3:		// RSB
+		assembler->Neg(w0, rn);
+		if (set_flags)
+			assembler->Adds(rd, w0, op2);
+		else
+			assembler->Add(rd, w0, op2);
+		break;
+	case 4:		// ADD
+		if (set_flags)
+			assembler->Adds(rd, rn, op2);
+		else
+			assembler->Add(rd, rn, op2);
+		break;
+	case 12:	// ORR
+		assembler->Orr(rd, rn, op2);
+		if (set_flags)
+			assembler->Tst(rd, rd);
+		break;
+	case 14:	// BIC
+		if (set_flags)
+			assembler->Bics(rd, rn, op2);
+		else
+			assembler->Bic(rd, rn, op2);
+		break;
+	case 5:		// ADC
+		if (set_flags)
+			assembler->Adcs(rd, rn, op2);
+		else
+			assembler->Adc(rd, rn, op2);
+		break;
+	case 6:		// SBC
+		if (set_flags)
+			assembler->Sbcs(rd, rn, op2);
+		else
+			assembler->Sbc(rd, rn, op2);
+		break;
+	case 7:		// RSC
+		assembler->Ngc(w0, rn);
+		if (set_flags)
+			assembler->Adds(rd, w0, op2);
+		else
+			assembler->Add(rd, w0, op2);
+		break;
+	case 8:		// TST
+		assembler->Tst(rn, op2);
+		break;
+	case 9:		// TEQ
+		assembler->Eor(w0, rn, op2);
+		assembler->Tst(w0, w0);
+		break;
+	case 10:	// CMP
+		assembler->Cmp(rn, op2);
+		break;
+	case 11:	// CMN
+		assembler->Cmn(rn, op2);
+		break;
+	case 13:	// MOV
+		assembler->Mov(rd, op2);
+		if (set_flags)
+			assembler->Tst(rd, rd);
+		break;
+	case 15:	// MVN
+		assembler->Mvn(rd, op2);
+		if (set_flags)
+			assembler->Tst(rd, rd);
+		break;
+	}
+	if (set_carry_bit)
+	{
+		assembler->Mrs(x0, NZCV);
+		assembler->Bfi(x0, x14, 29, 1);		// C is bit 29 in NZCV
+		assembler->Msr(NZCV, x0);
+	}
+	armv_end_conditional(cond_op_label);
+}
+
+//
+// Dynarec main loop
+//
+// w25 is used for temp mem save (post increment op2)
+// x26 is the entry points table
+// w27 is the cycle counter
+// x28 points to the arm7 registers base
+__asm__ (
+		".globl arm_compilecode				\n\t"
+		".hidden arm_compilecode			\n"
+	"arm_compilecode:						\n\t"
+		"bl CompileCode						\n\t"
+		"b arm_dispatch						\n\t"
+
+		".globl arm_mainloop				\n\t"
+		".hidden arm_mainloop				\n"
+	"arm_mainloop:							\n\t"	//  arm_mainloop(cycles, regs, entry points)
+		"stp x25, x26, [sp, #-48]!			\n\t"
+		"stp x27, x28, [sp, #16]			\n\t"
+		"stp x29, x30, [sp, #32]			\n\t"
+
+		"mov x28, x1						\n\t"	// arm7 registers
+		"mov x26, x2						\n\t"	// lookup base
+
+		"ldr w27, [x28, #192]				\n\t"	// cycle count
+		"add w27, w27, w0					\n\t"	// add cycles for this timeslice
+
+		".globl arm_dispatch				\n\t"
+		".hidden arm_dispatch				\n"
+	"arm_dispatch:							\n\t"
+		"ldp w0, w1, [x28, #184]			\n\t"	// load Next PC, interrupt
+		"ubfx w2, w0, #2, #21				\n\t"	// w2 = pc >> 2. Note: assuming address space == 8 MB (23 bits)
+		"cbnz w1, arm_dofiq					\n\t"	// if interrupt pending, handle it
+
+		"add x2, x26, x2, lsl #3			\n\t"	// x2 = EntryPoints + pc << 1
+		"ldr x3, [x2]						\n\t"
+		"br x3								\n"
+
+	"arm_dofiq:								\n\t"
+		"bl CPUFiq							\n\t"
+		"b arm_dispatch						\n\t"
+
+		".globl arm_exit					\n\t"
+		".hidden arm_exit					\n"
+	"arm_exit:								\n\t"
+		"str w27, [x28, #192]				\n\t"	// if timeslice is over, save remaining cycles
+		"ldp x29, x30, [sp, #32]			\n\t"
+		"ldp x27, x28, [sp, #16]			\n\t"
+		"ldp x25, x26, [sp], #48			\n\t"
+		"ret								\n"
+);
+#endif // ARM64
diff --git a/core/hw/arm7/arm7.cpp b/core/hw/arm7/arm7.cpp
index ac1289b..a920906 100644
--- a/core/hw/arm7/arm7.cpp
+++ b/core/hw/arm7/arm7.cpp
@@ -1,8 +1,9 @@
 #include "arm7.h"
 #include "arm_mem.h"
-#include "arm7_rec.h"
 
-#define CPUReadMemoryQuick(addr) (*(u32*)&aica_ram[(addr) & ARAM_MASK])
+#define arm_printf(...) DEBUG_LOG(AICA_ARM, __VA_ARGS__)
+
+#define CPUReadMemoryQuick(addr) (*(u32*)&aica_ram[addr&ARAM_MASK])
 #define CPUReadByte arm_ReadMem8
 #define CPUReadMemory arm_ReadMem32
 #define CPUReadHalfWord arm_ReadMem16
@@ -21,9 +22,11 @@
 #define CPUUpdateTicksAccess32(a) 1
 #define CPUUpdateTicksAccess16(a) 1
 
+#define ARM_CYCLES_PER_SAMPLE 256
+
 alignas(8) reg_pair arm_Reg[RN_ARM_REG_COUNT];
 
-static void CPUSwap(u32 *a, u32 *b)
+void CPUSwap(u32 *a, u32 *b)
 {
 	u32 c = *b;
 	*b = *a;
@@ -41,57 +44,57 @@ int armMode;
 
 bool Arm7Enabled = false;
 
-static u8 cpuBitsSet[256];
+u8 cpuBitsSet[256];
 
-static void CPUSwitchMode(int mode, bool saveState);
-static void CPUUpdateFlags();
-static void CPUSoftwareInterrupt(int comment);
-static void CPUUndefinedException();
+void CPUSwitchMode(int mode, bool saveState, bool breakLoop=true);
+extern "C" void CPUFiq();
+void CPUUpdateCPSR();
+void CPUUpdateFlags();
+void CPUSoftwareInterrupt(int comment);
+void CPUUndefinedException();
+void libAICA_TimeStep();
 
 #if FEAT_AREC == DYNAREC_NONE
 
 //
 // ARM7 interpreter
 //
-static int clockTicks;
-
-static void runInterpreter(u32 CycleCount)
+void arm_Run_(u32 CycleCount)
 {
 	if (!Arm7Enabled)
 		return;
 
-	clockTicks -= CycleCount;
-	while (clockTicks < 0)
+	u32 clockTicks = 0;
+	while (clockTicks < CycleCount)
 	{
 		if (reg[INTR_PEND].I)
+		{
 			CPUFiq();
+		}
 
 		reg[15].I = armNextPC + 8;
 		#include "arm-new.h"
 	}
 }
 
-void aicaarm::avoidRaceCondition()
-{
-	clockTicks = std::min(clockTicks, -50);
-}
-
-void aicaarm::run(u32 samples)
+void arm_Run(u32 samples)
 {
 	for (u32 i = 0; i < samples; i++)
 	{
-		runInterpreter(ARM_CYCLES_PER_SAMPLE);
+		arm_Run_(ARM_CYCLES_PER_SAMPLE);
 		libAICA_TimeStep();
 	}
 }
 #endif
 
-void aicaarm::init()
+void armt_init();
+
+void arm_Init()
 {
 #if FEAT_AREC != DYNAREC_NONE
-	recompiler::init();
+	armt_init();
 #endif
-	aicaarm::reset();
+	arm_Reset();
 
 	for (int i = 0; i < 256; i++)
 	{
@@ -104,7 +107,7 @@ void aicaarm::init()
 	}
 }
 
-static void CPUSwitchMode(int mode, bool saveState)
+void CPUSwitchMode(int mode, bool saveState, bool breakLoop)
 {
 	CPUUpdateCPSR();
 
@@ -114,7 +117,7 @@ static void CPUSwitchMode(int mode, bool saveState)
 	case 0x1F:
 		reg[R13_USR].I = reg[13].I;
 		reg[R14_USR].I = reg[14].I;
-		reg[RN_SPSR].I = reg[RN_CPSR].I;
+		reg[17].I = reg[16].I;
 		break;
 	case 0x11:
 		CPUSwap(&reg[R8_FIQ].I, &reg[8].I);
@@ -124,32 +127,32 @@ static void CPUSwitchMode(int mode, bool saveState)
 		CPUSwap(&reg[R12_FIQ].I, &reg[12].I);
 		reg[R13_FIQ].I = reg[13].I;
 		reg[R14_FIQ].I = reg[14].I;
-		reg[SPSR_FIQ].I = reg[RN_SPSR].I;
+		reg[SPSR_FIQ].I = reg[17].I;
 		break;
 	case 0x12:
 		reg[R13_IRQ].I  = reg[13].I;
 		reg[R14_IRQ].I  = reg[14].I;
-		reg[SPSR_IRQ].I =  reg[RN_SPSR].I;
+		reg[SPSR_IRQ].I =  reg[17].I;
 		break;
 	case 0x13:
 		reg[R13_SVC].I  = reg[13].I;
 		reg[R14_SVC].I  = reg[14].I;
-		reg[SPSR_SVC].I =  reg[RN_SPSR].I;
+		reg[SPSR_SVC].I =  reg[17].I;
 		break;
 	case 0x17:
 		reg[R13_ABT].I  = reg[13].I;
 		reg[R14_ABT].I  = reg[14].I;
-		reg[SPSR_ABT].I =  reg[RN_SPSR].I;
+		reg[SPSR_ABT].I =  reg[17].I;
 		break;
 	case 0x1b:
 		reg[R13_UND].I  = reg[13].I;
 		reg[R14_UND].I  = reg[14].I;
-		reg[SPSR_UND].I =  reg[RN_SPSR].I;
+		reg[SPSR_UND].I =  reg[17].I;
 		break;
 	}
 
-	u32 CPSR = reg[RN_CPSR].I;
-	u32 SPSR = reg[RN_SPSR].I;
+	u32 CPSR = reg[16].I;
+	u32 SPSR = reg[17].I;
 
 	switch(mode)
 	{
@@ -157,7 +160,7 @@ static void CPUSwitchMode(int mode, bool saveState)
 	case 0x1F:
 		reg[13].I = reg[R13_USR].I;
 		reg[14].I = reg[R14_USR].I;
-		reg[RN_CPSR].I = SPSR;
+		reg[16].I = SPSR;
 		break;
 	case 0x11:
 		CPUSwap(&reg[8].I, &reg[R8_FIQ].I);
@@ -168,45 +171,45 @@ static void CPUSwitchMode(int mode, bool saveState)
 		reg[13].I = reg[R13_FIQ].I;
 		reg[14].I = reg[R14_FIQ].I;
 		if(saveState)
-			reg[RN_SPSR].I = CPSR;
+			reg[17].I = CPSR;
 		else
-			reg[RN_SPSR].I = reg[SPSR_FIQ].I;
+			reg[17].I = reg[SPSR_FIQ].I;
 		break;
 	case 0x12:
 		reg[13].I = reg[R13_IRQ].I;
 		reg[14].I = reg[R14_IRQ].I;
-		reg[RN_CPSR].I = SPSR;
+		reg[16].I = SPSR;
 		if(saveState)
-			reg[RN_SPSR].I = CPSR;
+			reg[17].I = CPSR;
 		else
-			reg[RN_SPSR].I = reg[SPSR_IRQ].I;
+			reg[17].I = reg[SPSR_IRQ].I;
 		break;
 	case 0x13:
 		reg[13].I = reg[R13_SVC].I;
 		reg[14].I = reg[R14_SVC].I;
-		reg[RN_CPSR].I = SPSR;
+		reg[16].I = SPSR;
 		if(saveState)
-			reg[RN_SPSR].I = CPSR;
+			reg[17].I = CPSR;
 		else
-			reg[RN_SPSR].I = reg[SPSR_SVC].I;
+			reg[17].I = reg[SPSR_SVC].I;
 		break;
 	case 0x17:
 		reg[13].I = reg[R13_ABT].I;
 		reg[14].I = reg[R14_ABT].I;
-		reg[RN_CPSR].I = SPSR;
+		reg[16].I = SPSR;
 		if(saveState)
-			reg[RN_SPSR].I = CPSR;
+			reg[17].I = CPSR;
 		else
-			reg[RN_SPSR].I = reg[SPSR_ABT].I;
+			reg[17].I = reg[SPSR_ABT].I;
 		break;
 	case 0x1b:
 		reg[13].I = reg[R13_UND].I;
 		reg[14].I = reg[R14_UND].I;
-		reg[RN_CPSR].I = SPSR;
+		reg[16].I = SPSR;
 		if(saveState)
-			reg[RN_SPSR].I = CPSR;
+			reg[17].I = CPSR;
 		else
-			reg[RN_SPSR].I = reg[SPSR_UND].I;
+			reg[17].I = reg[SPSR_UND].I;
 		break;
 	default:
 		ERROR_LOG(AICA_ARM, "Unsupported ARM mode %02x", mode);
@@ -224,54 +227,56 @@ void CPUUpdateCPSR()
 
 	CPSR.I = reg[RN_CPSR].I & 0x40;
 
-	CPSR.PSR.NZCV = reg[RN_PSR_FLAGS].FLG.NZCV;
+	CPSR.PSR.NZCV=reg[RN_PSR_FLAGS].FLG.NZCV;
 
 	if (!armFiqEnable)
 		CPSR.I |= 0x40;
 	if(!armIrqEnable)
 		CPSR.I |= 0x80;
 
-	CPSR.PSR.M = armMode;
+	CPSR.PSR.M=armMode;
 	
-	reg[RN_CPSR].I = CPSR.I;
+	reg[16].I = CPSR.I;
 }
 
-static void CPUUpdateFlags()
+void CPUUpdateFlags()
 {
-	u32 CPSR = reg[RN_CPSR].I;
+	u32 CPSR = reg[16].I;
 
-	reg[RN_PSR_FLAGS].FLG.NZCV = reg[RN_CPSR].PSR.NZCV;
+	reg[RN_PSR_FLAGS].FLG.NZCV=reg[16].PSR.NZCV;
 
 	armIrqEnable = (CPSR & 0x80) ? false : true;
 	armFiqEnable = (CPSR & 0x40) ? false : true;
 	update_armintc();
 }
 
-static void CPUSoftwareInterrupt(int comment)
+void CPUSoftwareInterrupt(int comment)
 {
 	u32 PC = reg[R15_ARM_NEXT].I+4;
-	CPUSwitchMode(0x13, true);
+	CPUSwitchMode(0x13, true, false);
 	reg[14].I = PC;
 	
 	armIrqEnable = false;
 	armNextPC = 0x08;
 }
 
-static void CPUUndefinedException()
+void CPUUndefinedException()
 {
 	WARN_LOG(AICA_ARM, "arm7: CPUUndefinedException(). SOMETHING WENT WRONG");
 	u32 PC = reg[R15_ARM_NEXT].I+4;
-	CPUSwitchMode(0x1b, true);
+	CPUSwitchMode(0x1b, true, false);
 	reg[14].I = PC;
 	armIrqEnable = false;
 	armNextPC = 0x04;
 }
 
-void aicaarm::reset()
+void FlushCache();
+
+void arm_Reset()
 {
 	DEBUG_LOG(AICA_ARM, "AICA ARM Reset");
 #if FEAT_AREC != DYNAREC_NONE
-	recompiler::flush();
+	FlushCache();
 #endif
 	aica_interr = false;
 	aica_reg_L = 0;
@@ -283,11 +288,11 @@ void aicaarm::reset()
 	// clean registers
 	memset(&arm_Reg[0], 0, sizeof(arm_Reg));
 
-	armMode = 0x13;
+	armMode = 0x1F;
 
 	reg[13].I = 0x03007F00;
 	reg[15].I = 0x0000000;
-	reg[RN_CPSR].I = 0x00000000;
+	reg[16].I = 0x00000000;
 	reg[R13_IRQ].I = 0x03007FA0;
 	reg[R13_SVC].I = 0x03007FE0;
 	armIrqEnable = true;      
@@ -297,7 +302,7 @@ void aicaarm::reset()
 	C_FLAG = V_FLAG = N_FLAG = Z_FLAG = false;
 
 	// disable FIQ
-	reg[RN_CPSR].I |= 0x40;
+	reg[16].I |= 0x40;
 
 	CPUUpdateCPSR();
 
@@ -305,11 +310,12 @@ void aicaarm::reset()
 	reg[15].I += 4;
 }
 
+extern "C"
 NOINLINE
 void CPUFiq()
 {
 	u32 PC = reg[R15_ARM_NEXT].I+4;
-	CPUSwitchMode(0x11, true);
+	CPUSwitchMode(0x11, true, false);
 	reg[14].I = PC;
 	armIrqEnable = false;
 	armFiqEnable = false;
@@ -318,6 +324,7 @@ void CPUFiq()
 	armNextPC = 0x1c;
 }
 
+
 /*
 	--Seems like aica has 3 interrupt controllers actualy (damn lazy sega ..)
 	The "normal" one (the one that exists on scsp) , one to emulate the 68k intc , and , 
@@ -326,16 +333,19 @@ void CPUFiq()
 	The output of the sci* bits is input to the e68k , and the output of e68k is inputed into the FIQ
 	pin on arm7
 */
+#include "hw/sh4/sh4_core.h"
 
 
-void aicaarm::enable(bool enabled)
+void arm_SetEnabled(bool enabled)
 {
 	if(!Arm7Enabled && enabled)
-		aicaarm::reset();
+			arm_Reset();
 	
 	Arm7Enabled=enabled;
 }
 
+
+
 void update_armintc()
 {
 	reg[INTR_PEND].I=e68k_out && armFiqEnable;
@@ -343,23 +353,1006 @@ void update_armintc()
 
 #if FEAT_AREC != DYNAREC_NONE
 //
-// Used by ARM7 Recompiler
+// ARM7 Recompiler
 //
-namespace aicaarm {
 
-namespace recompiler {
+#include "virt_arm.h"
+
+#if defined(__APPLE__)
+#include <sys/mman.h>
+#endif
+
+extern "C" void CompileCode();
 
 //Emulate a single arm op, passed in opcode
+//DYNACALL for ECX passing
 
-void DYNACALL interpret(u32 opcode)
+u32 DYNACALL arm_single_op(u32 opcode)
 {
-	u32 clockTicks = 0;
+	u32 clockTicks=0;
 
 #define NO_OPCODE_READ
+
+	//u32 static_opcode=((opcd_hash&0xFFF0)<<16) |  ((opcd_hash&0x000F)<<4);
+	//u32 static_opcode=((opcd_hash)<<28);
 #include "arm-new.h"
-#undef NO_OPCODE_READ
 
-	reg[CYCL_CNT].I -= clockTicks;
+	return clockTicks;
+}
+
+/*
+
+	ARM
+		ALU opcodes (more or less)
+
+			(flags,rv)=opcode(flags,in regs ..)
+			rd=rv;
+			if (set_flags)
+				PSR=(rd==pc?CPSR:flags);
+		
+		(mem ops)
+		Writes of R15:
+			R15+12
+		R15 as base:
+			R15+8
+		LDR
+			rd=mem[addr(in regs)]
+		LDM
+
+		...
+		STR/STM: pc+12
+
+
+		///
+
+		"cached" interpreter:
+		Set PC+12 to PC reg
+		mov opcode
+		call function
+
+		if (pc settting opcode)
+			lookup again using armNextPC
+			
+
+		PC setting opcodes
+			ALU with write to PC
+			LDR with write to PC (SDT)
+			LDM with write to PC (BDT)
+			B/BL
+			SWI
+			<Undefined opcodes, if any>
+
+			Indirect, via write to PSR/Mode
+			MSR
+*/
+
+
+struct ArmDPOP
+{
+	u32 key;
+	u32 mask;
+	u32 flags;
+};
+
+std::vector<ArmDPOP> ops;
+
+enum OpFlags
+{
+	OP_SETS_PC         = 1,
+	OP_READS_PC        = 32768,
+	OP_IS_COND         = 65536,
+	OP_MFB             = 0x80000000,
+
+	OP_HAS_RD_12       = 2,
+	OP_HAS_RD_16       = 4,
+	OP_HAS_RS_0        = 8,
+	OP_HAS_RS_8        = 16,
+	OP_HAS_RS_16       = 32,
+	OP_HAS_FLAGS_READ  = 4096,
+	OP_HAS_FLAGS_WRITE = 8192,
+	OP_HAS_RD_READ     = 16384, //For conditionals
+
+	OP_WRITE_FLAGS     = 64,
+	OP_WRITE_FLAGS_S   = 128,
+	OP_READ_FLAGS      = 256,
+	OP_READ_FLAGS_S    = 512,
+	OP_WRITE_REG       = 1024,
+	OP_READ_REG_1      = 2048,
+};
+
+#define DP_R_ROFC (OP_READ_FLAGS_S|OP_READ_REG_1) //Reads reg1, op2, flags if S
+#define DP_R_ROF (OP_READ_FLAGS|OP_READ_REG_1)    //Reads reg1, op2, flags (ADC & co)
+#define DP_R_OFC (OP_READ_FLAGS_S)                //Reads op2, flags if S
+
+#define DP_W_RFC (OP_WRITE_FLAGS_S|OP_WRITE_REG)  //Writes reg, and flags if S
+#define DP_W_F (OP_WRITE_FLAGS)                   //Writes only flags, always (S=1)
+
+/*
+	COND | 00 0 OP1   S Rn Rd SA    ST 0  Rm -- Data opcode, PSR xfer (imm shifted reg)
+	     | 00 0 OP1   S Rn Rd Rs   0 ST 1 Rm -- Data opcode, PSR xfer (reg shifted reg)
+	     | 00 0 0 00A S Rd Rn Rs    1001  Rm -- Mult
+		 | 00 0 1 0B0 0 Rn Rd 0000  1001  Rm -- SWP
+		 | 00 1 OP1   S Rn Rd imm8r4         -- Data opcode, PSR xfer (imm8r4)
+
+		 | 01 0 P UBW L Rn Rd Offset          -- LDR/STR (I=0)
+		 | 01 1 P UBW L Rn Rd SHAM SHTP 0 Rs  -- LDR/STR (I=1)
+		 | 10 0 P USW L Rn {RList}            -- LDM/STM
+		 | 10 1 L {offset}                    -- B/BL
+		 | 11 1 1 X*                          -- SWI
+
+		 (undef cases)
+		 | 01 1 XXXX X X*  X*  X* 1 XXXX - Undefined (LDR/STR w/ encodings that would be reg. based shift)
+		 | 11 0 PUNW L Rn {undef} -- Copr. Data xfer (undef)
+		 | 11 1 0 CPOP Crn Crd Cpn CP3 0 Crm -- Copr. Data Op (undef)
+		 | 11 1 0 CPO3 L Crn Crd Cpn CP3 1 Crm -- Copr. Reg xf (undef)
+
+
+		 Phase #1:
+			-Non branches that don't touch memory (pretty much: Data processing, Not MSR, Mult)
+			-Everything else is ifb
+
+		 Phase #2:
+			Move LDR/STR to templates
+
+		 Phase #3:
+			Move LDM/STM to templates
+			
+
+*/
+
+void AddDPOP(u32 subcd, u32 rflags, u32 wflags)
+{
+	ArmDPOP op;
+
+	u32 key=subcd<<21;
+	u32 mask=(15<<21) | (7<<25);
+
+	op.flags=rflags|wflags;
+	
+	if (wflags==DP_W_F)
+	{
+		//also match S bit for opcodes that must write to flags (CMP & co)
+		mask|=1<<20;
+		key|=1<<20;
+	}
+
+	//ISR form (bit 25=0, bit 4 = 0)
+	op.key=key;
+	op.mask=mask | (1<<4);
+	ops.push_back(op);
+
+	//RSR form (bit 25=0, bit 4 = 1, bit 7=0)
+	op.key =  key  | (1<<4);
+	op.mask = mask | (1<<4) | (1<<7);
+	ops.push_back(op);
+
+	//imm8r4 form (bit 25=1) 
+	op.key =  key  | (1<<25);
+	op.mask = mask;
+	ops.push_back(op);
+}
+
+void InitHash()
+{
+	/*
+		COND | 00 I OP1  S Rn Rd OPER2 -- Data opcode, PSR xfer
+		Data processing opcodes
+	*/
+		 
+	//AND   0000        Rn, OPER2, {Flags}    Rd, {Flags}
+	//EOR   0001        Rn, OPER2, {Flags}    Rd, {Flags}
+	//SUB   0010        Rn, OPER2, {Flags}    Rd, {Flags}
+	//RSB   0011        Rn, OPER2, {Flags}    Rd, {Flags}
+	//ADD   0100        Rn, OPER2, {Flags}    Rd, {Flags}
+	//ORR   1100        Rn, OPER2, {Flags}    Rd, {Flags}
+	//BIC   1110        Rn, OPER2, {Flags}    Rd, {Flags}
+	AddDPOP(0,DP_R_ROFC, DP_W_RFC);
+	AddDPOP(1,DP_R_ROFC, DP_W_RFC);
+	AddDPOP(2,DP_R_ROFC, DP_W_RFC);
+	AddDPOP(3,DP_R_ROFC, DP_W_RFC);
+	AddDPOP(4,DP_R_ROFC, DP_W_RFC);
+	AddDPOP(12,DP_R_ROFC, DP_W_RFC);
+	AddDPOP(14,DP_R_ROFC, DP_W_RFC);
+	
+	//ADC   0101        Rn, OPER2, Flags      Rd, {Flags}
+	//SBC   0110        Rn, OPER2, Flags      Rd, {Flags}
+	//RSC   0111        Rn, OPER2, Flags      Rd, {Flags}
+	AddDPOP(5,DP_R_ROF, DP_W_RFC);
+	AddDPOP(6,DP_R_ROF, DP_W_RFC);
+	AddDPOP(7,DP_R_ROF, DP_W_RFC);
+
+	//TST   1000 S=1    Rn, OPER2, Flags      Flags
+	//TEQ   1001 S=1    Rn, OPER2, Flags      Flags
+	AddDPOP(8,DP_R_ROF, DP_W_F);
+	AddDPOP(9,DP_R_ROF, DP_W_F);
+
+	//CMP   1010 S=1    Rn, OPER2             Flags
+	//CMN   1011 S=1    Rn, OPER2             Flags
+	AddDPOP(10,DP_R_ROF, DP_W_F);
+	AddDPOP(11,DP_R_ROF, DP_W_F);
+	
+	//MOV   1101        OPER2, {Flags}        Rd, {Flags}
+	//MVN   1111        OPER2, {Flags}        Rd, {Flags}
+	AddDPOP(13,DP_R_OFC, DP_W_RFC);
+	AddDPOP(15,DP_R_OFC, DP_W_RFC);
+}
+
+void  armEmit32(u32 emit32);
+void *armGetEmitPtr();
+
+
+#define _DEVEL          (1)
+#define EMIT_I          armEmit32((I))
+#define EMIT_GET_PTR()  armGetEmitPtr()
+u8* icPtr;
+u8* ICache;
+
+extern const u32 ICacheSize=1024*1024;
+#ifdef _WIN32
+u8 ARM7_TCB[ICacheSize+4096];
+#elif HOST_OS == OS_LINUX
+
+u8 ARM7_TCB[ICacheSize+4096] __attribute__((section(".text")));
+
+#elif defined(__APPLE__)
+u8 ARM7_TCB[ICacheSize+4096] __attribute__((section("__TEXT, .text")));
+#else
+#error ARM7_TCB ALLOC
+#endif
+
+#include "arm_emitter/arm_emitter.h"
+#undef I
+
+
+using namespace ARM;
+
+
+void* EntryPoints[ARAM_SIZE_MAX/4];
+
+enum OpType
+{
+	VOT_Fallback,
+	VOT_DataOp,
+	VOT_B,
+	VOT_BL,
+	VOT_BR,     //Branch (to register)
+	VOT_Read,   //Actually, this handles LDR and STR
+	//VOT_LDM,  //This Isn't used anymore
+	VOT_MRS,
+	VOT_MSR,
+};
+
+
+
+void armv_call(void* target);
+void armv_setup();
+void armv_intpr(u32 opcd);
+void armv_end(void* codestart, u32 cycles);
+void armv_check_pc(u32 pc);
+void armv_check_cache(u32 opcd, u32 pc);
+void armv_imm_to_reg(u32 regn, u32 imm);
+void armv_MOV32(eReg regn, u32 imm);
+void armv_prof(OpType opt,u32 op,u32 flg);
+
+extern "C" void arm_dispatch();
+extern "C" void arm_exit();
+extern "C" void DYNACALL
+#ifdef __GNUC__
+	// Avoid inlining / duplicating / whatever
+	__attribute__ ((optimize(0)))
+#endif
+		arm_mainloop(u32 cycl, void* regs, void* entrypoints);
+extern "C" void DYNACALL arm_compilecode();
+
+template <bool Load, bool Byte>
+u32 DYNACALL DoMemOp(u32 addr,u32 data)
+{
+	u32 rv=0;
+
+	if (Load)
+	{
+		if (Byte)
+			rv=arm_ReadMem8(addr);
+		else
+			rv=arm_ReadMem32(addr);
+	}
+	else
+	{
+		if (Byte)
+			arm_WriteMem8(addr,data);
+		else
+			arm_WriteMem32(addr,data);
+	}
+
+	return rv;
+}
+
+//findfirstset -- used in LDM/STM handling
+#if HOST_CPU==CPU_X86 && !defined(__GNUC__)
+#include <intrin.h>
+
+u32 findfirstset(u32 v)
+{
+	unsigned long rv;
+	_BitScanForward(&rv,v);
+	return rv+1;
+}
+#else
+#define findfirstset __builtin_ffs
+#endif
+
+#if 0
+//LDM isn't perf. citrical, and as a result, not implemented fully. 
+//So this code is disabled
+//mask is *2
+template<u32 I>
+void DYNACALL DoLDM(u32 addr, u32 mask)
+{
+
+	//addr=(addr); //force align ?
+
+	u32 idx=-1;
+	do
+	{
+		u32 tz=findfirstset(mask);
+		mask>>=tz;
+		idx+=tz;
+		arm_Reg[idx].I=arm_ReadMem32(addr);
+		addr+=4;
+	} while(mask);
+}
+#endif
+
+void* GetMemOp(bool Load, bool Byte)
+{
+	if (Load)
+	{
+		if (Byte)
+			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<true,true>;
+		else
+			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<true,false>;
+	}
+	else
+	{
+		if (Byte)
+			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<false,true>;
+		else
+			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<false,false>;
+	}
+}
+
+//Decodes an opcode, returns type. 
+//opcd might be changed (currently for LDM/STM -> LDR/STR transforms)
+OpType DecodeOpcode(u32& opcd,u32& flags)
+{
+	//by default, PC has to be updated
+	flags=OP_READS_PC;
+
+	u32 CC=(opcd >> 28);
+
+	if (CC!=CC_AL)
+		flags|=OP_IS_COND;
+
+	//helpers ...
+	#define CHK_BTS(M,S,V) ( (M & (opcd>>S)) == (V) ) //Check bits value in opcode
+	#define IS_LOAD (opcd & (1<<20))                  //Is L bit set ? (LDM/STM LDR/STR)
+	#define READ_PC_CHECK(S) if (CHK_BTS(15,S,15)) flags|=OP_READS_PC;
+
+	//Opcode sets pc ?
+	bool _set_pc=
+		(CHK_BTS(3,26,0) && CHK_BTS(15,12,15))             || //Data processing w/ Rd=PC
+		(CHK_BTS(3,26,1) && CHK_BTS(15,12,15) && IS_LOAD ) || //LDR/STR w/ Rd=PC 
+		(CHK_BTS(7,25,4) && (opcd & 32768) &&  IS_LOAD)    || //LDM/STM w/ PC in list	
+		CHK_BTS(7,25,5)                                    || //B or BL
+		CHK_BTS(15,24,15);                                    //SWI
+	
+	//NV condition means VFP on newer cores, let interpreter handle it...
+	if (CC==15)
+		return VOT_Fallback;
+
+	if (_set_pc)
+		flags|=OP_SETS_PC;
+
+	//B / BL ?
+	if (CHK_BTS(7,25,5))
+	{
+		verify(_set_pc);
+		if (!(flags&OP_IS_COND))
+			flags&=~OP_READS_PC;  //not COND doesn't read from pc
+
+		flags|=OP_SETS_PC;        //Branches Set pc ..
+
+		//branch !
+		return (opcd&(1<<24))?VOT_BL:VOT_B;
+	}
+
+	//Common case: MOVCC PC,REG
+	if (CHK_BTS(0xFFFFFF,4,0x1A0F00))
+	{
+		verify(_set_pc);
+		if (CC==CC_AL)
+			flags&=~OP_READS_PC;
+
+		return VOT_BR;
+	}
+
+
+	//No support for COND branching opcodes apart from the forms above ..
+	if (CC!=CC_AL && _set_pc)
+	{
+		return VOT_Fallback;
+	}
+
+	u32 RList=opcd&0xFFFF;
+	u32 Rn=(opcd>>16)&15;
+
+#define LDM_REGCNT() (cpuBitsSet[RList & 255] + cpuBitsSet[(RList >> 8) & 255])
+
+
+	//Data Processing opcodes -- find using mask/key
+	//This will eventually be virtualised w/ register renaming
+	for( u32 i=0;i<ops.size();i++)
+	{
+		if (!_set_pc && ops[i].key==(opcd&ops[i].mask))
+		{
+			//We fill in the cases that we have to read pc
+			flags &= ~OP_READS_PC;
+
+			//Conditionals always need flags read ...
+			if ((opcd >> 28)!=0xE)
+			{
+				flags |= OP_HAS_FLAGS_READ;
+				//if (flags & OP_WRITE_REG)
+					flags |= OP_HAS_RD_READ;
+			}
+
+			//DPOP !
+
+			if ((ops[i].flags & OP_READ_FLAGS) ||
+			   ((ops[i].flags & OP_READ_FLAGS_S) && (opcd & (1<<20))))
+			{
+				flags |= OP_HAS_FLAGS_READ;
+			}
+
+			if ((ops[i].flags & OP_WRITE_FLAGS) ||
+			   ((ops[i].flags & OP_WRITE_FLAGS_S) && (opcd & (1<<20))))
+			{
+				flags |= OP_HAS_FLAGS_WRITE;
+			}
+
+			if(ops[i].flags & OP_WRITE_REG)
+			{
+				//All dpops that write, write to RD_12
+				flags |= OP_HAS_RD_12;
+				verify(! (CHK_BTS(15,12,15) && CC!=CC_AL));
+			}
+
+			if(ops[i].flags & OP_READ_REG_1)
+			{
+				//Reg 1 is RS_16
+				flags |= OP_HAS_RS_16;
+
+				//reads from pc ?
+				READ_PC_CHECK(16);
+			}
+
+			//op2 is imm or reg ?
+			if ( !(opcd & (1<<25)) )
+			{
+				//its reg (register or imm shifted)
+				flags |= OP_HAS_RS_0;
+				//reads from pc ?
+				READ_PC_CHECK(0);
+
+				//is it register shifted reg ?
+				if (opcd & (1<<4))
+				{
+					verify(! (opcd & (1<<7)) );	//must be zero
+					flags |= OP_HAS_RS_8;
+					//can't be pc ...
+					verify(!CHK_BTS(15,8,15));
+				}
+				else
+				{
+					//is it RRX ?
+					if ( ((opcd>>4)&7)==6)
+					{
+						//RRX needs flags to be read (even if the opcode doesn't)
+						flags |= OP_HAS_FLAGS_READ;
+					}
+				}
+			}
+
+			return VOT_DataOp;
+		}
+	}
+
+	//Lets try mem opcodes since its not data processing
+
+
+	
+	/*
+		Lets Check LDR/STR !
+
+		CCCC 01 0 P UBW L Rn Rd Offset	-- LDR/STR (I=0)
+	*/
+	if ((opcd>>25)==(0xE4/2) )
+	{
+		/*
+			I=0
+
+			Everything else handled
+		*/
+		arm_printf("ARM: MEM %08X L/S:%d, AWB:%d!\n",opcd,(opcd>>20)&1,(opcd>>21)&1);
+
+		return VOT_Read;
+	}
+	else if ((opcd>>25)==(0xE6/2) && CHK_BTS(0x7,4,0) )
+	{
+		arm_printf("ARM: MEM REG to Reg %08X\n",opcd);
+		
+		/*
+			I=1
+
+			Logical Left shift, only
+		*/
+		return VOT_Read;
+	}
+	//LDM common case
+	else if ((opcd>>25)==(0xE8/2) /*&& CHK_BTS(32768,0,0)*/ && CHK_BTS(1,22,0) && CHK_BTS(1,20,1) && LDM_REGCNT()==1)
+	{
+		//P=0
+		//U=1
+		//L=1
+		//W=1
+		//S=0
+		
+		u32 old_opcd=opcd;
+
+		//One register xfered
+		//Can be rewriten as normal mem opcode ..
+		opcd=0xE4000000;
+
+		//Imm offset
+		opcd |= 0<<25;
+		//Post incr
+		opcd |= old_opcd & (1<<24);
+		//Up/Dn
+		opcd |= old_opcd & (1<<23);
+		//Word/Byte
+		opcd |= 0<<22;
+		//Write back (must be 0 for PI)
+		opcd |= old_opcd & (1<<21);
+		//Load
+		opcd |= old_opcd & (1<<20);
+
+		//Rn
+		opcd |= Rn<<16;
+
+		//Rd
+		u32 Rd=findfirstset(RList)-1;
+		opcd |= Rd<<12;
+
+		//Offset
+		opcd |= 4;
+
+		arm_printf("ARM: MEM TFX R %08X\n",opcd);
+
+		return VOT_Read;
+	}
+	//STM common case
+	else if ((opcd>>25)==(0xE8/2) && CHK_BTS(1,22,0) && CHK_BTS(1,20,0) && LDM_REGCNT()==1)
+	{
+		//P=1
+		//U=0
+		//L=1
+		//W=1
+		//S=0
+		
+		u32 old_opcd=opcd;
+
+		//One register xfered
+		//Can be rewriten as normal mem opcode ..
+		opcd=0xE4000000;
+
+		//Imm offset
+		opcd |= 0<<25;
+		//Pre/Post incr
+		opcd |= old_opcd & (1<<24);
+		//Up/Dn
+		opcd |= old_opcd & (1<<23);
+		//Word/Byte
+		opcd |= 0<<22;
+		//Write back
+		opcd |= old_opcd & (1<<21);
+		//Store/Load
+		opcd |= old_opcd & (1<<20);
+
+		//Rn
+		opcd |= Rn<<16;
+
+		//Rd
+		u32 Rd=findfirstset(RList)-1;
+		opcd |= Rd<<12;
+
+		//Offset
+		opcd |= 4;
+
+		arm_printf("ARM: MEM TFX W %08X\n",opcd);
+
+		return VOT_Read;
+	}
+	else if (CHK_BTS(0xE10F0FFF,0,0xE10F0000))
+	{
+		return VOT_MRS;
+	}
+	else if (CHK_BTS(0xEFBFFFF0,0,0xE129F000))
+	{
+		return VOT_MSR;
+	}
+	else if ((opcd>>25)==(0xE8/2) && CHK_BTS(32768,0,0))
+	{
+		arm_printf("ARM: MEM FB %08X\n",opcd);
+		flags|=OP_MFB; //(flag Just for the fallback counters)
+	}
+	else
+	{
+		arm_printf("ARM: FB %08X\n",opcd);
+	}
+
+	//by default fallback to interpr
+	return VOT_Fallback;
+}
+
+//helpers ...
+#if HOST_CPU == CPU_ARM64
+extern void LoadReg(eReg rd,u32 regn,ConditionCode cc=CC_AL);
+extern void StoreReg(eReg rd,u32 regn,ConditionCode cc=CC_AL);
+extern void armv_mov(ARM::eReg regd, ARM::eReg regn);
+extern void armv_add(ARM::eReg regd, ARM::eReg regn, ARM::eReg regm);
+extern void armv_sub(ARM::eReg regd, ARM::eReg regn, ARM::eReg regm);
+extern void armv_add(ARM::eReg regd, ARM::eReg regn, s32 imm);
+extern void armv_lsl(ARM::eReg regd, ARM::eReg regn, u32 imm);
+extern void armv_bic(ARM::eReg regd, ARM::eReg regn, u32 imm);
+extern void *armv_start_conditional(ARM::ConditionCode cc);
+extern void armv_end_conditional(void *ref);
+// Use w25 for temp mem save because w9 is not callee-saved
+#define r9 ((ARM::eReg)25)
+#else
+void LoadReg(eReg rd,u32 regn,ConditionCode cc=CC_AL)
+{
+	LDR(rd,r8,(u8*)&reg[regn].I-(u8*)&reg[0].I,Offset,cc);
+}
+void StoreReg(eReg rd,u32 regn,ConditionCode cc=CC_AL)
+{
+	STR(rd,r8,(u8*)&reg[regn].I-(u8*)&reg[0].I,Offset,cc);
+}
+void armv_mov(ARM::eReg regd, ARM::eReg regn)
+{
+	MOV(regd, regn);
+}
+
+void armv_add(ARM::eReg regd, ARM::eReg regn, ARM::eReg regm)
+{
+	ADD(regd, regn, regm);
+}
+
+void armv_sub(ARM::eReg regd, ARM::eReg regn, ARM::eReg regm)
+{
+	SUB(regd, regn, regm);
+}
+
+void armv_add(ARM::eReg regd, ARM::eReg regn, s32 imm)
+{
+	if (imm >= 0)
+		ADD(regd, regn, imm);
+	else
+		SUB(regd, regn, -imm);
+}
+
+void armv_lsl(ARM::eReg regd, ARM::eReg regn, u32 imm)
+{
+	LSL(regd, regn, imm);
+}
+
+void armv_bic(ARM::eReg regd, ARM::eReg regn, u32 imm)
+{
+	BIC(regd, regn, imm);
+}
+
+void *armv_start_conditional(ARM::ConditionCode cc)
+{
+	return NULL;
+}
+void armv_end_conditional(void *ref)
+{
+}
+#endif
+
+//very quick-and-dirty register rename based virtualisation
+u32 renamed_regs[16];
+u32 rename_reg_base;
+
+void RenameRegReset()
+{
+	rename_reg_base=r1;
+	memset(renamed_regs, 0, sizeof(renamed_regs));
+}
+
+//returns new reg #. didrn is true if a rename mapping was added
+u32 RenameReg(u32 reg, bool& didrn)
+{
+	if (renamed_regs[reg] == 0)
+	{
+		renamed_regs[reg]=rename_reg_base;
+		rename_reg_base++;
+		didrn=true;
+	}
+	else
+	{
+		didrn=false;
+	}
+
+	return renamed_regs[reg];
+}
+
+//For reg reads (they need to be loaded)
+//load can be used to skip loading (for RD if not cond)
+void LoadAndRename(u32& opcd, u32 bitpos, bool load,u32 pc)
+{
+	bool didrn;
+	u32 reg=(opcd>>bitpos)&15;
+
+	u32 nreg=RenameReg(reg,didrn);
+
+	opcd = (opcd& ~(15<<bitpos)) | (nreg<<bitpos);
+
+	if (load && didrn)
+	{
+		if (reg==15)
+			armv_MOV32((eReg)nreg,pc);
+		else
+			LoadReg((eReg)nreg,reg);
+	}
+}
+
+//For results store (they need to be stored)
+void StoreAndRename(u32 opcd, u32 bitpos)
+{
+	bool didrn;
+	u32 reg=(opcd>>bitpos)&15;
+
+	u32 nreg=RenameReg(reg,didrn);
+
+	verify(!didrn);
+
+	if (reg==15)
+		reg=R15_ARM_NEXT;
+
+	StoreReg((eReg)nreg,reg);
+}
+
+#if HOST_CPU == CPU_ARM64
+extern void LoadFlags();
+extern void StoreFlags();
+#else
+//For COND
+void LoadFlags()
+{
+	//Load flags
+	LoadReg(r0,RN_PSR_FLAGS);
+	//move them to flags register
+	MSR(0,8,r0);
+}
+
+void StoreFlags()
+{
+	//get results from flags register
+	MRS(r1,0);
+	//Store flags
+	StoreReg(r1,RN_PSR_FLAGS);
+}
+#endif
+
+//Virtualise Data Processing opcode
+void VirtualizeOpcode(u32 opcd,u32 flag,u32 pc)
+{
+	//Keep original opcode for info
+	u32 orig=opcd;
+
+	//Load arm flags, RS0/8/16, RD12/16 (as indicated by the decoder flags)
+
+	if (flag & OP_HAS_FLAGS_READ)
+	{
+		LoadFlags();
+	}
+
+	// Dynamic LSL/LSR/ASR/ROR adds +4 to pc due to delay
+	bool shiftByReg = !(opcd & (1 << 25)) && (opcd & (1 << 4));
+	if (flag & OP_HAS_RS_0)
+		LoadAndRename(opcd, 0, true, pc + (shiftByReg ? 12 : 8));
+	if (flag & OP_HAS_RS_8)
+		LoadAndRename(opcd, 8, true, pc + 8);
+	if (flag & OP_HAS_RS_16)
+		LoadAndRename(opcd, 16, true, pc + (shiftByReg ? 12 : 8));
+
+	if (flag & OP_HAS_RD_12)
+		LoadAndRename(opcd,12,flag&OP_HAS_RD_READ,pc+4);
+
+	if (flag & OP_HAS_RD_16)
+	{
+		verify(! (flag & OP_HAS_RS_16));
+		LoadAndRename(opcd,16,flag&OP_HAS_RD_READ,pc+4);
+	}
+
+	//Opcode has been modified to use the new regs
+	//Emit it ...
+	arm_printf("Arm Virtual: %08X -> %08X\n",orig,opcd);
+	armEmit32(opcd);
+
+	//Store arm flags, rd12/rd16 (as indicated by the decoder flags)
+	if (flag & OP_HAS_RD_12)
+		StoreAndRename(orig,12);
+
+	if (flag & OP_HAS_RD_16)
+		StoreAndRename(orig,16);
+
+	//Sanity check ..
+	if (renamed_regs[15] != 0)
+	{
+		verify(flag&OP_READS_PC || (flag&OP_SETS_PC && !(flag&OP_IS_COND)));
+	}
+
+	if (flag & OP_HAS_FLAGS_WRITE)
+		StoreFlags();
+}
+
+u32 nfb,ffb,bfb,mfb;
+
+void *armGetEmitPtr()
+{
+	if (icPtr < (ICache+ICacheSize-1024))	//ifdebug
+		return static_cast<void *>(icPtr);
+
+	return NULL;
+}
+
+#if	(HOST_CPU == CPU_ARM)
+
+/*
+ *
+ *	ARMv7 Compiler
+ *
+ */
+
+void  armEmit32(u32 emit32)
+{
+	if (icPtr >= (ICache+ICacheSize-1024))
+		die("ICache is full, invalidate old entries ...");	//ifdebug
+
+	*(u32*)icPtr = emit32;  
+	icPtr+=4;
+}
+
+#if defined(__APPLE__)
+#include <libkern/OSCacheControl.h>
+extern "C" void armFlushICache(void *code, void *pEnd) {
+    sys_dcache_flush(code, (u8*)pEnd - (u8*)code + 1);
+    sys_icache_invalidate(code, (u8*)pEnd - (u8*)code + 1);
+}
+#else
+extern "C" void armFlushICache(void *bgn, void *end) {
+	__builtin___clear_cache((char *)bgn, (char *)end);
+}
+#endif
+
+
+void armv_imm_to_reg(u32 regn, u32 imm)
+{
+	MOV32(r0,imm);
+	StoreReg(r0,regn);
+}
+
+void armv_call(void* loc)
+{
+	CALL((u32)loc);
+}
+
+void armv_setup()
+{
+	//Setup emitter
+
+	//r9: temp for mem ops (PI WB)
+	//r8: base
+	//Stored on arm_mainloop so no need for push/pop
+}
+
+void armv_intpr(u32 opcd)
+{
+	//Call interpreter
+	MOV32(r0,opcd);
+	CALL((u32)arm_single_op);
+	SUB(r5, r5, r0, false);
+}
+
+void armv_end(void* codestart, u32 cycl)
+{
+	//Normal block end
+	//cycle counter rv
+
+	//pop registers & return
+	if (is_i8r4(cycl))
+		SUB(r5,r5,cycl,true);
+	else
+	{
+		u32 togo = cycl;
+		while(ARMImmid8r4_enc(togo) == -1)
+		{
+			SUB(r5,r5,256);
+			togo -= 256;
+		}
+		SUB(r5,r5,togo,true);
+	}
+	JUMP((u32)&arm_exit,CC_MI);	//statically predicted as not taken
+	JUMP((u32)&arm_dispatch);
+
+	armFlushICache(codestart,(void*)EMIT_GET_PTR());
+}
+
+//Hook cus varm misses this
+void armv_MOV32(eReg regn, u32 imm)
+{
+	MOV32(regn,imm);
+}
+
+/*
+	No sanity checks on arm ..
+*/
+
+#endif	// HOST_CPU == CPU_ARM
+
+//Run a timeslice for ARMREC
+void arm_Run(u32 samples)
+{
+	for (int i = 0; i < samples; i++)
+	{
+		if (Arm7Enabled)
+			arm_mainloop(ARM_CYCLES_PER_SAMPLE, arm_Reg, EntryPoints);
+		libAICA_TimeStep();
+	}
+}
+
+
+#undef r
+
+/*
+	TODO:
+	R15 read/writing is kind of .. weird
+	Gotta investigate why ..
+*/
+
+//Mem operand 2 calculation, if Reg or large imm
+void MemOperand2(eReg dst,bool I, bool U,u32 offs, u32 opcd)
+{
+	if (I==true)
+	{
+		u32 Rm=(opcd>>0)&15;
+		verify(CHK_BTS(7,4,0));// only SHL mode
+		LoadReg(r1,Rm);
+		u32 SA=31&(opcd>>7);
+		//can't do shifted add for now -- EMITTER LIMIT --
+		if (SA)
+			armv_lsl(r1, r1, SA);
+	}
+	else
+	{
+		armv_MOV32(r1,offs);
+	}
+
+	if (U)
+		armv_add(dst, r0, r1);
+	else
+		armv_sub(dst, r0, r1);
 }
 
 template<u32 Pd>
@@ -369,14 +1362,14 @@ void DYNACALL MSR_do(u32 v)
 	{
 		if(armMode > 0x10 && armMode < 0x1f) /* !=0x10 ?*/
 		{
-			reg[RN_SPSR].I = (reg[RN_SPSR].I & 0x00FFFF00) | (v & 0xFF0000FF);
+			reg[17].I = (reg[17].I & 0x00FFFF00) | (v & 0xFF0000FF);
 		}
 	}
 	else
 	{
 		CPUUpdateCPSR();
 	
-		u32 newValue = reg[RN_CPSR].I;
+		u32 newValue = reg[16].I;
 		if(armMode > 0x10)
 		{
 			newValue = (newValue & 0xFFFFFF00) | (v & 0x000000FF);
@@ -388,14 +1381,393 @@ void DYNACALL MSR_do(u32 v)
 		{
 			CPUSwitchMode(newValue & 0x1f, false);
 		}
-		reg[RN_CPSR].I = newValue;
+		reg[16].I = newValue;
 		CPUUpdateFlags();
 	}
 }
-template void DYNACALL MSR_do<0>(u32 v);
-template void DYNACALL MSR_do<1>(u32 v);
 
+//Compile & run block of code, starting armNextPC
+extern "C" void CompileCode()
+{
+	//Get the code ptr
+	void* rv=EMIT_GET_PTR();
+
+	//update the block table
+	// Note that we mask with the max aica size (8 MB), which is
+	// also the size of the EntryPoints table. This way the dynarec
+	// main loop doesn't have to worry about the actual aica
+	// ram size. The aica ram always wraps to 8 MB anyway.
+	EntryPoints[(armNextPC & (ARAM_SIZE_MAX - 1)) / 4] = rv;
+
+	//setup local pc counter
+	u32 pc=armNextPC;
+
+	//emitter/block setup
+	armv_setup();
+
+	//the ops counter is used to terminate the block (max op count for a single block is 32 currently)
+	//We don't want too long blocks for timing accuracy
+	u32 ops=0;
+
+	u32 Cycles=0;
+
+	for(;;)
+	{
+		ops++;
+
+		// Each opcode takes at least 6 cycles
+		Cycles += 6;
+
+		//Read opcode ...
+		u32 opcd=CPUReadMemoryQuick(pc);
+
+		u32 op_flags;
+
+		//Decode & handle opcode
+
+		OpType opt=DecodeOpcode(opcd,op_flags);
+
+		switch(opt)
+		{
+		case VOT_DataOp:
+			{
+				//data processing opcode that can be virtualised
+				RenameRegReset();
+
+				/*
+				if (op_flags & OP_READS_PC)
+					armv_imm_to_reg(15,pc+8);
+
+				else*/
+				VirtualizeOpcode(opcd,op_flags,pc);
+			}
+			break;
+		
+		case VOT_BR:
+			{
+				//Branch to reg
+				ConditionCode cc=(ConditionCode)(opcd>>28);
+
+				verify(op_flags&OP_SETS_PC);
+
+				if (cc!=CC_AL)
+				{
+					LoadFlags();
+					armv_imm_to_reg(R15_ARM_NEXT,pc+4);
+				}
+
+				LoadReg(r0,opcd&0xF);
+				armv_bic(r0, r0, 3);
+
+				void *ref = armv_start_conditional(cc);
+				StoreReg(r0,R15_ARM_NEXT,cc);
+				armv_end_conditional(ref);
+				Cycles += 3;
+			}
+			break;
+
+		case VOT_B:
+		case VOT_BL:
+			{
+				//Branch to imm
+
+				//<<2, sign extend !
+				s32 offs=((s32)opcd<<8)>>6;
+
+				if (op_flags & OP_IS_COND)
+				{
+					armv_imm_to_reg(R15_ARM_NEXT,pc+4);
+					LoadFlags();
+					ConditionCode cc=(ConditionCode)(opcd>>28);
+					void *ref = armv_start_conditional(cc);
+					if (opt==VOT_BL)
+					{
+						armv_MOV32(r0,pc+4);
+						StoreReg(r0,14,cc);
+					}
+
+					armv_MOV32(r0,pc+8+offs);
+					StoreReg(r0,R15_ARM_NEXT,cc);
+					armv_end_conditional(ref);
+				}
+				else
+				{
+					if (opt==VOT_BL)
+						armv_imm_to_reg(14,pc+4);
+
+					armv_imm_to_reg(R15_ARM_NEXT,pc+8+offs);
+				}
+				Cycles += 3;
+			}
+			break;
+
+		case VOT_Read:
+			{
+				//LDR/STR
+
+				u32 offs=opcd&4095;
+				bool U=opcd&(1<<23);
+				bool Pre=opcd&(1<<24);
+				
+				bool W=opcd&(1<<21);
+				bool I=opcd&(1<<25);
+				bool L = opcd & (1 << 20);
+				
+				u32 Rn=(opcd>>16)&15;
+				u32 Rd=(opcd>>12)&15;
+
+				bool DoWB = (W || !Pre) && Rn != Rd;	//Write back if pre- or post-indexed and Rn!=Rd
+				bool DoAdd=DoWB || Pre;
+
+				//Register not updated anyway
+				if (!I && offs == 0)
+				{
+					DoWB = false;
+					DoAdd = false;
+				}
+
+				//verify(Rd!=15);
+				verify(!((Rn==15) && DoWB));
+
+				//AGU
+				if (Rn!=15)
+				{
+					LoadReg(r0,Rn);
+
+					if (DoAdd)
+					{
+						eReg dst=Pre?r0:r9;
+
+						if (!I && is_i8r4(offs))
+						{
+							if (U)
+								armv_add(dst, r0, offs);
+							else
+								armv_add(dst, r0, -offs);
+						}
+						else
+						{
+							MemOperand2(dst,I,U,offs,opcd);
+						}
+
+						if (DoWB && dst==r0)
+							armv_mov(r9, r0);
+					}
+				}
+				else
+				{
+					u32 addr=pc+8;
+
+					if (Pre && offs && !I)
+					{
+						addr+=U?offs:-offs;
+					}
+					
+					armv_MOV32(r0,addr);
+					
+					if (Pre && I)
+					{
+						MemOperand2(r1,I,U,offs,opcd);
+						armv_add(r0, r0, r1);
+					}
+				}
+
+				if (!L)
+				{
+					if (Rd==15)
+					{
+						armv_MOV32(r1,pc+12);
+					}
+					else
+					{
+						LoadReg(r1,Rd);
+					}
+				}
+				//Call handler
+				armv_call(GetMemOp(L, CHK_BTS(1,22,1)));
+
+				if (L)
+				{
+					if (Rd==15)
+					{
+						verify(op_flags & OP_SETS_PC);
+						StoreReg(r0,R15_ARM_NEXT);
+					}
+					else
+					{
+						StoreReg(r0,Rd);
+					}
+				}
+				
+				//Write back from AGU, if any
+				if (DoWB)
+				{
+					StoreReg(r9,Rn);
+				}
+				if (L)
+					Cycles += 4;
+				else
+					Cycles += 3;
+			}
+			break;
+
+		case VOT_MRS:
+			{
+				u32 Rd=(opcd>>12)&15;
+
+				armv_call((void*)&CPUUpdateCPSR);
+
+				if (opcd & (1<<22))
+				{
+					LoadReg(r0,17);
+				}
+				else
+				{
+					LoadReg(r0,16);
+				}
+
+				StoreReg(r0,Rd);
+			}
+			break;
+
+		case VOT_MSR:
+			{
+				u32 Rm=(opcd>>0)&15;
+
+				LoadReg(r0,Rm);
+				if (opcd & (1<<22))
+					armv_call((void*)(void (DYNACALL*)(u32))&MSR_do<1>);
+				else
+					armv_call((void*)(void (DYNACALL*)(u32))&MSR_do<0>);
+
+				if (op_flags & OP_SETS_PC)
+					armv_imm_to_reg(R15_ARM_NEXT,pc+4);
+				Cycles++;
+			}
+			break;
+		/*
+		//LDM is disabled for now
+		//Common cases of LDM/STM are converted to STR/LDR (tsz==1)
+		//Other cases are very uncommon and not worth implementing
+		case VOT_LDM:
+			{
+				//P=0, U=1, S=0, L=1, W=1
+				
+				u32 Rn=(opcd>>16)&15;
+				u32 RList=opcd&0xFFFF;
+				u32 tsz=(cpuBitsSet[RList & 255] + cpuBitsSet[(RList >> 8) & 255]);
+
+				verify(CHK_BTS(1,24,0)); //P=0
+				verify(CHK_BTS(1,23,1)); //U=1
+				verify(CHK_BTS(1,22,0)); //S=0
+				verify(CHK_BTS(1,21,1)); //W=1
+				verify(CHK_BTS(1,20,1)); //L=0
+
+				
+				//if (tsz!=1)
+				//	goto FALLBACK;
+
+				bool _W=true; //w=1
+				
+
+				if (RList & (1<<Rn))
+					_W=false;
+
+				bool _AGU=_W; // (w=1 && p=0) || p=1 (P=0)
+
+				LoadReg(r0,Rn);
+				if (_AGU)
+				{
+					ADD(r9,r0,tsz*4);
+				}
+				armv_MOV32(r1,RList);
+				armv_call((void*)(u32(DYNACALL*)(u32,u32))&DoLDM<0>);
+
+				if (_W)
+				{
+					StoreReg(r9,Rn);
+				}
+			}
+			break;
+			*/
+			
+		case VOT_Fallback:
+			{
+				//interpreter fallback
+
+				// Let the interpreter count cycles
+				Cycles -= 6;
+
+				//arm_single_op needs PC+4 on r15
+				//TODO: only write it if needed -> Probably not worth the code, very few fallbacks now...
+				armv_imm_to_reg(15,pc+8);
+
+				//For cond branch, MSR
+				if (op_flags & OP_SETS_PC)
+					armv_imm_to_reg(R15_ARM_NEXT,pc+4);
+
+				armv_intpr(opcd);
+			}
+			break;
+
+		default:
+			die("can't happen\n");
+		}
+
+		//Branch ?
+		if (op_flags & OP_SETS_PC)
+		{
+			arm_printf("ARM: %06X: Block End %d\n",pc,ops);
+
+			break;
+		}
+
+		//block size limit ?
+		if (ops>32)
+		{
+			arm_printf("ARM: %06X: Block split %d\n",pc,ops);
+
+			armv_imm_to_reg(R15_ARM_NEXT,pc+4);
+			break;
+		}
+		
+		//Goto next opcode
+		pc+=4;
+	}
+
+	armv_end((void*)rv,Cycles);
 }
+
+void FlushCache()
+{
+	icPtr=ICache;
+	for (u32 i = 0; i < ARRAY_SIZE(EntryPoints); i++)
+		EntryPoints[i] = (void*)&arm_compilecode;
 }
-#endif	// FEAT_AREC != DYNAREC_NONE
 
+void armt_init()
+{
+	InitHash();
+
+	//align to next page ..
+	ICache = (u8*)(((unat)ARM7_TCB+4095)& ~4095);
+
+#ifdef TARGET_IPHONE
+	//Can't just mprotect on iOS
+	munmap(ICache, ICacheSize);
+	ICache = (u8*)mmap(ICache, ICacheSize, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_FIXED | MAP_PRIVATE | MAP_ANON, 0, 0);
+#endif
+
+	mem_region_set_exec(ICache, ICacheSize);
+
+#ifdef TARGET_IPHONE
+	memset((u8*)mmap(ICache, ICacheSize, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_FIXED | MAP_PRIVATE | MAP_ANON, 0, 0),0xFF,ICacheSize);
+#else
+	memset(ICache,0xFF,ICacheSize);
+#endif
+
+	icPtr=ICache;
+}
+
+
+#endif	// FEAT_AREC != DYNAREC_NONE
diff --git a/core/hw/arm7/arm7.h b/core/hw/arm7/arm7.h
index f0cf597..726bd05 100644
--- a/core/hw/arm7/arm7.h
+++ b/core/hw/arm7/arm7.h
@@ -1,20 +1,13 @@
 #pragma once
 #include "types.h"
 
-namespace aicaarm {
+void arm_Init();
+void arm_Reset();
+void arm_Run(u32 samples);
+void arm_SetEnabled(bool enabled);
 
-void init();
-void reset();
-void run(u32 samples);
-void enable(bool enabled);
-// Called when the arm interrupts the SH4 to make sure it has enough cycles to finish what it's doing.
-void avoidRaceCondition();
-}
-
-enum Arm7Reg
+enum
 {
-	RN_LR		 = 14,
-	RN_PC		 = 15,
 	RN_CPSR      = 16,
 	RN_SPSR      = 17,
 
@@ -44,7 +37,6 @@ enum Arm7Reg
 	R15_ARM_NEXT = 46,
 	INTR_PEND    = 47,
 	CYCL_CNT     = 48,
-	RN_SCRATCH   = 49,
 
 	RN_ARM_REG_COUNT,
 };
@@ -95,10 +87,3 @@ typedef union
 
 	u32 I;
 } reg_pair;
-
-alignas(8) extern reg_pair arm_Reg[RN_ARM_REG_COUNT];
-
-#define ARM_CYCLES_PER_SAMPLE 256
-
-void CPUFiq();
-void CPUUpdateCPSR();
diff --git a/core/hw/arm7/arm7_rec.cpp b/core/hw/arm7/arm7_rec.cpp
deleted file mode 100644
index fb34c7b..0000000
--- a/core/hw/arm7/arm7_rec.cpp
+++ /dev/null
@@ -1,737 +0,0 @@
-/*
-	Copyright 2020 flyinghead
-
-	This file is part of flycast.
-
-    flycast is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 2 of the License, or
-    (at your option) any later version.
-
-    flycast is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with flycast.  If not, see <https://www.gnu.org/licenses/>.
- */
-
-#include "build.h"
-
-#if	FEAT_AREC != DYNAREC_NONE
-
-#include "arm7_rec.h"
-#include "arm7.h"
-#include "hw/aica/aica_if.h"
-#include "hw/mem/_vmem.h"
-#include "arm_mem.h"
-
-#if 0
-// for debug
-#include <aarch32/disasm-aarch32.h>
-#include <iostream>
-#include <sstream>
-#endif
-
-extern bool Arm7Enabled;
-
-namespace aicaarm {
-
-#define arm_printf(...) DEBUG_LOG(AICA_ARM, __VA_ARGS__)
-
-void (*arm_compilecode)();
-arm_mainloop_t arm_mainloop;
-
-namespace recompiler {
-
-u8* icPtr;
-u8* ICache;
-void (*EntryPoints[ARAM_SIZE_MAX / 4])();
-
-#ifdef _WIN32
-alignas(4096) static u8 ARM7_TCB[ICacheSize];
-#elif HOST_OS == OS_LINUX
-
-alignas(4096) static u8 ARM7_TCB[ICacheSize] __attribute__((section(".text")));
-
-#elif HOST_OS==OS_DARWIN
-alignas(4096) static u8 ARM7_TCB[ICacheSize] __attribute__((section("__TEXT, .text")));
-#else
-#error ARM7_TCB ALLOC
-#endif
-
-#pragma pack(push,1)
-union ArmOpBits
-{
-	ArmOpBits(u32 opcode) : full(opcode) {}
-
-    struct {
-    	// immediate (str/ldr)
-    	u32 imm12:12;
-        u32 rd:4;
-		// common
-		u32 rn : 4;
-		// data processing
-		u32 set_flags : 1;
-		u32 op_type : 4;
-		//
-		u32 imm_op : 1;
-		u32 op_group : 2;
-		u32 condition : 4;
-	};
-    // Register
-    struct
-    {
-        u32 rm:4;
-        u32 shift_by_reg:1;
-        u32 shift_type:2;
-        // Shift by immediate
-        u32 shift_imm:5;
-        u32 :4;
-    };
-    // Immediate value
-    struct
-    {
-        u32 imm8:8;
-        u32 rotate:4;
-        u32 :4;
-    };
-	struct {
-		u32 :7;
-		// op2 Shift by reg
-		u32 _zero:1;
-		u32 shift_reg:4;
-		u32 :8;
-
-		// LDR/STR
-		u32 load:1;
-		u32 write_back:1;
-		u32 byte:1;
-		u32 up:1;
-		u32 pre_index:1;
-		u32 :7;
-	};
-	u32 full;
-};
-#pragma pack(pop)
-static_assert(sizeof(ArmOpBits) == sizeof(u32), "sizeof(ArmOpBits) == sizeof(u32)");
-
-static std::vector<ArmOp> block_ops;
-static u8 cpuBitsSet[256];
-
-//findfirstset -- used in LDM/STM handling
-#ifdef _MSC_VER
-#include <intrin.h>
-
-u32 findfirstset(u32 v)
-{
-	unsigned long rv;
-	_BitScanForward(&rv,v);
-	return rv+1;
-}
-#else
-#define findfirstset __builtin_ffs
-#endif
-
-static ArmOp decodeArmOp(u32 opcode, u32 arm_pc)
-{
-	ArmOpBits bits(opcode);
-
-	ArmOp op;
-	op.condition = (ArmOp::Condition)bits.condition;
-	if (op.condition == ArmOp::UC)
-	{
-		//NV condition means VFP on newer cores, let interpreter handle it...
-		op.op_type = ArmOp::FALLBACK;
-		op.arg[0] = ArmOp::Operand(opcode);
-		return op;
-	}
-	if (op.condition != ArmOp::AL)
-		op.flags |= ArmOp::OP_READS_FLAGS;
-
-	switch (bits.op_group)
-	{
-	case 0:	// data processing, Multiply, Swap
-		// disambiguate
-		if ((bits.op_type & 4) == 0 && bits.imm_op == 0 && bits.shift_by_reg && bits._zero != 0)
-		{
-			// MUL, MLA or SWP
-			op.op_type = ArmOp::FALLBACK;
-			op.arg[0] = ArmOp::Operand(opcode);
-			op.cycles = 0;
-			return op;
-		}
-		if (bits.op_type >= (u32)ArmOp::TST && bits.op_type <= ArmOp::CMN && bits.set_flags == 0)
-		{
-			// MSR, MRS
-			op.spsr = bits.op_type & 2;
-			if ((bits.full & 0x0FBF0FFF) == 0x010F0000)
-			{
-				op.op_type = ArmOp::MRS;
-				op.rd = ArmOp::Operand((Arm7Reg)bits.rd);
-				verify(bits.rd != 15);
-			}
-			else if ((bits.full & 0x0FBFFFF0) == 0x0129F000)
-			{
-				op.op_type = ArmOp::MSR;
-				op.arg[0] = ArmOp::Operand((Arm7Reg)bits.rm);
-				op.cycles++;
-			}
-			else if ((bits.full & 0x0DBFF000) == 0x0128F000)
-			{
-				op.op_type = ArmOp::MSR;
-				if (bits.imm_op == 0)
-				{
-					// source is reg
-					op.arg[0] = ArmOp::Operand((Arm7Reg)bits.rm);
-					verify(bits.rm != 15);
-				}
-				else
-				{
-					u32 rotate = bits.rotate * 2;
-					op.arg[0] = ArmOp::Operand((bits.imm8 >> rotate) | (bits.imm8 << (32 - rotate)));
-				}
-			}
-			else
-			{
-				// Unsupported op
-				op.op_type = ArmOp::MOV;
-				op.condition = ArmOp::AL;
-				op.flags = 0;
-				op.rd = ArmOp::Operand((Arm7Reg)0);
-				op.arg[0] = op.rd;
-			}
-			return op;
-		}
-		{
-			op.op_type = (ArmOp::OpType)bits.op_type;
-			if (!op.isCompOp())
-				op.rd = ArmOp::Operand((Arm7Reg)bits.rd);
-			int argidx = 0;
-			if (op.op_type != ArmOp::MOV && op.op_type != ArmOp::MVN)
-			{
-				op.arg[0] = ArmOp::Operand((Arm7Reg)bits.rn);
-				if (op.arg[0].getReg().armreg == RN_PC)
-					op.arg[0] = ArmOp::Operand(arm_pc + (!bits.imm_op && bits.shift_by_reg ? 12 : 8));
-				argidx++;
-			}
-			if (bits.set_flags)
-				op.flags |= ArmOp::OP_SETS_FLAGS;
-			if (bits.imm_op)
-			{
-				u32 rotate = bits.rotate * 2;
-				op.arg[argidx] = ArmOp::Operand((bits.imm8 >> rotate) | (bits.imm8 << (32 - rotate)));
-			}
-			else
-			{
-				op.arg[argidx] = ArmOp::Operand((Arm7Reg)bits.rm);
-				op.arg[argidx].shift_type = (ArmOp::ShiftOp)bits.shift_type;
-				op.arg[argidx].shift_imm = bits.shift_by_reg == 0;
-				if (op.arg[argidx].shift_imm)
-				{
-					op.arg[argidx].shift_value = bits.shift_imm;
-					if (op.arg[argidx].shift_type == ArmOp::RRX && op.arg[argidx].shift_value == 0)
-						op.flags |= ArmOp::OP_READS_FLAGS;
-				}
-				else
-				{
-					op.arg[argidx].shift_reg = ArmOp::Register((Arm7Reg)bits.shift_reg);
-				}
-				// Compute pc-relative addresses
-				if (op.arg[argidx].getReg().armreg == RN_PC)
-				{
-					if (op.arg[argidx].shift_imm && !((op.flags & ArmOp::OP_SETS_FLAGS) && op.isLogicalOp()) && op.arg[argidx].shift_type != ArmOp::ROR)
-					{
-
-						const u32 next_pc = arm_pc + 8;
-						switch (op.arg[argidx].shift_type)
-						{
-						case ArmOp::LSL:
-							op.arg[argidx] = ArmOp::Operand(next_pc << op.arg[argidx].shift_value);
-							break;
-						case ArmOp::LSR:
-							op.arg[argidx] = ArmOp::Operand(next_pc >> op.arg[argidx].shift_value);
-							break;
-						case ArmOp::ASR:
-							op.arg[argidx] = ArmOp::Operand((int)next_pc >> op.arg[argidx].shift_value);
-							break;
-						default:
-							break;
-						}
-					}
-					else
-					{
-						op.arg[argidx].setImmediate(arm_pc + (op.arg[argidx].shift_imm ? 8 : 12));
-					}
-				}
-			}
-			if (op.rd.isReg() && op.rd.getReg().armreg == RN_PC)
-			{
-				if (op.op_type == ArmOp::MOV && op.arg[0].isReg() && !bits.set_flags && !op.arg[0].isShifted())
-				{
-					// MOVcc pc, rn -> B
-					op.op_type = ArmOp::B;
-					op.flags |= ArmOp::OP_SETS_PC;
-					op.rd = ArmOp::Operand();
-					return op;
-				}
-				if (op.condition != ArmOp::AL || (op.flags & ArmOp::OP_SETS_FLAGS))
-				{
-					// TODO no support for conditional/setflags ops that set pc except the case above
-					op.op_type = ArmOp::FALLBACK;
-					op.arg[0] = ArmOp::Operand(opcode);
-					op.arg[1] = ArmOp::Operand();
-					op.arg[2] = ArmOp::Operand();
-					op.rd = ArmOp::Operand();
-					op.cycles = 0;
-				}
-				else
-					op.rd.getReg().armreg = R15_ARM_NEXT;
-				op.flags |= ArmOp::OP_SETS_PC;
-			}
-			if (op.op_type == ArmOp::ADC || op.op_type == ArmOp::SBC || op.op_type == ArmOp::RSC)
-				op.flags |= ArmOp::OP_READS_FLAGS;
-		}
-		break;
-
-	case 1: // LDR/STR
-		{
-			op.add_offset = bits.up;
-			op.byte_xfer = bits.byte;
-			op.pre_index = bits.pre_index;
-			op.write_back = (bits.write_back || !bits.pre_index) && bits.rd != bits.rn && (bits.imm_op != 0 || bits.imm12 != 0);
-			if (bits.load)
-			{
-				op.op_type = ArmOp::LDR;
-				op.rd = ArmOp::Operand((Arm7Reg)bits.rd);
-				if (op.rd.getReg().armreg == RN_PC)			// LDR w/ rd=pc
-				{
-					op.flags |= ArmOp::OP_SETS_PC;
-					if (op.condition != ArmOp::AL)
-					{
-						// TODO no support for conditional ops
-						op.op_type = ArmOp::FALLBACK;
-						op.arg[0] = ArmOp::Operand(opcode);
-						op.cycles = 0;
-						return op;
-					}
-					op.rd.setReg(R15_ARM_NEXT);
-				}
-				op.cycles += 4;
-			}
-			else
-			{
-				op.op_type = ArmOp::STR;
-				op.arg[2] = ArmOp::Operand((Arm7Reg)bits.rd);
-				if (op.arg[2].getReg().armreg == RN_PC)
-					op.arg[2] = ArmOp::Operand(arm_pc + 12);
-				op.cycles += 3;
-			}
-			op.arg[0] = ArmOp::Operand((Arm7Reg)bits.rn);
-			if (op.arg[0].getReg().armreg == RN_PC && op.write_back)
-			{
-				// LDR/STR w pc-based offset and write-back
-				op.flags |= ArmOp::OP_SETS_PC;
-				// TODO not supported
-				op.op_type = ArmOp::FALLBACK;
-				op.arg[0] = ArmOp::Operand(opcode);
-				op.arg[1] = ArmOp::Operand();
-				op.arg[2] = ArmOp::Operand();
-				op.cycles = 0;
-				return op;
-			}
-			if (bits.imm_op == 0)
-			{
-				// Immediate offset
-				if (op.arg[0].getReg().armreg == RN_PC)
-					// Compute pc-relative address
-					op.arg[0] = ArmOp::Operand(arm_pc + 8 + (op.add_offset ? (int)bits.imm12 : -(int)bits.imm12));
-				else
-					op.arg[1] = ArmOp::Operand(bits.imm12);
-			}
-			else
-			{
-				// Offset by register, optionally shifted
-				if (op.arg[0].getReg().armreg == RN_PC)
-					op.arg[0] = ArmOp::Operand(arm_pc + 8);
-				op.arg[1] = ArmOp::Operand((Arm7Reg)bits.rm);
-				op.arg[1].shift_type = (ArmOp::ShiftOp)bits.shift_type;
-				op.arg[1].shift_imm = true;
-				op.arg[1].shift_value = bits.shift_imm;
-				if (op.arg[1].getReg().armreg == RN_PC)
-				{
-					verify(op.arg[1].shift_value == 0 && op.arg[1].shift_type == ArmOp::LSL);
-					op.arg[1] = ArmOp::Operand(arm_pc + 8);
-				}
-				if (op.arg[1].shift_type == ArmOp::RRX && op.arg[1].shift_value == 0)
-					op.flags |= ArmOp::OP_READS_FLAGS;
-			}
-		}
-		break;
-
-	case 2:	// LDM/STM and B,BL
-		if (bits.imm_op)
-		{
-			// B, BL
-			op.op_type = bits.op_type & 8 ? ArmOp::BL : ArmOp::B;	// L bit
-			op.arg[0] = ArmOp::Operand(arm_pc + 8 + (((int)(opcode & 0xffffff) << 8) >> 6));
-			op.flags |= ArmOp::OP_SETS_PC;
-			op.cycles += 3;
-		}
-		else
-		{
-			// LDM/STM
-			u32 reg_list = opcode & 0xffff;
-			// one register selected and no PSR
-			if (!(opcode & (1 << 22)) && cpuBitsSet[reg_list & 255] + cpuBitsSet[(reg_list >> 8) & 255] == 1)
-			{
-				if (opcode & (1 << 20))
-				{
-					// LDM
-					//One register xfered
-					//Can be rewriten as normal mem opcode ..
-					ArmOpBits newbits(0x04000000 | (opcode & 0xf0000000));
-
-					//Imm offset
-					//opcd |= 0<<25;
-					//Post incr
-					newbits.pre_index = bits.pre_index;
-					//Up/Dn
-					newbits.up = bits.up;
-					//Word/Byte
-					//newbits.byte = 0;
-					//Write back (must be 0 for post-incr)
-					newbits.write_back = bits.write_back & bits.pre_index;
-					//Load
-					newbits.load = 1;
-
-					//Rn
-					newbits.rn = bits.rn;
-
-					//Rd
-					newbits.rd = findfirstset(reg_list) - 1;
-
-					//Offset
-					newbits.full |= 4;
-
-					arm_printf("ARM: MEM TFX R %08X -> %08X", opcode, newbits.full);
-
-					return decodeArmOp(newbits.full, arm_pc);
-				}
-				//STM common case
-				else
-				{
-					ArmOpBits newbits(0x04000000 | (opcode & 0xf0000000));
-
-					//Imm offset
-					//opcd |= 0<<25;
-					//Post incr
-					newbits.pre_index = bits.pre_index;
-					//Up/Dn
-					newbits.up = bits.up;
-					//Word/Byte
-					//newbits.byte = 0;
-					//Write back (must be 0 for PI)
-					newbits.write_back = bits.pre_index;
-					//Load
-					newbits.load = 0;
-
-					//Rn
-					newbits.rn = bits.rn;
-
-					//Rd
-					newbits.rd = findfirstset(reg_list) - 1;
-
-					//Offset
-					newbits.full |= 4;
-
-					arm_printf("ARM: MEM TFX W %08X -> %08X", opcode, newbits.full);
-
-					return decodeArmOp(newbits.full, arm_pc);
-				}
-			}
-			op.op_type = ArmOp::FALLBACK;
-			op.arg[0] = ArmOp::Operand(opcode);
-			op.cycles = 0;
-
-			if ((opcode & 0x8000) && bits.load)	// LDM w/ pc
-				op.flags |= ArmOp::OP_SETS_PC;
-		}
-		break;
-
-	case 3: // coproc, SWI
-		op.op_type = ArmOp::FALLBACK;
-		op.arg[0] = ArmOp::Operand(opcode);
-		op.cycles = 0;
-		if (bits.imm_op == 1 && (bits.op_type & 8)) // SWI
-			op.flags |= ArmOp::OP_SETS_PC;
-		break;
-	}
-
-	return op;
-}
-
-static void block_ssa_pass()
-{
-	std::array<u32, RN_ARM_REG_COUNT> versions{};
-	for (auto it = block_ops.begin(); it != block_ops.end(); it++)
-	{
-		if (it->op_type == ArmOp::FALLBACK)
-			for (auto& v : versions)
-				v++;
-		else
-		{
-			if ((it->op_type == ArmOp::STR || it->op_type == ArmOp::LDR) && it->write_back)
-			{
-				// Extract add/sub operation from STR/LDR
-				if (it->op_type == ArmOp::LDR && !it->pre_index && it->arg[1].isReg()
-						&& it->arg[1].getReg().armreg == it->rd.getReg().armreg)
-				{
-					// Edge case where the offset reg is the target register but its value before the op
-					// must be used in post-increment/decrement
-					// Thus we save its value in a scratch register.
-					ArmOp newop(ArmOp::MOV, it->condition);
-					newop.rd = ArmOp::Operand(RN_SCRATCH);
-					newop.arg[0] = ArmOp::Operand(it->rd);
-					// Insert before
-					it = block_ops.insert(it, newop);
-					it++;
-					ArmOp newop2(it->add_offset ? ArmOp::ADD : ArmOp::SUB, it->condition);
-					newop2.rd = ArmOp::Operand(it->arg[0]);
-					newop2.arg[0] = newop2.rd;
-					newop2.arg[1] = it->arg[1];
-					newop2.arg[1].setReg(RN_SCRATCH);
-					if (it->arg[1].shift_type == ArmOp::RRX && it->arg[1].shift_value == 0)
-						newop2.flags |= ArmOp::OP_READS_FLAGS;
-					it->flags &= ~ArmOp::OP_READS_FLAGS;
-					it->write_back = false;
-					it->arg[1] = ArmOp::Operand();
-					// Insert after
-					it = block_ops.insert(it + 1, newop2);
-					it--;
-					it--;
-				}
-				else
-				{
-					ArmOp newop(it->add_offset ? ArmOp::ADD : ArmOp::SUB, it->condition);
-					newop.rd = ArmOp::Operand(it->arg[0]);
-					newop.arg[0] = newop.rd;
-					newop.arg[1] = it->arg[1];
-					if (it->arg[1].shift_type == ArmOp::RRX && it->arg[1].shift_value == 0)
-						newop.flags |= ArmOp::OP_READS_FLAGS;
-					it->flags &= ~ArmOp::OP_READS_FLAGS;
-					it->write_back = false;
-					it->arg[1] = ArmOp::Operand();
-					if (it->pre_index)
-						// Insert before
-						it = block_ops.insert(it, newop);
-					else
-					{
-						// Insert after
-						it = block_ops.insert(it + 1, newop);
-						it--;
-					}
-				}
-			}
-			// Set versions
-			for (auto& arg : it->arg)
-			{
-				if (arg.isReg())
-					arg.getReg().version = versions[(size_t)arg.getReg().armreg];
-				if (!arg.shift_imm)
-					arg.shift_reg.version = versions[(size_t)arg.shift_reg.armreg];
-			}
-			if (it->rd.isReg())
-				it->rd.getReg().version = ++versions[(size_t)it->rd.getReg().armreg];
-		}
-	}
-}
-
-void compile()
-{
-	//Get the code ptr
-	void* rv = icPtr;
-
-	//setup local pc counter
-	u32 pc = arm_Reg[R15_ARM_NEXT].I;
-
-	//update the block table
-	// Note that we mask with the max aica size (8 MB), which is
-	// also the size of the EntryPoints table. This way the dynarec
-	// main loop doesn't have to worry about the actual aica
-	// ram size. The aica ram always wraps to 8 MB anyway.
-	EntryPoints[(pc & (ARAM_SIZE_MAX - 1)) / 4] = (void (*)())rv;
-
-	block_ops.clear();
-
-	u32 cycles = 0;
-
-	arm_printf("ARM7 Block %x", pc);
-	//the ops counter is used to terminate the block (max op count for a single block is 32 currently)
-	//We don't want too long blocks for timing accuracy
-	for (u32 ops = 0; ops < 32; ops++)
-	{
-		//Read opcode ...
-		u32 opcd = *(u32*)&aica_ram[pc & ARAM_MASK];
-
-#if 0
-		std::ostringstream ostr;
-		vixl::aarch32::Disassembler disassembler(ostr, pc);
-		disassembler.DecodeA32(opcd);
-		arm_printf("%s", ostr.str().c_str());
-#endif
-
-		ArmOp last_op = decodeArmOp(opcd, pc);
-		cycles += last_op.cycles;
-
-		//Goto next opcode
-		pc += 4;
-
-		if (opcd != 0)	// andeq r0, r0, r0 -> NOP
-		{				// ARAM is filled with these at start up
-
-			if (last_op.op_type == ArmOp::FALLBACK)
-			{
-				// Interpreter needs pc + 8 in r15
-				ArmOp armop(ArmOp::MOV, ArmOp::AL);
-				armop.rd = ArmOp::Operand(RN_PC);
-				armop.arg[0] = ArmOp::Operand(pc + 4);
-				block_ops.push_back(armop);
-			}
-			//Branch ?
-			if (last_op.flags & ArmOp::OP_SETS_PC)
-			{
-				if (last_op.condition != ArmOp::AL)
-				{
-					// insert a "mov armNextPC, pc + 4" before the jump if not taken
-					ArmOp armop(ArmOp::MOV, ArmOp::AL);
-					armop.rd = ArmOp::Operand(R15_ARM_NEXT);
-					armop.arg[0] = ArmOp::Operand(pc);
-					block_ops.push_back(armop);
-				}
-				if (last_op.op_type == ArmOp::BL)
-				{
-					// Save pc+4 into r14
-					ArmOp armop(ArmOp::MOV, last_op.condition);
-					armop.rd = ArmOp::Operand(RN_LR);
-					armop.arg[0] = ArmOp::Operand(pc);
-					block_ops.push_back(armop);
-				}
-				block_ops.push_back(last_op);
-				arm_printf("ARM: %06X: Block End %d", pc, ops);
-				break;
-			}
-			block_ops.push_back(last_op);
-		}
-
-		//block size limit ?
-		if (ops == 31)
-		{
-			// Update armNextPC
-			ArmOp armop(ArmOp::MOV, ArmOp::AL);
-			armop.rd = ArmOp::Operand(R15_ARM_NEXT);
-			armop.arg[0] = ArmOp::Operand(pc);
-			block_ops.push_back(armop);
-			arm_printf("ARM: %06X: Block split", pc);
-		}
-	}
-
-	block_ssa_pass();
-
-	arm7backend_compile(block_ops, cycles);
-
-	arm_printf("arm7rec_compile done: %p,%p", rv, icPtr);
-}
-
-void flush()
-{
-	icPtr = ICache;
-	arm7backend_flush();
-	verify(arm_compilecode != nullptr);
-	for (u32 i = 0; i < ARRAY_SIZE(EntryPoints); i++)
-		EntryPoints[i] = arm_compilecode;
-}
-
-void init()
-{
-	if (!vmem_platform_prepare_jit_block(ARM7_TCB, ICacheSize, (void**)&ICache))
-		die("vmem_platform_prepare_jit_block failed");
-
-	icPtr = ICache;
-
-	for (int i = 0; i < 256; i++)
-	{
-		int count = 0;
-		for (int j = 0; j < 8; j++)
-			if (i & (1 << j))
-				count++;
-
-		cpuBitsSet[i] = count;
-	}
-}
-
-template <bool Load, bool Byte>
-u32 DYNACALL DoMemOp(u32 addr,u32 data)
-{
-	u32 rv=0;
-
-	if (Load)
-	{
-		if (Byte)
-			rv=arm_ReadMem8(addr);
-		else
-			rv=arm_ReadMem32(addr);
-	}
-	else
-	{
-		if (Byte)
-			arm_WriteMem8(addr,data);
-		else
-			arm_WriteMem32(addr,data);
-	}
-
-	return rv;
-}
-
-void *getMemOp(bool Load, bool Byte)
-{
-	if (Load)
-	{
-		if (Byte)
-			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<true,true>;
-		else
-			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<true,false>;
-	}
-	else
-	{
-		if (Byte)
-			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<false,true>;
-		else
-			return (void*)(u32(DYNACALL*)(u32,u32))&DoMemOp<false,false>;
-	}
-}
-
-} // recompiler ns
-// Run a timeslice of arm7
-
-void run(u32 samples)
-{
-	for (u32 i = 0; i < samples; i++)
-	{
-		if (Arm7Enabled)
-		{
-			arm_Reg[CYCL_CNT].I += ARM_CYCLES_PER_SAMPLE;
-			arm_mainloop(arm_Reg, recompiler::EntryPoints);
-		}
-		libAICA_TimeStep();
-	}
-}
-
-void avoidRaceCondition()
-{
-	arm_Reg[CYCL_CNT].I = std::max((int)arm_Reg[CYCL_CNT].I, 50);
-}
-
-} // aicarm ns
-#endif // FEAT_AREC != DYNAREC_NONE
diff --git a/core/hw/arm7/arm7_rec.h b/core/hw/arm7/arm7_rec.h
deleted file mode 100644
index c94b45d..0000000
--- a/core/hw/arm7/arm7_rec.h
+++ /dev/null
@@ -1,456 +0,0 @@
-/*
-	Copyright 2020 flyinghead
-
-	This file is part of flycast.
-
-    flycast is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 2 of the License, or
-    (at your option) any later version.
-
-    flycast is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with flycast.  If not, see <https://www.gnu.org/licenses/>.
- */
-#pragma once
-#include <array>
-#include "types.h"
-#include "arm7.h"
-
-namespace aicaarm {
-
-struct ArmOp
-{
-	enum OpType {
-		AND, EOR, SUB, RSB, ADD, ADC, SBC, RSC,
-		TST, TEQ, CMP, CMN, ORR, MOV, BIC, MVN,
-		LDR, STR, B, BL, MSR, MRS, FALLBACK
-	};
-	enum Condition {
-		EQ,	NE, CS, CC, MI, PL, VS, VC, HI, LS, GE, LT, GT, LE, AL, UC
-	};
-	enum ShiftOp {
-		LSL, LSR, ASR, ROR, RRX = ROR,
-	};
-	static_assert(UC == 15, "UC == 15");
-	static const u32 OP_READS_FLAGS = 1;
-	static const u32 OP_SETS_FLAGS = 4;
-	static const u32 OP_SETS_PC = 8;
-
-	ArmOp() : ArmOp(FALLBACK, AL) {}
-	ArmOp(OpType type, Condition condition) : op_type(type), condition(condition) {
-		if (condition != AL)
-			flags |= OP_READS_FLAGS;
-	}
-
-	struct Register {
-		Register() : armreg((Arm7Reg)0) {}
-		Register(Arm7Reg armreg) : armreg(armreg) {}
-		Register(Arm7Reg armreg, int version) : armreg(armreg), version(version) {}
-
-		Arm7Reg armreg;
-		int version = 0;
-	};
-	struct Operand
-	{
-		Operand() : type(none) {}
-		Operand(u32 v) : type(imm), imm_value(v) {}
-		Operand(Arm7Reg r) : type(reg_), reg_value(r, 0) {}
-		bool isImmediate() const { return type == imm; }
-		bool isReg() const { return type == reg_; }
-		bool isNone() const { return type == none; }
-
-		u32 getImmediate() const { verify(isImmediate()); return imm_value; }
-		void setImmediate(u32 v) { type = imm; imm_value = v; }
-		Register& getReg() { verify(isReg()); return reg_value; }
-		const Register& getReg() const { verify(isReg()); return reg_value; }
-		void setReg(Arm7Reg armreg, int version = 0) { type = reg_; reg_value = Register(armreg, version); }
-		bool isShifted() const { return !shift_imm || shift_value != 0 || shift_type != ArmOp::LSL; }
-
-		enum { none, reg_, imm } type;
-		union {
-			u32 imm_value;
-			Register reg_value;
-		};
-
-		// For flexible operand
-		ShiftOp shift_type = LSL;
-		bool shift_imm = true;
-		union {
-			u32 shift_value = 0;
-			Register shift_reg;
-		};
-	};
-
-	OpType op_type;
-	Operand rd;
-	std::array<Operand, 3> arg;
-	// For LDR/STR
-	bool pre_index = false;
-	bool add_offset = false;
-	bool byte_xfer = false;
-	bool write_back = false;
-	Condition condition;
-	u8 flags = 0;
-	u8 cycles = 6;
-	bool spsr = false;
-
-	bool isLogicalOp() const
-	{
-		return op_type == AND || op_type == EOR || op_type == TST || op_type == TEQ
-				|| (op_type >= ORR && op_type <= MVN);
-	}
-
-	bool isCompOp() const
-	{
-		return op_type >= TST &&  op_type <= CMN;
-	}
-
-	const std::string& conditionToString() const {
-		static const std::string labels[] = { "eq", "ne", "cs", "cc", "mi", "pl", "vs", "vc", "hi", "ls", "ge", "lt", "gt", "le", "", "uc" };
-		return labels[(int)condition];
-	}
-	std::string regToString(const Register &r) const {
-		return "r" + std::to_string((int)r.armreg) + ":" + std::to_string(r.version);
-	}
-	std::string shiftToString(ShiftOp type, u32 value) const {
-		switch (type) {
-		case LSL:
-			return "LSL";
-		case LSR:
-			return "LSR";
-		case ASR:
-			return "ASR";
-		case ROR:
-			return value == 0 ? "RRX" : "ROR";
-		default:
-			return "";
-		}
-	}
-
-	std::string operandToString(const Operand& op) const {
-		std::string s;
-		if (op.isImmediate())
-			s = "#" + std::to_string(op.getImmediate());
-		else if (op.isReg())
-			s = regToString(op.getReg());
-
-		if (op.shift_type != LSL || op.shift_value != 0)
-		{
-			s += ", " + shiftToString(op.shift_type, op.shift_value);
-			if (op.shift_imm)
-				s += " #" + std::to_string(op.shift_value);
-			else
-				s += " " + regToString(op.shift_reg);
-		}
-
-		return s;
-	}
-	std::string toString() const {
-		static const std::string labels[] = {
-			"and", "eor", "sub", "rsb", "add", "adc", "sbc", "rsc",
-			"tst", "teq", "cmp", "cmn", "orr", "mov", "bic", "mvn",
-			"ldr", "str", "b", "bl", "msr", "mrs", "(fallback)",
-		};
-		std::string s = labels[(int)op_type];
-		if (op_type <= MVN)
-		{
-			if (!isCompOp() && (flags & OP_SETS_FLAGS))
-				s += "s";
-			s += conditionToString();
-			if (rd.isReg())
-				s += " " + regToString(rd.getReg()) + ", ";
-			else
-				s += " ";
-			if (!arg[0].isNone())
-			{
-				s += operandToString(arg[0]);
-				if (!arg[1].isNone())
-				{
-					s += ", " + operandToString(arg[1]);
-					if (!arg[2].isNone())
-						s += ", " + operandToString(arg[2]);
-				}
-			}
-		}
-		else if (op_type <= STR)
-		{
-			if (byte_xfer)
-				s += "b";
-			s += conditionToString() + " ";
-			if (rd.isReg())
-				s += regToString(rd.getReg()) + ", ";
-			if (arg[2].isReg())
-				s += regToString(arg[2].getReg()) + ", ";
-			s += "[" + operandToString(arg[0]);
-			if (!pre_index)
-				s += "]";
-			if (!arg[1].isNone())
-				s += ", " + operandToString(arg[1]);
-			if (pre_index)
-				s += "]";
-			if (write_back)
-				s += "!";
-		}
-		else if (op_type <= BL)
-		{
-			s += conditionToString() + " " + operandToString(arg[0]);
-		}
-		else if (op_type == MSR)
-		{
-			s += conditionToString() + " CPSR, " + operandToString(arg[0]);
-		}
-		else if (op_type == MRS)
-			s += conditionToString() + " " + operandToString(rd) + ", CPSR";
-
-		return s;
-	}
-};
-
-template <int max_regs, typename T>
-class ArmRegAlloc
-{
-	struct RegAlloc {
-		int host_reg = -1;
-		u16 version = 0;
-		bool dirty = false;
-		bool temporary = false;
-	};
-	std::array<RegAlloc, RN_ARM_REG_COUNT> allocs;
-	std::vector<int> host_regs;
-	const std::vector<ArmOp>& block_ops;
-
-	void allocReg(const ArmOp::Register& reg, bool write, bool temporary, u32 opidx)
-	{
-		RegAlloc& alloc = allocs[(int)reg.armreg];
-		if (alloc.host_reg == -1 || (alloc.version != reg.version && !write))
-		{
-			if (host_regs.empty())
-			{
-				// Need to flush a reg
-				Arm7Reg bestReg = (Arm7Reg)-1;
-				int bestRegUse = -1;
-				for (u32 i = 0; i < allocs.size(); i++)
-				{
-					auto& alloc = allocs[i];
-					if (alloc.host_reg == -1)
-						continue;
-					if (!alloc.dirty)
-					{
-						int nextUse_ = nextUse((Arm7Reg)i, alloc.version, opidx);
-						if (nextUse_ == -1)
-						{
-							host_regs.push_back(alloc.host_reg);
-							alloc.host_reg = -1;
-							break;
-						}
-						if (nextUse_ != (int)opidx && nextUse_ > bestRegUse)
-						{
-							bestRegUse = nextUse_;
-							bestReg = (Arm7Reg)i;
-						}
-					}
-				}
-				if (host_regs.empty())
-				{
-					if (bestReg == (Arm7Reg)-1)
-					{
-						for (u32 i = 0; i < allocs.size(); i++)
-						{
-							auto& alloc = allocs[i];
-							if (alloc.host_reg == -1)
-								continue;
-							int nextUse_ = nextUse((Arm7Reg)i, alloc.version, opidx);
-							if (nextUse_ == -1)
-							{
-								bestReg = (Arm7Reg)i;
-								break;
-							}
-							if (nextUse_ != (int)opidx && nextUse_ > bestRegUse)
-							{
-								bestRegUse = nextUse_;
-								bestReg = (Arm7Reg)i;
-							}
-						}
-						verify(bestReg != (Arm7Reg)-1);
-						DEBUG_LOG(AICA_ARM, "Flushing dirty register r%d", bestReg);
-					}
-					flushReg(allocs[bestReg]);
-				}
-				verify(!host_regs.empty());
-			}
-			alloc.host_reg = host_regs.back();
-			host_regs.pop_back();
-			alloc.version = reg.version;
-			alloc.dirty = write;
-			alloc.temporary = temporary;
-			if (!write)
-				static_cast<T*>(this)->LoadReg(alloc.host_reg, reg.armreg);
-		}
-		if (write)
-		{
-			alloc.dirty = true;
-			alloc.version = reg.version;
-			alloc.temporary = temporary;
-		}
-	}
-
-	bool needsWriteback(const ArmOp::Register& reg, u32 opidx)
-	{
-		for (auto it = block_ops.begin() + opidx; it != block_ops.end(); it++)
-		{
-			if (it->op_type == ArmOp::FALLBACK)
-				// assume the value is being used
-				return true;
-			if (it->rd.isReg() && it->rd.getReg().armreg == reg.armreg)
-			{
-				if (it->condition == ArmOp::AL)
-					// register is overwritten so it's not used
-					return false;
-				else
-					// might be overwritten but we don't know so write it back
-					return true;
-			}
-		}
-		// assume the value will be used
-		return true;
-	}
-
-	// Returns the index of the next op that uses the given reg version.
-	// returns -1 if not used in the remainder of the block or if a fallback is found
-	int nextUse(Arm7Reg reg, int version, u32 opidx)
-	{
-		auto get_index_or_max = [version](const ArmOp::Register& opreg, int idx) {
-			if (opreg.version == version)
-				return idx;
-			else
-				return -1;
-		};
-		for (auto it = block_ops.begin() + opidx; it != block_ops.end(); it++, opidx++)
-		{
-			if (it->op_type == ArmOp::FALLBACK)
-				return -1;
-			for (const auto& arg : it->arg)
-			{
-				if (arg.isReg() && arg.getReg().armreg == reg)
-					return get_index_or_max(arg.getReg(), opidx);
-				if (!arg.shift_imm && arg.shift_reg.armreg == reg)
-					return get_index_or_max(arg.shift_reg, opidx);
-			}
-			if (it->rd.isReg() && it->rd.getReg().armreg == reg)
-				return -1;
-		}
-		return -1;
-	}
-
-	void flushReg(RegAlloc& alloc)
-	{
-		if (alloc.dirty)
-		{
-			static_cast<T*>(this)->StoreReg(alloc.host_reg, (Arm7Reg)(&alloc - &allocs.front()));
-			alloc.dirty = false;
-		}
-		host_regs.push_back(alloc.host_reg);
-		alloc.host_reg = -1;
-	}
-
-	void flushAllRegs()
-	{
-		for (auto& alloc : allocs)
-			if (alloc.host_reg != -1)
-				flushReg(alloc);
-	}
-
-public:
-	ArmRegAlloc(const std::vector<ArmOp>& block_ops) : block_ops(block_ops) {
-		host_regs.clear();
-		for (int i = 0; i < max_regs; i++)
-			host_regs.push_back(i);
-	}
-
-	void load(u32 opidx)
-	{
-		const ArmOp& op = block_ops[opidx];
-		if (op.op_type == ArmOp::FALLBACK)
-			flushAllRegs();
-		else
-		{
-			bool conditional = op.condition != ArmOp::AL;
-			for (const auto& arg : op.arg)
-			{
-				if (arg.isReg())
-					allocReg(arg.getReg(), false, conditional, opidx);
-				if (!arg.shift_imm)
-					allocReg(arg.shift_reg, false, conditional, opidx);
-			}
-			if (op.rd.isReg())
-				allocReg(op.rd.getReg(), true, conditional, opidx);
-		}
-	}
-
-	void store(u32 opidx)
-	{
-		const ArmOp& op = block_ops[opidx];
-		if (op.op_type == ArmOp::FALLBACK)
-			return;
-		if (op.condition != ArmOp::AL)
-		{
-			for (auto& alloc : allocs)
-				if (alloc.host_reg != -1 && alloc.temporary)
-					flushReg(alloc);
-		}
-		else if (op.rd.isReg() && needsWriteback(op.rd.getReg(), opidx + 1))
-		{
-			RegAlloc& alloc = allocs[(int)op.rd.getReg().armreg];
-			static_cast<T*>(this)->StoreReg(alloc.host_reg, op.rd.getReg().armreg);
-			alloc.dirty = false;
-		}
-	}
-
-protected:
-	int map(Arm7Reg r)
-	{
-		return allocs[(int)r].host_reg;
-	}
-};
-
-namespace recompiler {
-
-void init();
-void flush();
-void compile();
-void *getMemOp(bool load, bool byte);
-template<u32 Pd> void DYNACALL MSR_do(u32 v);
-void DYNACALL interpret(u32 opcode);
-
-extern u8* icPtr;
-extern u8* ICache;
-const u32 ICacheSize = 1024 * 1024 * 4;
-
-static inline void *currentCode() {
-	return icPtr;
-}
-static inline u32 spaceLeft() {
-	return ICacheSize - (icPtr - ICache);
-}
-static inline bool empty() {
-	return icPtr == ICache;
-}
-static inline void advance(u32 size) {
-	icPtr += size;
-}
-
-}
-
-void arm7backend_compile(const std::vector<ArmOp>& block_ops, u32 cycles);
-void arm7backend_flush();
-
-extern void (*arm_compilecode)();
-using arm_mainloop_t = void (*)(reg_pair *arm_regs, void (*entrypoints[])());
-extern arm_mainloop_t arm_mainloop;
-
-}
diff --git a/core/hw/arm7/arm7_rec_arm32.cpp b/core/hw/arm7/arm7_rec_arm32.cpp
deleted file mode 100644
index 4cbedc4..0000000
--- a/core/hw/arm7/arm7_rec_arm32.cpp
+++ /dev/null
@@ -1,557 +0,0 @@
-/*
-	Copyright 2020 flyinghead
-
-	This file is part of flycast.
-
-    flycast is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 2 of the License, or
-    (at your option) any later version.
-
-    flycast is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with flycast.  If not, see <https://www.gnu.org/licenses/>.
- */
-
-#include "build.h"
-
-#if HOST_CPU == CPU_ARM && FEAT_AREC != DYNAREC_NONE
-#include "arm7_rec.h"
-#include "hw/mem/_vmem.h"
-
-#define _DEVEL          1
-#define EMIT_I          aicaarm::armEmit32(I)
-#define EMIT_GET_PTR()  aicaarm::recompiler::currentCode()
-namespace aicaarm {
-    static void armEmit32(u32 emit32);
-}
-#include "arm_emitter/arm_emitter.h"
-#undef I
-using namespace ARM;
-
-namespace aicaarm {
-
-static void (*arm_dispatch)();
-
-static void loadReg(eReg host_reg, Arm7Reg guest_reg, ArmOp::Condition cc = ArmOp::AL)
-{
-	LDR(host_reg, r8, (u8*)&arm_Reg[guest_reg].I - (u8*)&arm_Reg[0].I, ARM::Offset, (ARM::ConditionCode)cc);
-}
-
-static void storeReg(eReg host_reg, Arm7Reg guest_reg, ArmOp::Condition cc = ArmOp::AL)
-{
-	STR(host_reg, r8, (u8*)&arm_Reg[guest_reg].I - (u8*)&arm_Reg[0].I, ARM::Offset, (ARM::ConditionCode)cc);
-}
-
-static const std::array<eReg, 6> alloc_regs{
-	r5, r6, r7, r9, r10, r11
-};
-
-class Arm32ArmRegAlloc : public ArmRegAlloc<alloc_regs.size(), Arm32ArmRegAlloc>
-{
-	using super = ArmRegAlloc<alloc_regs.size(), Arm32ArmRegAlloc>;
-
-	void LoadReg(int host_reg, Arm7Reg armreg, ArmOp::Condition cc = ArmOp::AL)
-	{
-		// printf("LoadReg R%d <- r%d\n", host_reg, armreg);
-		loadReg(getReg(host_reg), armreg, cc);
-	}
-
-	void StoreReg(int host_reg, Arm7Reg armreg, ArmOp::Condition cc = ArmOp::AL)
-	{
-		// printf("StoreReg R%d -> r%d\n", host_reg, armreg);
-		storeReg(getReg(host_reg), armreg, cc);
-	}
-
-	static eReg getReg(int i)
-	{
-		verify(i >= 0 && (u32)i < alloc_regs.size());
-		return alloc_regs[i];
-	}
-
-public:
-	Arm32ArmRegAlloc(const std::vector<ArmOp>& block_ops)
-		: super(block_ops) {}
-
-	eReg map(Arm7Reg r)
-	{
-		int i = super::map(r);
-		return getReg(i);
-	}
-
-	friend super;
-};
-
-static void armEmit32(u32 emit32)
-{
-	if (recompiler::spaceLeft() <= 1024)
-	{
-		ERROR_LOG(AICA_ARM, "JIT buffer full: %d bytes free", recompiler::spaceLeft());
-		die("AICA ARM code buffer full");
-	}
-
-	*(u32 *)recompiler::currentCode() = emit32;
-	recompiler::advance(4);
-}
-
-static Arm32ArmRegAlloc *regalloc;
-
-static void loadFlags()
-{
-	//Load flags
-	loadReg(r3, RN_PSR_FLAGS);
-	//move them to flags register
-	MSR(0, 8, r3);
-}
-
-static void storeFlags()
-{
-	//get results from flags register
-	MRS(r3, 0);
-	//Store flags
-	storeReg(r3, RN_PSR_FLAGS);
-}
-
-static u32 *startConditional(ArmOp::Condition cc)
-{
-	if (cc == ArmOp::AL)
-		return nullptr;
-	verify(cc <= ArmOp::LE);
-	ARM::ConditionCode condition = (ARM::ConditionCode)((u32)cc ^ 1);
-	u32 *code = (u32 *)recompiler::currentCode();
-	JUMP((u32)code, condition);
-
-	return code;
-}
-
-static void endConditional(u32 *pos)
-{
-	if (pos != nullptr)
-	{
-		u32 *curpos = (u32 *)recompiler::currentCode();
-		ARM::ConditionCode condition = (ARM::ConditionCode)(*pos >> 28);
-		recompiler::icPtr = (u8 *)pos;
-		JUMP((u32)curpos, condition);
-		recompiler::icPtr = (u8 *)curpos;
-	}
-}
-
-static eReg getOperand(ArmOp::Operand arg, eReg scratch_reg)
-{
-	if (arg.isNone())
-		return (eReg)-1;
-	else if (arg.isImmediate())
-	{
-		if (is_i8r4(arg.getImmediate()))
-			MOV(scratch_reg, arg.getImmediate());
-		else
-			MOV32(scratch_reg, arg.getImmediate());
-	}
-	else if (arg.isReg())
-	{
-		if (!arg.isShifted())
-			return regalloc->map(arg.getReg().armreg);
-		MOV(scratch_reg, regalloc->map(arg.getReg().armreg));
-	}
-
-	if (!arg.shift_imm)
-	{
-		// Shift by register
-		eReg shift_reg = regalloc->map(arg.shift_reg.armreg);
-		MOV(scratch_reg, scratch_reg, (ARM::ShiftOp)arg.shift_type, shift_reg);
-	}
-	else
-	{
-		// Shift by immediate
-		if (arg.shift_value != 0 || arg.shift_type != ArmOp::LSL)	// LSL 0 is a no-op
-			MOV(scratch_reg, scratch_reg, (ARM::ShiftOp)arg.shift_type, arg.shift_value);
-	}
-
-	return scratch_reg;
-}
-
-template <void (*OpImmediate)(eReg rd, eReg rn, s32 imm8, bool S, ConditionCode cc),
-		void (*OpShiftImm)(eReg rd, eReg rn, eReg rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode cc),
-		void (*OpShiftReg)(eReg rd, eReg rn, eReg rm, ShiftOp Shift, eReg shift_reg, bool S, ConditionCode cc)>
-void emit3ArgOp(const ArmOp& op)
-{
-	eReg rn;
-	const ArmOp::Operand *op2;
-	if (op.op_type != ArmOp::MOV && op.op_type != ArmOp::MVN)
-	{
-		rn = getOperand(op.arg[0], r2);
-		op2 = &op.arg[1];
-	}
-	else
-		op2 = &op.arg[0];
-
-	eReg rd = regalloc->map(op.rd.getReg().armreg);
-
-	bool set_flags = op.flags & ArmOp::OP_SETS_FLAGS;
-	eReg rm;
-	if (op2->isImmediate())
-	{
-		if (is_i8r4(op2->getImmediate()) && op2->shift_imm)
-		{
-			OpImmediate(rd, rn, op2->getImmediate(), set_flags, CC_AL);
-			return;
-		}
-		MOV32(r0, op2->getImmediate());
-		rm = r0;
-	}
-	else if (op2->isReg())
-		rm = regalloc->map(op2->getReg().armreg);
-
-	if (op2->shift_imm)
-		OpShiftImm(rd, rn, rm, (ShiftOp)op2->shift_type, op2->shift_value, set_flags, CC_AL);
-	else
-	{
-		// Shift by reg
-		eReg shift_reg = regalloc->map(op2->shift_reg.armreg);
-		OpShiftReg(rd, rn, rm, (ShiftOp)op2->shift_type, shift_reg, set_flags, CC_AL);
-	}
-}
-
-template <void (*OpImmediate)(eReg rd, s32 imm8, bool S, ConditionCode cc),
-		void (*OpShiftImm)(eReg rd, eReg rm, ShiftOp Shift, u32 ImmShift, bool S, ConditionCode cc),
-		void (*OpShiftReg)(eReg rd, eReg rm, ShiftOp Shift, eReg shift_reg, bool S, ConditionCode cc)>
-void emit2ArgOp(const ArmOp& op)
-{
-	// Used for rd (MOV, MVN) and rn (CMP, TST, ...)
-	eReg rd;
-	const ArmOp::Operand *op2;
-	if (op.op_type != ArmOp::MOV && op.op_type != ArmOp::MVN)
-	{
-		rd = getOperand(op.arg[0], r2);
-		op2 = &op.arg[1];
-	}
-	else {
-		op2 = &op.arg[0];
-		rd = regalloc->map(op.rd.getReg().armreg);
-	}
-
-	bool set_flags = op.flags & ArmOp::OP_SETS_FLAGS;
-	eReg rm;
-	if (op2->isImmediate())
-	{
-		if (is_i8r4(op2->getImmediate()) && op2->shift_imm)
-		{
-			OpImmediate(rd, op2->getImmediate(), set_flags, CC_AL);
-			return;
-		}
-		MOV32(r0, op2->getImmediate());
-		rm = r0;
-	}
-	else if (op2->isReg())
-		rm = regalloc->map(op2->getReg().armreg);
-
-	if (op2->shift_imm)
-		OpShiftImm(rd, rm, (ShiftOp)op2->shift_type, op2->shift_value, set_flags, CC_AL);
-	else
-	{
-		// Shift by reg
-		eReg shift_reg = regalloc->map(op2->shift_reg.armreg);
-		OpShiftReg(rd, rm, (ShiftOp)op2->shift_type, shift_reg, set_flags, CC_AL);
-	}
-}
-
-static void emitDataProcOp(const ArmOp& op)
-{
-	switch (op.op_type)
-	{
-	case ArmOp::AND:
-		emit3ArgOp<&AND, &AND, &AND>(op);
-		break;
-	case ArmOp::EOR:
-		emit3ArgOp<&EOR, &EOR, &EOR>(op);
-		break;
-	case ArmOp::SUB:
-		emit3ArgOp<&SUB, &SUB, &SUB>(op);
-		break;
-	case ArmOp::RSB:
-		emit3ArgOp<&RSB, &RSB, &RSB>(op);
-		break;
-	case ArmOp::ADD:
-		emit3ArgOp<&ADD, &ADD, &ADD>(op);
-		break;
-	case ArmOp::ORR:
-		emit3ArgOp<&ORR, &ORR, &ORR>(op);
-		break;
-	case ArmOp::BIC:
-		emit3ArgOp<&BIC, &BIC, &BIC>(op);
-		break;
-	case ArmOp::ADC:
-		emit3ArgOp<&ADC, &ADC, &ADC>(op);
-		break;
-	case ArmOp::SBC:
-		emit3ArgOp<&SBC, &SBC, &SBC>(op);
-		break;
-	case ArmOp::RSC:
-		emit3ArgOp<&RSC, &RSC, &RSC>(op);
-		break;
-	case ArmOp::TST:
-		emit2ArgOp<&TST, &TST, &TST>(op);
-		break;
-	case ArmOp::TEQ:
-		emit2ArgOp<&TEQ, &TEQ, &TEQ>(op);
-		break;
-	case ArmOp::CMP:
-		emit2ArgOp<&CMP, &CMP, &CMP>(op);
-		break;
-	case ArmOp::CMN:
-		emit2ArgOp<&CMN, &CMN, &CMN>(op);
-		break;
-	case ArmOp::MOV:
-		emit2ArgOp<&MOV, &MOV, &MOV>(op);
-		break;
-	case ArmOp::MVN:
-		emit2ArgOp<&MVN, &MVN, &MVN>(op);
-		break;
-	default:
-		die("invalid op");
-		break;
-	}
-}
-
-static void call(u32 addr, ARM::ConditionCode cc = ARM::CC_AL)
-{
-	storeFlags();
-	CALL(addr, cc);
-	loadFlags();
-}
-
-static void emitMemOp(const ArmOp& op)
-{
-	eReg addr_reg = getOperand(op.arg[0], r2);
-	if (op.pre_index)
-	{
-		const ArmOp::Operand& offset = op.arg[1];
-		if (offset.isReg())
-		{
-			eReg offset_reg = getOperand(offset, r3);
-			if (op.add_offset)
-				ADD(r0, addr_reg, offset_reg);
-			else
-				SUB(r0, addr_reg, offset_reg);
-			addr_reg = r0;
-		}
-		else if (offset.isImmediate() && offset.getImmediate() != 0)
-		{
-			if (is_i8r4(offset.getImmediate()))
-			{
-				if (op.add_offset)
-					ADD(r0, addr_reg, offset.getImmediate());
-				else
-					SUB(r0, addr_reg, offset.getImmediate());
-			}
-			else
-			{
-				MOV32(r0, offset.getImmediate());
-				if (op.add_offset)
-					ADD(r0, addr_reg, r0);
-				else
-					SUB(r0, addr_reg, r0);
-			}
-			addr_reg = r0;
-		}
-	}
-	if (addr_reg != r0)
-		MOV(r0, addr_reg);
-	if (op.op_type == ArmOp::STR)
-	{
-		if (op.arg[2].isImmediate())
-		{
-			if (is_i8r4(op.arg[2].getImmediate()))
-				MOV(r1, op.arg[2].getImmediate());
-			else
-				MOV32(r1, op.arg[2].getImmediate());
-		}
-		else
-			MOV(r1, regalloc->map(op.arg[2].getReg().armreg));
-	}
-
-	call((u32)recompiler::getMemOp(op.op_type == ArmOp::LDR, op.byte_xfer));
-
-	if (op.op_type == ArmOp::LDR)
-		MOV(regalloc->map(op.rd.getReg().armreg), r0);
-
-}
-
-static void emitBranch(const ArmOp& op)
-{
-	if (op.arg[0].isImmediate())
-		MOV32(r0, op.arg[0].getImmediate());
-	else
-	{
-		MOV(r0, regalloc->map(op.arg[0].getReg().armreg));
-		BIC(r0, r0, 3);
-	}
-	storeReg(r0, R15_ARM_NEXT);
-}
-
-static void emitMRS(const ArmOp& op)
-{
-	call((u32)CPUUpdateCPSR);
-
-	if (op.spsr)
-		loadReg(regalloc->map(op.rd.getReg().armreg), RN_SPSR);
-	else
-		loadReg(regalloc->map(op.rd.getReg().armreg), RN_CPSR);
-}
-
-static void emitMSR(const ArmOp& op)
-{
-	if (op.arg[0].isImmediate())
-		MOV32(r0, op.arg[0].getImmediate());
-	else
-		MOV(r0, regalloc->map(op.arg[0].getReg().armreg));
-
-	if (op.spsr)
-		call((u32)recompiler::MSR_do<1>);
-	else
-		call((u32)recompiler::MSR_do<0>);
-}
-
-static void emitFallback(const ArmOp& op)
-{
-	//Call interpreter
-	MOV32(r0, op.arg[0].getImmediate());
-	call((u32)recompiler::interpret);
-}
-
-void arm7backend_compile(const std::vector<ArmOp>& block_ops, u32 cycles)
-{
-	loadReg(r2, CYCL_CNT);
-	while (!is_i8r4(cycles))
-	{
-		SUB(r2, r2, 256);
-		cycles -= 256;
-	}
-	SUB(r2, r2, cycles);
-	storeReg(r2, CYCL_CNT);
-
-	regalloc = new Arm32ArmRegAlloc(block_ops);
-	void *codestart = recompiler::currentCode();
-
-	loadFlags();
-
-	for (u32 i = 0; i < block_ops.size(); i++)
-	{
-		const ArmOp& op = block_ops[i];
-		DEBUG_LOG(AICA_ARM, "-> %s", op.toString().c_str());
-
-		u32 *condPos = nullptr;
-
-		if (op.op_type != ArmOp::FALLBACK)
-			condPos = startConditional(op.condition);
-
-		regalloc->load(i);
-
-		if (op.op_type <= ArmOp::MVN)
-			// data processing op
-			emitDataProcOp(op);
-		else if (op.op_type <= ArmOp::STR)
-			// memory load/store
-			emitMemOp(op);
-		else if (op.op_type <= ArmOp::BL)
-			// branch
-			emitBranch(op);
-		else if (op.op_type == ArmOp::MRS)
-			emitMRS(op);
-		else if (op.op_type == ArmOp::MSR)
-			emitMSR(op);
-		else if (op.op_type == ArmOp::FALLBACK)
-			emitFallback(op);
-		else
-			die("invalid");
-
-		regalloc->store(i);
-
-		endConditional(condPos);
-	}
-	storeFlags();
-
-	JUMP((uintptr_t)arm_dispatch);
-
-	vmem_platform_flush_cache(codestart, (u8*)recompiler::currentCode() - 1,
-			codestart, (u8*)recompiler::currentCode() - 1);
-
-	delete regalloc;
-	regalloc = nullptr;
-}
-
-void arm7backend_flush()
-{
-	if (!recompiler::empty())
-	{
-		verify(arm_mainloop != nullptr);
-		verify(arm_compilecode != nullptr);
-		return;
-	}
-	void *codestart = recompiler::currentCode();
-	uintptr_t arm_exit = (uintptr_t)codestart;
-	uintptr_t arm_dofiq = (uintptr_t)codestart;
-
-	// arm_mainloop:
-	arm_mainloop = (arm_mainloop_t)codestart;
-	u32 regList = (1 << r4) | (1 << r5) | (1 << r6) | (1 << r7)
-		 | (1 << r8) | (1 << r9) | (1 << r10) | (1 << r11) | (1 << lr);
-	PUSH(regList);
-	SUB(sp, sp, 4);							// 8-byte stack alignment
-
-	MOV(r8, r0);							// load regs
-	MOV(r4, r1);							// load entry points
-
-	// arm_dispatch:
-	arm_dispatch = (void (*)())recompiler::currentCode();
-	loadReg(r3, CYCL_CNT);					// load cycle counter
-	loadReg(r0, R15_ARM_NEXT);				// load Next PC
-	loadReg(r1, INTR_PEND);					// load Interrupt
-	CMP(r3, 0);
-	u8 *exit_fixup = (u8 *)recompiler::currentCode();
-	JUMP(arm_exit, CC_LE);					// exit if counter <= 0
-	UBFX(r2, r0, 2, 21);					// assuming 8 MB address space max (23 bits)
-	CMP(r1, 0);
-	u8 *dofiq_fixup = (u8 *)recompiler::currentCode();
-	JUMP(arm_dofiq, CC_NE);					// if interrupt pending, handle it
-
-	LDR(pc, r4, r2, AddrMode::Offset, true, ShiftOp::S_LSL, 2);
-
-	// arm_dofiq:
-	arm_dofiq = (uintptr_t)recompiler::currentCode();
-	// fix up
-	u8 *icptr_save = (u8 *)recompiler::currentCode();
-	recompiler::icPtr = dofiq_fixup;
-	JUMP(arm_dofiq, CC_NE);
-	recompiler::icPtr = icptr_save;
-	// end fix up
-	CALL((uintptr_t)CPUFiq);
-	JUMP((uintptr_t)arm_dispatch);
-
-	// arm_exit:
-	arm_exit = (uintptr_t)recompiler::currentCode();
-	// fix up
-	icptr_save = (u8 *)recompiler::currentCode();
-	recompiler::icPtr = exit_fixup;
-	JUMP(arm_exit, CC_LE);
-	recompiler::icPtr = icptr_save;
-	// end fix up
-	ADD(sp, sp, 4);
-	POP(regList);
-	MOV(pc, lr);
-
-	// arm_compilecode:
-	arm_compilecode = (void (*)())recompiler::currentCode();
-	CALL((uintptr_t)recompiler::compile);
-	JUMP((uintptr_t)arm_dispatch);
-
-	vmem_platform_flush_cache(codestart, (u8*)recompiler::currentCode() - 1,
-			codestart, (u8*)recompiler::currentCode() - 1);
-}
-
-}
-#endif // HOST_CPU == CPU_ARM && FEAT_AREC != DYNAREC_NONE
diff --git a/core/hw/arm7/arm7_rec_arm64.cpp b/core/hw/arm7/arm7_rec_arm64.cpp
deleted file mode 100644
index e8b69e6..0000000
--- a/core/hw/arm7/arm7_rec_arm64.cpp
+++ /dev/null
@@ -1,717 +0,0 @@
-/*
-	Copyright 2020 flyinghead
-
-	This file is part of flycast.
-
-    flycast is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 2 of the License, or
-    (at your option) any later version.
-
-    flycast is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with flycast.  If not, see <https://www.gnu.org/licenses/>.
- */
-
-#include "build.h"
-
-#if	HOST_CPU == CPU_ARM64 && FEAT_AREC != DYNAREC_NONE
-
-#include <sstream>
-#include "arm7_rec.h"
-#include "hw/mem/_vmem.h"
-#include <aarch64/macro-assembler-aarch64.h>
-using namespace vixl::aarch64;
-//#include <aarch32/disasm-aarch32.h>
-
-namespace aicaarm {
-
-static void (*arm_dispatch)();
-
-class Arm7Compiler;
-
-#define MAX_REGS 8
-
-class AArch64ArmRegAlloc : public ArmRegAlloc<MAX_REGS, AArch64ArmRegAlloc>
-{
-	Arm7Compiler& assembler;
-
-	void LoadReg(int host_reg, Arm7Reg armreg);
-	void StoreReg(int host_reg, Arm7Reg armreg);
-
-	static const WRegister& getReg(int i)
-	{
-		static const WRegister regs[] = {
-				w19, w20, w21, w22, w23, w24, w25, w27
-		};
-		static_assert(MAX_REGS == ARRAY_SIZE(regs), "MAX_REGS == ARRAY_SIZE(regs)");
-		verify(i >= 0 && (u32)i < ARRAY_SIZE(regs));
-		return regs[i];
-	}
-
-public:
-	AArch64ArmRegAlloc(Arm7Compiler& assembler, const std::vector<ArmOp>& block_ops)
-		: ArmRegAlloc<MAX_REGS, AArch64ArmRegAlloc>(block_ops), assembler(assembler) {}
-
-	const WRegister& map(Arm7Reg r)
-	{
-		int i = ArmRegAlloc<MAX_REGS, AArch64ArmRegAlloc>::map(r);
-		return getReg(i);
-	}
-
-	friend class ArmRegAlloc<MAX_REGS, AArch64ArmRegAlloc>;
-};
-
-static MemOperand arm_reg_operand(Arm7Reg reg)
-{
-	return MemOperand(x28, (u8*)&arm_Reg[reg].I - (u8*)&arm_Reg[0].I);
-}
-
-class Arm7Compiler : public MacroAssembler
-{
-	bool logical_op_set_flags = false;
-	bool set_carry_bit = false;
-	bool set_flags = false;
-	AArch64ArmRegAlloc *regalloc = nullptr;
-
-	static const u32 N_FLAG = 1 << 31;
-	static const u32 Z_FLAG = 1 << 30;
-	static const u32 C_FLAG = 1 << 29;
-	static const u32 V_FLAG = 1 << 28;
-
-	Label *startConditional(ArmOp::Condition cc)
-	{
-		if (cc == ArmOp::AL)
-			return nullptr;
-		Label *label = new Label();
-		verify(cc <= ArmOp::LE);
-		Condition condition = (Condition)((u32)cc ^ 1);
-		B(label, condition);
-
-		return label;
-	}
-
-	void endConditional(Label *label)
-	{
-		if (label != nullptr)
-		{
-			Bind(label);
-			delete label;
-		}
-	}
-
-	void call(void *loc)
-	{
-		ptrdiff_t offset = reinterpret_cast<uintptr_t>(loc) - GetBuffer()->GetStartAddress<uintptr_t>();
-		Label function_label;
-		BindToOffset(&function_label, offset);
-		Bl(&function_label);
-	}
-
-	Operand getOperand(ArmOp::Operand arg, const Register& scratch_reg)
-	{
-		Register rm;
-		if (arg.isNone())
-			return Operand();
-		else if (arg.isImmediate())
-		{
-			if (!arg.isShifted())
-				return Operand(arg.getImmediate());
-
-			Mov(scratch_reg, arg.getImmediate());
-			rm = scratch_reg;
-		}
-		else if (arg.isReg())
-		{
-			rm = regalloc->map(arg.getReg().armreg);
-		}
-		Operand rv;
-		if (!arg.shift_imm)
-		{
-			// Shift by register
-			const Register& shift_reg = regalloc->map(arg.shift_reg.armreg);
-
-			switch (arg.shift_type)
-			{
-			case ArmOp::LSL:
-			case ArmOp::LSR:
-				verify(!scratch_reg.Is(w0));
-				Mrs(x0, NZCV);
-				Cmp(shift_reg, 32);
-				if (arg.shift_type == ArmOp::LSL)
-					Lsl(scratch_reg, rm, shift_reg);
-				else
-					Lsr(scratch_reg, rm, shift_reg);
-				Csel(scratch_reg, 0, scratch_reg, ge);			// LSL and LSR by 32 or more gives 0
-				Msr(NZCV, x0);
-				break;
-			case ArmOp::ASR:
-				verify(!scratch_reg.Is(w0));
-				Mrs(x0, NZCV);
-				Cmp(shift_reg, 32);
-				Sbfx(w13, rm, 31, 1);
-				Asr(scratch_reg, rm, shift_reg);
-				Csel(scratch_reg, w13, scratch_reg, ge);		// ASR by 32 or more gives 0 or -1 depending on operand sign
-				Msr(NZCV, x0);
-				break;
-			case ArmOp::ROR:
-				Ror(scratch_reg, rm, shift_reg);
-				break;
-			default:
-				die("Invalid shift");
-				break;
-			}
-			rv = Operand(scratch_reg);
-		}
-		else
-		{
-			// Shift by immediate
-			if (arg.shift_type != ArmOp::ROR && arg.shift_value != 0 && !logical_op_set_flags)
-			{
-				rv = Operand(rm, (Shift)arg.shift_type, arg.shift_value);
-			}
-			else if (arg.shift_value == 0)
-			{
-				if (arg.shift_type == ArmOp::LSL)
-				{
-					rv = Operand(rm);		// LSL 0 is a no-op
-				}
-				else
-				{
-					// Shift by 32
-					if (logical_op_set_flags)
-						set_carry_bit = true;
-					if (arg.shift_type == ArmOp::LSR)
-					{
-						if (logical_op_set_flags)
-							Ubfx(w14, rm, 31, 1);				// w14 = rm[31]
-						Mov(scratch_reg, 0);					// scratch = 0
-					}
-					else if (arg.shift_type == ArmOp::ASR)
-					{
-						if (logical_op_set_flags)
-							Ubfx(w14, rm, 31, 1);				// w14 = rm[31]
-						Sbfx(scratch_reg, rm, 31, 1);			// scratch = rm < 0 ? -1 : 0
-					}
-					else if (arg.shift_type == ArmOp::ROR)
-					{
-						// RRX
-						Cset(w14, cs);							// w14 = C
-						if (logical_op_set_flags)
-							Mov(w13, rm);						// save rm in case rm = scratch_reg
-						Mov(scratch_reg, Operand(rm, LSR, 1));	// scratch = rm >> 1
-						Bfi(scratch_reg, w14, 31, 1);			// scratch[31] = C
-						if (logical_op_set_flags)
-							Ubfx(w14, w13, 0, 1);				// w14 = rm[0] (new C)
-					}
-					else
-						die("Invalid shift");
-					rv = Operand(scratch_reg);
-				}
-			}
-			else
-			{
-				// Carry must be preserved or Ror shift
-				if (logical_op_set_flags)
-					set_carry_bit = true;
-				if (arg.shift_type == ArmOp::LSL)
-				{
-					Ubfx(w14, rm, 32 - arg.shift_value, 1);		// w14 = rm[lsb]
-					Lsl(scratch_reg, rm, arg.shift_value);		// scratch <<= shift
-				}
-				else
-				{
-					if (logical_op_set_flags)
-						Ubfx(w14, rm, arg.shift_value - 1, 1);	// w14 = rm[msb]
-
-					if (arg.shift_type == ArmOp::LSR)
-						Lsr(scratch_reg, rm, arg.shift_value);	// scratch >>= shift
-					else if (arg.shift_type == ArmOp::ASR)
-						Asr(scratch_reg, rm, arg.shift_value);
-					else if (arg.shift_type == ArmOp::ROR)
-						Ror(scratch_reg, rm, arg.shift_value);
-					else
-						die("Invalid shift");
-				}
-				rv = Operand(scratch_reg);
-			}
-		}
-		return rv;
-	}
-
-	const Register getRegister(const Register& scratch_reg, const Operand& op)
-	{
-		if (op.IsImmediate())
-		{
-			Mov(scratch_reg, op.GetImmediate());
-			return scratch_reg;
-		}
-		else if (op.IsPlainRegister())
-			return op.GetRegister();
-
-		switch (op.GetShift())
-		{
-		case LSL:
-			Lsl(scratch_reg, op.GetRegister(), op.GetShiftAmount());
-			break;
-		case LSR:
-			Lsr(scratch_reg, op.GetRegister(), op.GetShiftAmount());
-			break;
-		case ASR:
-			Asr(scratch_reg, op.GetRegister(), op.GetShiftAmount());
-			break;
-		case ROR:
-			Ror(scratch_reg, op.GetRegister(), op.GetShiftAmount());
-			break;
-		default:
-			die("Invalid shift");
-			break;
-		}
-		return scratch_reg;
-	}
-
-	void loadFlags()
-	{
-		//Load flags
-		Ldr(w0, arm_reg_operand(RN_PSR_FLAGS));
-		//move them to flags register
-		Msr(NZCV, x0);
-	}
-
-	void storeFlags()
-	{
-		if (!set_flags)
-			return;
-
-		//get results from flags register
-		Mrs(x1, NZCV);
-		//Store flags
-		Str(w1, arm_reg_operand(RN_PSR_FLAGS));
-	}
-
-	void emitDataProcOp(const ArmOp& op)
-	{
-		Operand arg0 = getOperand(op.arg[0], w1);
-		Register rn;
-		Operand op2;
-		if (op.op_type != ArmOp::MOV && op.op_type != ArmOp::MVN)
-		{
-			rn = getRegister(w1, arg0);
-			if (!rn.Is(w1))
-			{
-				Mov(w1, rn);
-				rn = w1;
-			}
-			op2 = getOperand(op.arg[1], w2);
-		}
-		else
-			op2 = arg0;
-		WRegister rd;
-		if (op.rd.isReg())
-			rd = regalloc->map(op.rd.getReg().armreg);
-
-		if (logical_op_set_flags)
-		{
-			// When an Operand2 constant is used with the instructions MOVS, MVNS, ANDS, ORRS, ORNS, EORS, BICS, TEQ or TST,
-			// the carry flag is updated to bit[31] of the constant,
-			// if the constant is greater than 255 and can be produced by shifting an 8-bit value.
-			if (op.arg[0].isImmediate() && op.arg[0].getImmediate() > 255)
-			{
-				set_carry_bit = true;
-				Mov(w14, (op.arg[0].getImmediate() & 0x80000000) >> 31);
-			}
-			else if (op.arg[1].isImmediate() && op.arg[1].getImmediate() > 255)
-			{
-				set_carry_bit = true;
-				Mov(w14, (op.arg[1].getImmediate() & 0x80000000) >> 31);
-			}
-			else if (!set_carry_bit)
-			{
-				// Logical ops should only affect the carry bit based on the op2 shift
-				// Here we're not shifting so the carry bit should be preserved
-				set_carry_bit = true;
-				Cset(w14, cs);
-			}
-		}
-
-		switch (op.op_type)
-		{
-		case ArmOp::AND:		// AND
-			if (set_flags)
-				Ands(rd, rn, op2);
-			else
-				And(rd, rn, op2);
-			break;
-		case 1:		// EOR
-			Eor(rd, rn, op2);
-			if (set_flags)
-				Tst(rd, rd);
-			break;
-		case 2:		// SUB
-			if (set_flags)
-				Subs(rd, rn, op2);
-			else
-				Sub(rd, rn, op2);
-			break;
-		case 3:		// RSB
-			Neg(w0, rn);
-			if (set_flags)
-				Adds(rd, w0, op2);
-			else
-				Add(rd, w0, op2);
-			break;
-		case 4:		// ADD
-			if (set_flags)
-				Adds(rd, rn, op2);
-			else
-				Add(rd, rn, op2);
-			break;
-		case 12:	// ORR
-			Orr(rd, rn, op2);
-			if (set_flags)
-				Tst(rd, rd);
-			break;
-		case 14:	// BIC
-			if (set_flags)
-				Bics(rd, rn, op2);
-			else
-				Bic(rd, rn, op2);
-			break;
-		case 5:		// ADC
-			if (set_flags)
-				Adcs(rd, rn, op2);
-			else
-				Adc(rd, rn, op2);
-			break;
-		case 6:		// SBC
-			if (set_flags)
-				Sbcs(rd, rn, op2);
-			else
-				Sbc(rd, rn, op2);
-			break;
-		case 7:		// RSC
-			Ngc(w0, rn);
-			if (set_flags)
-				Adds(rd, w0, op2);
-			else
-				Add(rd, w0, op2);
-			break;
-		case 8:		// TST
-#ifdef STRICT_MODE
-			// In armv7, TST and TEQ do not affect the V flag.
-			// This isn't the case in armv8 so we need to save
-			// and restore it.
-			// Since this is a bit complicated/slow, let's assume nobody
-			// relies on this.
-			Cset(w3, vs);
-#endif
-			Tst(rn, op2);
-#ifdef STRICT_MODE
-			Mrs(x0, NZCV);
-			Bfi(x0, x3, 28, 1);		// V is bit 28
-			Msr(NZCV, x0);
-#endif
-			break;
-		case 9:		// TEQ
-			Eor(w0, rn, op2);
-#ifdef STRICT_MODE
-			Cset(w3, vs);
-#endif
-			Tst(w0, w0);
-#ifdef STRICT_MODE
-			Mrs(x0, NZCV);
-			Bfi(x0, x3, 28, 1);		// V is bit 28
-			Msr(NZCV, x0);
-#endif
-			break;
-		case 10:	// CMP
-			Cmp(rn, op2);
-			break;
-		case 11:	// CMN
-			Cmn(rn, op2);
-			break;
-		case 13:	// MOV
-			Mov(rd, op2);
-			if (set_flags)
-				Tst(rd, rd);
-			break;
-		case 15:	// MVN
-			Mvn(rd, op2);
-			if (set_flags)
-				Tst(rd, rd);
-			break;
-		default:
-			die("invalid op");
-			break;
-		}
-		if (set_carry_bit)
-		{
-			Mrs(x0, NZCV);
-			Bfi(x0, x14, 29, 1);		// C is bit 29 in NZCV
-			Msr(NZCV, x0);
-		}
-	}
-
-	void emitMemOp(const ArmOp& op)
-	{
-		Operand arg0 = getOperand(op.arg[0], w2);
-		Register addr_reg = getRegister(w2, arg0);
-		if (!w2.Is(addr_reg))
-			Mov(w2, addr_reg);
-		if (op.pre_index)
-		{
-			const ArmOp::Operand& offset = op.arg[1];
-			Operand arg1 = getOperand(offset, w1);
-			if (!arg1.IsImmediate())
-			{
-				Register offset_reg = getRegister(w1, arg1);
-				if (op.add_offset)
-					Add(w2, w2, offset_reg);
-				else
-					Sub(w2, w2, offset_reg);
-			}
-			else if (offset.isImmediate() && offset.getImmediate() != 0)
-			{
-				if (op.add_offset)
-					Add(w2, w2, offset.getImmediate());
-				else
-					Sub(w2, w2, offset.getImmediate());
-			}
-		}
-		Mov(w0, w2);
-		if (op.op_type == ArmOp::STR)
-		{
-			if (op.arg[2].isImmediate())
-				Mov(w1, op.arg[2].getImmediate());
-			else
-				Mov(w1, regalloc->map(op.arg[2].getReg().armreg));
-		}
-
-		call(recompiler::getMemOp(op.op_type == ArmOp::LDR, op.byte_xfer));
-
-		if (op.op_type == ArmOp::LDR)
-			Mov(regalloc->map(op.rd.getReg().armreg), w0);
-	}
-
-	void emitBranch(const ArmOp& op)
-	{
-		if (op.arg[0].isImmediate())
-			Mov(w0, op.arg[0].getImmediate());
-		else
-		{
-			Mov(w0, regalloc->map(op.arg[0].getReg().armreg));
-			And(w0, w0, 0xfffffffc);
-		}
-		Str(w0, arm_reg_operand(R15_ARM_NEXT));
-	}
-
-	void emitMRS(const ArmOp& op)
-	{
-		call((void*)CPUUpdateCPSR);
-
-		if (op.spsr)
-			Ldr(regalloc->map(op.rd.getReg().armreg), arm_reg_operand(RN_SPSR));
-		else
-			Ldr(regalloc->map(op.rd.getReg().armreg), arm_reg_operand(RN_CPSR));
-	}
-
-	void emitMSR(const ArmOp& op)
-	{
-		if (op.arg[0].isImmediate())
-			Mov(w0, op.arg[0].getImmediate());
-		else
-			Mov(w0, regalloc->map(op.arg[0].getReg().armreg));
-		if (op.spsr)
-			call((void*)recompiler::MSR_do<1>);
-		else
-			call((void*)recompiler::MSR_do<0>);
-	}
-
-	void emitFallback(const ArmOp& op)
-	{
-		set_flags = false;
-		Mov(w0, op.arg[0].getImmediate());
-		call((void*)recompiler::interpret);
-	}
-
-public:
-	Arm7Compiler() : MacroAssembler((u8 *)recompiler::currentCode(), recompiler::spaceLeft()) {}
-
-	void compile(const std::vector<ArmOp>& block_ops, u32 cycles)
-	{
-		Ldr(w1, arm_reg_operand(CYCL_CNT));
-		Sub(w1, w1, cycles);
-		Str(w1, arm_reg_operand(CYCL_CNT));
-
-		regalloc = new AArch64ArmRegAlloc(*this, block_ops);
-
-		for (u32 i = 0; i < block_ops.size(); i++)
-		{
-			const ArmOp& op = block_ops[i];
-			DEBUG_LOG(AICA_ARM, "-> %s\n", op.toString().c_str());
-
-			set_flags = op.flags & ArmOp::OP_SETS_FLAGS;
-			logical_op_set_flags = op.isLogicalOp() && set_flags;
-			set_carry_bit = false;
-			bool save_v_flag = true;	// FIXME is this needed?
-
-			Label *condLabel = nullptr;
-
-			if (op.flags & (ArmOp::OP_READS_FLAGS|ArmOp::OP_SETS_FLAGS))
-				loadFlags();
-
-			if (op.op_type != ArmOp::FALLBACK)
-				condLabel = startConditional(op.condition);
-
-			regalloc->load(i);
-
-			if (op.op_type <= ArmOp::MVN)
-				// data processing op
-				emitDataProcOp(op);
-			else if (op.op_type <= ArmOp::STR)
-				// memory load/store
-				emitMemOp(op);
-			else if (op.op_type <= ArmOp::BL)
-				// branch
-				emitBranch(op);
-			else if (op.op_type == ArmOp::MRS)
-				emitMRS(op);
-			else if (op.op_type == ArmOp::MSR)
-				emitMSR(op);
-			else if (op.op_type == ArmOp::FALLBACK)
-				emitFallback(op);
-			else
-				die("invalid");
-
-			storeFlags();
-
-			regalloc->store(i);
-
-			endConditional(condLabel);
-		}
-
-		ptrdiff_t offset = reinterpret_cast<uintptr_t>(arm_dispatch) - GetBuffer()->GetStartAddress<uintptr_t>();
-		Label arm_dispatch_label;
-		BindToOffset(&arm_dispatch_label, offset);
-		B(&arm_dispatch_label);
-
-		FinalizeCode();
-		verify(GetBuffer()->GetCursorOffset() <= GetBuffer()->GetCapacity());
-		vmem_platform_flush_cache(
-				GetBuffer()->GetStartAddress<void*>(), GetBuffer()->GetEndAddress<void*>(),
-				GetBuffer()->GetStartAddress<void*>(), GetBuffer()->GetEndAddress<void*>());
-		recompiler::advance(GetBuffer()->GetSizeInBytes());
-
-#if 0
-		Instruction* instr_start = (Instruction *)codestart;
-		Instruction* instr_end = GetBuffer()->GetEndAddress<Instruction*>();
-		Decoder decoder;
-		Disassembler disasm;
-		decoder.AppendVisitor(&disasm);
-		Instruction* instr;
-		for (instr = instr_start; instr < instr_end; instr += kInstructionSize) {
-			decoder.Decode(instr);
-			DEBUG_LOG(AICA_ARM, "arm64 arec\t %p:\t%s",
-					   reinterpret_cast<void*>(instr),
-					   disasm.GetOutput());
-		}
-#endif
-		delete regalloc;
-		regalloc = nullptr;
-	}
-
-	void generateMainLoop()
-	{
-		if (!recompiler::empty())
-		{
-			verify(arm_mainloop != nullptr);
-			verify(arm_compilecode != nullptr);
-			return;
-		}
-		Label arm_dispatch_label;
-		Label arm_dofiq;
-		Label arm_exit;
-
-		// arm_compilecode:
-		arm_compilecode = GetCursorAddress<void (*)()>();
-		call((void*)recompiler::compile);
-		B(&arm_dispatch_label);
-
-		// arm_mainloop(regs, entry points)
-		arm_mainloop = GetCursorAddress<arm_mainloop_t>();
-		Stp(x25, x26, MemOperand(sp, -96, AddrMode::PreIndex));
-		Stp(x27, x28, MemOperand(sp, 16));
-		Stp(x29, x30, MemOperand(sp, 32));
-		Stp(x19, x20, MemOperand(sp, 48));
-		Stp(x21, x22, MemOperand(sp, 64));
-		Stp(x23, x24, MemOperand(sp, 80));
-
-		Mov(x28, x0);		// arm7 registers
-		Mov(x26, x1);		// lookup base
-
-		// arm_dispatch:
-		Bind(&arm_dispatch_label);
-		arm_dispatch = GetCursorAddress<void (*)()>();
-		Ldr(w3, arm_reg_operand(CYCL_CNT));			// load cycle counter
-		Ldp(w0, w1, arm_reg_operand(R15_ARM_NEXT));	// load Next PC, interrupt
-		Tbnz(w3, 31, &arm_exit);					// exit if cycle counter negative
-		Ubfx(w2, w0, 2, 21);						// w2 = pc >> 2. Note: assuming address space == 8 MB (23 bits)
-		Cbnz(w1, &arm_dofiq);						// if interrupt pending, handle it
-
-		Add(x2, x26, Operand(x2, Shift::LSL, 3));	// x2 = EntryPoints + pc << 1
-		Ldr(x3, MemOperand(x2));
-		Br(x3);
-
-		// arm_dofiq:
-		Bind(&arm_dofiq);
-		call((void*)CPUFiq);
-		B(&arm_dispatch_label);
-
-		// arm_exit:
-		Bind(&arm_exit);
-		Ldp(x23, x24, MemOperand(sp, 80));
-		Ldp(x21, x22, MemOperand(sp, 64));
-		Ldp(x19, x20, MemOperand(sp, 48));
-		Ldp(x29, x30, MemOperand(sp, 32));
-		Ldp(x27, x28, MemOperand(sp, 16));
-		Ldp(x25, x26, MemOperand(sp, 96, AddrMode::PostIndex));
-		Ret();
-
-		FinalizeCode();
-		vmem_platform_flush_cache(
-				GetBuffer()->GetStartAddress<void*>(), GetBuffer()->GetEndAddress<void*>(),
-				GetBuffer()->GetStartAddress<void*>(), GetBuffer()->GetEndAddress<void*>());
-		recompiler::advance(GetBuffer()->GetSizeInBytes());
-	}
-};
-
-void AArch64ArmRegAlloc::LoadReg(int host_reg, Arm7Reg armreg)
-{
-	// printf("LoadReg W%d <- r%d\n", host_reg, armreg);
-	assembler.Ldr(getReg(host_reg), arm_reg_operand(armreg));
-}
-
-void AArch64ArmRegAlloc::StoreReg(int host_reg, Arm7Reg armreg)
-{
-	// printf("StoreReg W%d -> r%d\n", host_reg, armreg);
-	assembler.Str(getReg(host_reg), arm_reg_operand(armreg));
-}
-
-void arm7backend_compile(const std::vector<ArmOp>& block_ops, u32 cycles)
-{
-	Arm7Compiler assembler;
-	assembler.compile(block_ops, cycles);
-}
-
-void arm7backend_flush()
-{
-	Arm7Compiler assembler;
-	assembler.generateMainLoop();
-}
-
-}
-#endif // ARM64
diff --git a/core/hw/arm7/arm7_rec_x64.cpp b/core/hw/arm7/arm7_rec_x64.cpp
deleted file mode 100644
index d546b71..0000000
--- a/core/hw/arm7/arm7_rec_x64.cpp
+++ /dev/null
@@ -1,969 +0,0 @@
-/*
-	Copyright 2020 flyinghead
-
-	This file is part of flycast.
-
-    flycast is free software: you can redistribute it and/or modify
-    it under the terms of the GNU General Public License as published by
-    the Free Software Foundation, either version 2 of the License, or
-    (at your option) any later version.
-
-    flycast is distributed in the hope that it will be useful,
-    but WITHOUT ANY WARRANTY; without even the implied warranty of
-    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-    GNU General Public License for more details.
-
-    You should have received a copy of the GNU General Public License
-    along with flycast.  If not, see <https://www.gnu.org/licenses/>.
- */
-
-#include "build.h"
-
-#if	HOST_CPU == CPU_X64 && FEAT_AREC != DYNAREC_NONE
-
-#define XBYAK_NO_OP_NAMES
-#include <xbyak/xbyak.h>
-#include <xbyak/xbyak_util.h>
-using namespace Xbyak::util;
-
-#include "arm7_rec.h"
-
-namespace aicaarm {
-
-static void (*arm_dispatch)();
-
-#ifdef _WIN32
-static const Xbyak::Reg32 call_regs[] = { ecx, edx, r8d, r9d };
-#else
-static const Xbyak::Reg32 call_regs[] = { edi, esi, edx, ecx  };
-#endif
-static void (**entry_points)();
-
-class Arm7Compiler;
-
-#ifdef _WIN32
-static const std::array<Xbyak::Reg32, 8> alloc_regs {
-		ebx, ebp, edi, esi, r12d, r13d, r14d, r15d
-};
-#else
-static const std::array<Xbyak::Reg32, 6> alloc_regs {
-		ebx, ebp, r12d, r13d, r14d, r15d
-};
-#endif
-
-class X64ArmRegAlloc : public ArmRegAlloc<sizeof(alloc_regs) / sizeof(alloc_regs[0]), X64ArmRegAlloc>
-{
-	using super = ArmRegAlloc<sizeof(alloc_regs) / sizeof(alloc_regs[0]), X64ArmRegAlloc>;
-	Arm7Compiler& assembler;
-
-	void LoadReg(int host_reg, Arm7Reg armreg);
-	void StoreReg(int host_reg, Arm7Reg armreg);
-
-	static const Xbyak::Reg32& getReg32(int i)
-	{
-		verify(i >= 0 && (u32)i < alloc_regs.size());
-		return alloc_regs[i];
-	}
-
-public:
-	X64ArmRegAlloc(Arm7Compiler& assembler, const std::vector<ArmOp>& block_ops)
-		: super(block_ops), assembler(assembler) {}
-
-	const Xbyak::Reg32& map(Arm7Reg r)
-	{
-		int i = super::map(r);
-		return getReg32(i);
-	}
-
-	friend super;
-};
-
-class Arm7Compiler : public Xbyak::CodeGenerator
-{
-	bool logical_op_set_flags = false;
-	bool set_carry_bit = false;
-	bool set_flags = false;
-	X64ArmRegAlloc *regalloc = nullptr;
-
-	static const u32 N_FLAG = 1 << 31;
-	static const u32 Z_FLAG = 1 << 30;
-	static const u32 C_FLAG = 1 << 29;
-	static const u32 V_FLAG = 1 << 28;
-
-
-	Xbyak::Operand getOperand(const ArmOp::Operand& arg, Xbyak::Reg32 scratch_reg)
-	{
-		Xbyak::Reg32 r;
-		if (!arg.isReg())
-		{
-			if (arg.isNone() || arg.shift_imm)
-				return Xbyak::Operand();
-			mov(scratch_reg, arg.getImmediate());
-			r = scratch_reg;
-		}
-		else
-			r = regalloc->map(arg.getReg().armreg);
-		if (arg.isShifted())
-		{
-			if (r != scratch_reg)
-			{
-				mov(scratch_reg, r);
-				r = scratch_reg;
-			}
-			if (arg.shift_imm)
-			{
-				// shift by immediate
-				if (arg.shift_type != ArmOp::ROR && arg.shift_value != 0 && !logical_op_set_flags)
-				{
-					switch (arg.shift_type)
-					{
-					case ArmOp::LSL:
-						shl(r, arg.shift_value);
-						break;
-					case ArmOp::LSR:
-						shr(r, arg.shift_value);
-						break;
-					case ArmOp::ASR:
-						sar(r, arg.shift_value);
-						break;
-					default:
-						die("invalid");
-						break;
-					}
-				}
-				else if (arg.shift_value == 0)
-				{
-					// Shift by 32
-					if (logical_op_set_flags)
-						set_carry_bit = true;
-					if (arg.shift_type == ArmOp::LSR)
-					{
-						if (set_carry_bit)
-						{
-							mov(r10d, r);			// r10d = rm[31]
-							shr(r10d, 31);
-						}
-						mov(r, 0);					// r = 0
-					}
-					else if (arg.shift_type == ArmOp::ASR)
-					{
-						if (set_carry_bit)
-						{
-							mov(r10d, r);			// r10d = rm[31]
-							shr(r10d, 31);
-						}
-						sar(r, 31);					// r = rm < 0 ? -1 : 0
-					}
-					else if (arg.shift_type == ArmOp::ROR)
-					{
-						// RRX
-						mov(r10d, dword[rip + &arm_Reg[RN_PSR_FLAGS].I]);
-						shl(r10d, 2);
-						verify(r != eax);
-						mov(eax, r);				// eax = rm
-						and_(r10d, 0x80000000);		// r10[31] = C
-						shr(eax, 1);				// eax = eax >> 1
-						or_(eax, r10d);				// eax[31] = C
-						if (set_carry_bit)
-						{
-							mov(r10d, r);
-							and_(r10d, 1);			// r10 = rm[0] (new C)
-						}
-						mov(r, eax);				// r = eax
-					}
-					else
-						die("Invalid shift");
-				}
-				else
-				{
-					// Carry must be preserved or Ror shift
-					if (logical_op_set_flags)
-						set_carry_bit = true;
-					if (arg.shift_type == ArmOp::LSL)
-					{
-						if (set_carry_bit)
-							mov(r10d, r);
-						if (set_carry_bit)
-							shr(r10d, 32 - arg.shift_value);
-						shl(r, arg.shift_value);			// r <<= shift
-						if (set_carry_bit)
-							and_(r10d, 1);					// r10d = rm[lsb]
-					}
-					else
-					{
-						if (set_carry_bit)
-						{
-							mov(r10d, r);
-							shr(r10d, arg.shift_value - 1);
-							and_(r10d, 1);					// r10d = rm[msb]
-						}
-
-						if (arg.shift_type == ArmOp::LSR)
-							shr(r, arg.shift_value);		// r >>= shift
-						else if (arg.shift_type == ArmOp::ASR)
-							sar(r, arg.shift_value);
-						else if (arg.shift_type == ArmOp::ROR)
-							ror(r, arg.shift_value);
-						else
-							die("Invalid shift");
-					}
-				}
-			}
-			else
-			{
-				// shift by register
-				const Xbyak::Reg32 shift_reg = regalloc->map(arg.shift_reg.armreg);
-				switch (arg.shift_type)
-				{
-				case ArmOp::LSL:
-				case ArmOp::LSR:
-					mov(ecx, shift_reg);
-					mov(eax, 0);
-					if (arg.shift_type == ArmOp::LSL)
-						shl(r, cl);
-					else
-						shr(r, cl);
-					cmp(shift_reg, 32);
-					cmovnb(r, eax);		// LSL and LSR by 32 or more gives 0
-					break;
-				case ArmOp::ASR:
-					mov(ecx, shift_reg);
-					mov(eax, r);
-					sar(eax, 31);
-					sar(r, cl);
-					cmp(shift_reg, 32);
-					cmovnb(r, eax);		// ASR by 32 or more gives 0 or -1 depending on operand sign
-					break;
-				case ArmOp::ROR:
-					mov(ecx, shift_reg);
-					ror(r, cl);
-					break;
-				default:
-					die("Invalid shift");
-					break;
-				}
-			}
-		}
-		return r;
-	}
-
-	Xbyak::Label *startConditional(ArmOp::Condition cc)
-	{
-		if (cc == ArmOp::AL)
-			return nullptr;
-		Xbyak::Label *label = new Xbyak::Label();
-		cc = (ArmOp::Condition)((u32)cc ^ 1);	// invert the condition
-		mov(eax, dword[rip + &arm_Reg[RN_PSR_FLAGS].I]);
-		switch (cc)
-		{
-		case ArmOp::EQ:	// Z==1
-			and_(eax, Z_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		case ArmOp::NE:	// Z==0
-			and_(eax, Z_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::CS:	// C==1
-			and_(eax, C_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		case ArmOp::CC:	// C==0
-			and_(eax, C_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::MI:	// N==1
-			and_(eax, N_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		case ArmOp::PL:	// N==0
-			and_(eax, N_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::VS:	// V==1
-			and_(eax, V_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		case ArmOp::VC:	// V==0
-			and_(eax, V_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::HI:	// (C==1) && (Z==0)
-			and_(eax, C_FLAG | Z_FLAG);
-			cmp(eax, C_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::LS:	// (C==0) || (Z==1)
-			and_(eax, C_FLAG | Z_FLAG);
-			cmp(eax, C_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		case ArmOp::GE:	// N==V
-			mov(ecx, eax);
-			shl(ecx, 3);
-			xor_(eax, ecx);
-			and_(eax, N_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::LT:	// N!=V
-			mov(ecx, eax);
-			shl(ecx, 3);
-			xor_(eax, ecx);
-			and_(eax, N_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		case ArmOp::GT:	// (Z==0) && (N==V)
-			mov(ecx, eax);
-			mov(edx, eax);
-			shl(ecx, 3);
-			shl(edx, 1);
-			xor_(eax, ecx);
-			or_(eax, edx);
-			and_(eax, N_FLAG);
-			jz(*label, T_NEAR);
-			break;
-		case ArmOp::LE:	// (Z==1) || (N!=V)
-			mov(ecx, eax);
-			mov(edx, eax);
-			shl(ecx, 3);
-			shl(edx, 1);
-			xor_(eax, ecx);
-			or_(eax, edx);
-			and_(eax, N_FLAG);
-			jnz(*label, T_NEAR);
-			break;
-		default:
-			die("Invalid condition code");
-			break;
-		}
-
-		return label;
-	}
-
-	void endConditional(Xbyak::Label *label)
-	{
-		if (label != nullptr)
-		{
-			L(*label);
-			delete label;
-		}
-	}
-
-	bool emitDataProcOp(const ArmOp& op)
-	{
-		bool save_v_flag = true;
-
-		Xbyak::Operand arg0 = getOperand(op.arg[0], r8d);
-		Xbyak::Operand arg1 = getOperand(op.arg[1], r9d);
-		Xbyak::Reg32 rd;
-		if (op.rd.isReg())
-			rd = regalloc->map(op.rd.getReg().armreg);
-		if (logical_op_set_flags)
-		{
-			// When an Operand2 constant is used with the instructions MOVS, MVNS, ANDS, ORRS, ORNS, EORS, BICS, TEQ or TST,
-			// the carry flag is updated to bit[31] of the constant,
-			// if the constant is greater than 255 and can be produced by shifting an 8-bit value.
-			if (op.arg[0].isImmediate() && op.arg[0].getImmediate() > 255)
-			{
-				set_carry_bit = true;
-				mov(r10d, (op.arg[0].getImmediate() & 0x80000000) >> 31);
-			}
-			else if (op.arg[1].isImmediate() && op.arg[1].getImmediate() > 255)
-			{
-				set_carry_bit = true;
-				mov(r10d, (op.arg[1].getImmediate() & 0x80000000) >> 31);
-			}
-		}
-
-		switch (op.op_type)
-		{
-		case ArmOp::AND:
-			if (arg1 == rd)
-				and_(rd, arg0);
-			else
-			{
-				if (rd != arg0)
-				{
-					mov(rd, arg0);
-					verify(rd != arg1);
-				}
-				if (!arg1.isNone())
-					and_(rd, arg1);
-				else
-					and_(rd, op.arg[1].getImmediate());
-			}
-			save_v_flag = false;
-			break;
-		case ArmOp::ORR:
-			if (arg1 == rd)
-				or_(rd, arg0);
-			else
-			{
-				if (rd != arg0)
-				{
-					// FIXME need static evaluation or this must be duplicated
-					if (arg0.isNone())
-						mov(rd, op.arg[0].getImmediate());
-					else
-						mov(rd, arg0);
-					verify(rd != arg1);
-				}
-				if (!arg1.isNone())
-					or_(rd, arg1);
-				else
-					or_(rd, op.arg[1].getImmediate());
-			}
-			save_v_flag = false;
-			break;
-		case ArmOp::EOR:
-			if (arg1 == rd)
-				xor_(rd, arg0);
-			else
-			{
-				if (rd != arg0)
-				{
-					verify(rd != arg1);
-					mov(rd, arg0);
-				}
-				if (!arg1.isNone())
-					xor_(rd, arg1);
-				else
-					xor_(rd, op.arg[1].getImmediate());
-			}
-			save_v_flag = false;
-			break;
-		case ArmOp::BIC:
-			if (arg1.isNone())
-			{
-				mov(eax, op.arg[1].getImmediate());
-				arg1 = eax;
-			}
-			andn(rd, static_cast<Xbyak::Reg32&>(arg1), arg0);
-			save_v_flag = false;
-			break;
-
-		case ArmOp::TST:
-			if (!arg1.isNone())
-				test(arg0, static_cast<Xbyak::Reg32&>(arg1));
-			else
-				test(arg0, op.arg[1].getImmediate());
-			save_v_flag = false;
-			break;
-		case ArmOp::TEQ:
-			if (arg0 != r8d)
-				mov(r8d, arg0);
-			if (!arg1.isNone())
-				xor_(r8d, arg1);
-			else
-				xor_(r8d, op.arg[1].getImmediate());
-			save_v_flag = false;
-			break;
-		case ArmOp::CMP:
-			if (!arg1.isNone())
-				cmp(arg0, arg1);
-			else
-				cmp(arg0, op.arg[1].getImmediate());
-			if (set_flags)
-			{
-				setnb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		case ArmOp::CMN:
-			if (arg0 != r8d)
-				mov(r8d, arg0);
-			if (!arg1.isNone())
-				add(r8d, arg1);
-			else
-				add(r8d, op.arg[1].getImmediate());
-			if (set_flags)
-			{
-				setb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-
-		case ArmOp::MOV:
-			if (arg0.isNone())
-				mov(rd, op.arg[0].getImmediate());
-			else if (arg0 != rd)
-				mov(rd, arg0);
-			if (set_flags)
-			{
-				test(rd, rd);
-				save_v_flag = false;
-			}
-			break;
-		case ArmOp::MVN:
-			if (arg0.isNone())
-				mov(rd, ~op.arg[0].getImmediate());
-			else
-			{
-				if (arg0 != rd)
-					mov(rd, arg0);
-				not_(rd);
-			}
-			if (set_flags)
-			{
-				test(rd, rd);
-				save_v_flag = false;
-			}
-			break;
-
-		case ArmOp::SUB:
-			if (arg1 == rd)
-			{
-				sub(arg0, arg1);
-				if (rd != arg0)
-					mov(rd, arg0);
-			}
-			else
-			{
-				if (rd != arg0)
-					mov(rd, arg0);
-				if (arg1.isNone())
-					sub(rd, op.arg[1].getImmediate());
-				else
-					sub(rd, arg1);
-			}
-			if (set_flags)
-			{
-				setnb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		case ArmOp::RSB:
-			if (arg1 == rd)
-				sub(rd, arg0);
-			else
-			{
-				if (rd != arg0)
-					mov(rd, arg0);
-				neg(rd);
-				if (arg1.isNone())
-					add(rd, op.arg[1].getImmediate());
-				else
-					add(rd, arg1);
-			}
-			if (set_flags)
-			{
-				setb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		case ArmOp::ADD:
-			if (arg1 == rd)
-				add(rd, arg0);
-			else
-			{
-				if (rd != arg0)
-				{
-					// FIXME need static evaluation or this must be duplicated
-					if (arg0.isNone())
-						mov(rd, op.arg[0].getImmediate());
-					else
-						mov(rd, arg0);
-				}
-				if (arg1.isNone())
-					add(rd, op.arg[1].getImmediate());
-				else
-					add(rd, arg1);
-			}
-			if (set_flags)
-			{
-				setb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		case ArmOp::ADC:
-			mov(r11d, dword[rip + &arm_Reg[RN_PSR_FLAGS].I]);
-			and_(r11d, C_FLAG);
-			neg(r11d);
-			if (arg1 == rd)
-				adc(rd, arg0);
-			else
-			{
-				if (rd != arg0)
-					mov(rd, arg0);
-				if (arg1.isNone())
-					adc(rd, op.arg[1].getImmediate());
-				else
-					adc(rd, arg1);
-			}
-			if (set_flags)
-			{
-				setb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		case ArmOp::SBC:
-			// rd = rn - op2 - !C
-			mov(r11d, dword[rip + &arm_Reg[RN_PSR_FLAGS].I]);
-			and_(r11d, C_FLAG);
-			neg(r11d);
-			cmc();		// on arm, -1 if carry is clear
-			if (arg1 == rd)
-			{
-				sbb(arg0, arg1);
-				if (rd != arg0)
-					mov(rd, arg0);
-			}
-			else
-			{
-				if (rd != arg0)
-					mov(rd, arg0);
-				if (arg1.isNone())
-					sbb(rd, op.arg[1].getImmediate());
-				else
-					sbb(rd, arg1);
-			}
-			if (set_flags)
-			{
-				setnb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		case ArmOp::RSC:
-			// rd = op2 - rn - !C
-			mov(r11d, dword[rip + &arm_Reg[RN_PSR_FLAGS].I]);
-			and_(r11d, C_FLAG);
-			neg(r11d);
-			cmc();		// on arm, -1 if carry is clear
-			if (arg1 == rd)
-				sbb(rd, arg0);
-			else
-			{
-				if (arg1.isNone())
-					mov(rd, op.arg[1].getImmediate());
-				else if (rd != arg1)
-					mov(rd, arg1);
-				sbb(rd, arg0);
-			}
-			if (set_flags)
-			{
-				setnb(r10b);
-				set_carry_bit = true;
-			}
-			break;
-		default:
-			die("invalid");
-			break;
-		}
-
-		return save_v_flag;
-	}
-
-	void emitMemOp(const ArmOp& op)
-	{
-		Xbyak::Operand addr_reg = getOperand(op.arg[0], call_regs[0]);
-		if (addr_reg != call_regs[0])
-		{
-			if (addr_reg.isNone())
-				mov(call_regs[0], op.arg[0].getImmediate());
-			else
-				mov(call_regs[0], addr_reg);
-			addr_reg = call_regs[0];
-		}
-		if (op.pre_index)
-		{
-			const ArmOp::Operand& offset = op.arg[1];
-			Xbyak::Operand offset_reg = getOperand(offset, r9d);
-			if (!offset_reg.isNone())
-			{
-				if (op.add_offset)
-					add(addr_reg, offset_reg);
-				else
-					sub(addr_reg, offset_reg);
-			}
-			else if (offset.isImmediate() && offset.getImmediate() != 0)
-			{
-				if (op.add_offset)
-					add(addr_reg, offset.getImmediate());
-				else
-					sub(addr_reg, offset.getImmediate());
-			}
-		}
-		if (op.op_type == ArmOp::STR)
-		{
-			if (op.arg[2].isImmediate())
-				mov(call_regs[1], op.arg[2].getImmediate());
-			else
-				mov(call_regs[1], regalloc->map(op.arg[2].getReg().armreg));
-		}
-
-		call(recompiler::getMemOp(op.op_type == ArmOp::LDR, op.byte_xfer));
-
-		if (op.op_type == ArmOp::LDR)
-			mov(regalloc->map(op.rd.getReg().armreg), eax);
-	}
-
-	void saveFlags(bool save_v_flag)
-	{
-		if (!set_flags)
-			return;
-
-		pushf();
-		pop(rax);
-
-		if (save_v_flag)
-		{
-			mov(r11d, eax);
-			shl(r11d, 28 - 11);		// V
-		}
-		shl(eax, 30 - 6);			// Z,N
-		if (save_v_flag)
-			and_(r11d, V_FLAG);		// V
-		and_(eax, Z_FLAG | N_FLAG);	// Z,N
-		if (save_v_flag)
-			or_(eax, r11d);
-
-		mov(r11d, dword[rip + &arm_Reg[RN_PSR_FLAGS].I]);
-		if (set_carry_bit)
-		{
-			if (save_v_flag)
-				and_(r11d, ~(Z_FLAG | N_FLAG | C_FLAG | V_FLAG));
-			else
-				and_(r11d, ~(Z_FLAG | N_FLAG | C_FLAG));
-			shl(r10d, 29);
-			or_(r11d, r10d);
-		}
-		else
-		{
-			if (save_v_flag)
-				and_(r11d, ~(Z_FLAG | N_FLAG | V_FLAG));
-			else
-				and_(r11d, ~(Z_FLAG | N_FLAG));
-		}
-		or_(r11d, eax);
-		mov(dword[rip + &arm_Reg[RN_PSR_FLAGS].I], r11d);
-	}
-
-	void emitBranch(const ArmOp& op)
-	{
-		Xbyak::Operand addr_reg = getOperand(op.arg[0], eax);
-		if (addr_reg.isNone())
-			mov(eax, op.arg[0].getImmediate());
-		else
-		{
-			if (eax != addr_reg)
-				mov(eax, addr_reg);
-			and_(eax, 0xfffffffc);
-		}
-		mov(dword[rip + &arm_Reg[R15_ARM_NEXT].I], eax);
-	}
-
-	void emitMSR(const ArmOp& op)
-	{
-		if (op.arg[0].isImmediate())
-			mov(call_regs[0], op.arg[0].getImmediate());
-		else
-			mov(call_regs[0], regalloc->map(op.arg[0].getReg().armreg));
-		if (op.spsr)
-			call(recompiler::MSR_do<1>);
-		else
-			call(recompiler::MSR_do<0>);
-	}
-
-	void emitMRS(const ArmOp& op)
-	{
-		call(CPUUpdateCPSR);
-
-		if (op.spsr)
-			mov(regalloc->map(op.rd.getReg().armreg), dword[rip + &arm_Reg[RN_SPSR]]);
-		else
-			mov(regalloc->map(op.rd.getReg().armreg), dword[rip + &arm_Reg[RN_CPSR]]);
-	}
-
-	void emitFallback(const ArmOp& op)
-	{
-		set_flags = false;
-		mov(call_regs[0], op.arg[0].getImmediate());
-		call(recompiler::interpret);
-	}
-
-public:
-	Arm7Compiler() : Xbyak::CodeGenerator(recompiler::spaceLeft(), recompiler::currentCode()) { }
-
-	void compile(const std::vector<ArmOp>& block_ops, u32 cycles)
-	{
-		regalloc = new X64ArmRegAlloc(*this, block_ops);
-
-		sub(dword[rip + &arm_Reg[CYCL_CNT]], cycles);
-
-		ArmOp::Condition currentCondition = ArmOp::AL;
-		Xbyak::Label *condLabel = nullptr;
-
-		for (u32 i = 0; i < block_ops.size(); i++)
-		{
-			const ArmOp& op = block_ops[i];
-			DEBUG_LOG(AICA_ARM, "-> %s", op.toString().c_str());
-
-			set_flags = op.flags & ArmOp::OP_SETS_FLAGS;
-			logical_op_set_flags = op.isLogicalOp() && set_flags;
-			set_carry_bit = false;
-			bool save_v_flag = true;
-
-			if (op.op_type == ArmOp::FALLBACK)
-			{
-				endConditional(condLabel);
-				condLabel = nullptr;
-				currentCondition = ArmOp::AL;
-			}
-			else if (op.condition != currentCondition)
-			{
-				endConditional(condLabel);
-				currentCondition = op.condition;
-				condLabel = startConditional(op.condition);
-			}
-
-			regalloc->load(i);
-
-			if (op.op_type <= ArmOp::MVN)
-				// data processing op
-				save_v_flag = emitDataProcOp(op);
-			else if (op.op_type <= ArmOp::STR)
-				// memory load/store
-				emitMemOp(op);
-			else if (op.op_type <= ArmOp::BL)
-				// branch
-				emitBranch(op);
-			else if (op.op_type == ArmOp::MRS)
-				emitMRS(op);
-			else if (op.op_type == ArmOp::MSR)
-				emitMSR(op);
-			else if (op.op_type == ArmOp::FALLBACK)
-				emitFallback(op);
-			else
-				die("invalid");
-
-			saveFlags(save_v_flag);
-
-			regalloc->store(i);
-
-			if (set_flags)
-			{
-				currentCondition = ArmOp::AL;
-				endConditional(condLabel);
-				condLabel = nullptr;
-			}
-		}
-		endConditional(condLabel);
-
-		jmp((void*)arm_dispatch);
-
-		ready();
-		recompiler::advance(getSize());
-
-		delete regalloc;
-		regalloc = nullptr;
-	}
-
-	void generateMainLoop()
-	{
-		if (!recompiler::empty())
-		{
-			verify(arm_mainloop != nullptr);
-			verify(arm_compilecode != nullptr);
-			return;
-		}
-		Xbyak::Label arm_dispatch_label;
-		Xbyak::Label arm_mainloop_label;
-
-		//arm_compilecode:
-		call(recompiler::compile);
-		jmp(arm_dispatch_label);
-
-		// arm_mainloop:
-		L(arm_mainloop_label);
-#ifdef _WIN32
-		push(rdi);
-		push(rsi);
-#endif
-		push(r12);
-		push(r13);
-		push(r14);
-		push(r15);
-		push(rbx);
-		push(rbp);
-#ifdef _WIN32
-		sub(rsp, 40);	// 32-byte shadow space + 16-byte stack alignment
-#else
-		sub(rsp, 8);		// 16-byte stack alignment
-#endif
-		mov(qword[rip + &entry_points], call_regs[1].cvt64());
-
-		// arm_dispatch:
-		L(arm_dispatch_label);
-		mov(rdx, qword[rip + &entry_points]);
-		mov(ecx, dword[rip + &arm_Reg[R15_ARM_NEXT]]);
-		mov(eax, dword[rip + &arm_Reg[INTR_PEND]]);
-		cmp(dword[rip + &arm_Reg[CYCL_CNT]], 0);
-		Xbyak::Label arm_exit;
-		jle(arm_exit);			// timeslice is over
-		test(eax, eax);
-		Xbyak::Label arm_dofiq;
-		jne(arm_dofiq);			// if interrupt pending, handle it
-
-		and_(ecx, 0x7ffffc);
-		jmp(qword[rdx + rcx * 2]);
-
-		// arm_dofiq:
-		L(arm_dofiq);
-		call(CPUFiq);
-		jmp(arm_dispatch_label);
-
-		// arm_exit:
-		L(arm_exit);
-#ifdef _WIN32
-		add(rsp, 40);
-#else
-		add(rsp, 8);
-#endif
-		pop(rbp);
-		pop(rbx);
-		pop(r15);
-		pop(r14);
-		pop(r13);
-		pop(r12);
-#ifdef _WIN32
-		pop(rsi);
-		pop(rdi);
-#endif
-		ret();
-
-		ready();
-		arm_compilecode = (void (*)())getCode();
-		arm_mainloop = (arm_mainloop_t)arm_mainloop_label.getAddress();
-		arm_dispatch = (void (*)())arm_dispatch_label.getAddress();
-
-		recompiler::advance(getSize());
-	}
-
-};
-
-void X64ArmRegAlloc::LoadReg(int host_reg, Arm7Reg armreg)
-{
-	// printf("LoadReg X%d <- r%d\n", host_reg, armreg);
-	assembler.mov(getReg32(host_reg), dword[rip + &arm_Reg[(u32)armreg].I]);
-}
-
-void X64ArmRegAlloc::StoreReg(int host_reg, Arm7Reg armreg)
-{
-	// printf("StoreReg X%d -> r%d\n", host_reg, armreg);
-	assembler.mov(dword[rip + &arm_Reg[(u32)armreg].I], getReg32(host_reg));
-}
-
-void arm7backend_compile(const std::vector<ArmOp>& block_ops, u32 cycles)
-{
-	Arm7Compiler assembler;
-	assembler.compile(block_ops, cycles);
-}
-
-void arm7backend_flush()
-{
-	Arm7Compiler assembler;
-	assembler.generateMainLoop();
-}
-
-}
-#endif // X64 && DYNAREC_JIT
diff --git a/core/hw/arm7/vbaARM.cpp b/core/hw/arm7/vbaARM.cpp
index f905ec0..b225f4c 100644
--- a/core/hw/arm7/vbaARM.cpp
+++ b/core/hw/arm7/vbaARM.cpp
@@ -6,7 +6,7 @@
 //called when plugin is used by emu (you should do first time init here)
 s32 libARM_Init()
 {
-	aicaarm::init();
+	arm_Init();
 
 	return 0;
 }
@@ -20,6 +20,6 @@ void libARM_Term()
 //It's supposed to reset anything
 void libARM_Reset(bool hard)
 {
-	aicaarm::reset();
-	aicaarm::enable(false);
+	arm_Reset();
+	arm_SetEnabled(false);
 }
diff --git a/core/hw/arm7/virt_arm.cpp b/core/hw/arm7/virt_arm.cpp
new file mode 100644
index 0000000..43655c7
--- /dev/null
+++ b/core/hw/arm7/virt_arm.cpp
@@ -0,0 +1,213 @@
+#include "build.h"
+
+#if HOST_CPU==CPU_X86 && FEAT_AREC != DYNAREC_NONE
+
+#include "virt_arm.h"
+
+namespace VARM
+{
+#define CPUReadByte(addr) (*(u8*)(addr))
+#define CPUReadMemory(addr) (*(u32*)(addr))
+#define CPUReadHalfWord(addr) (*(u16*)(addr))
+#define CPUReadHalfWordSigned(addr) (*(s16*)(addr))
+
+#define CPUWriteMemory(addr,data) (*(u32*)addr=data)
+#define CPUWriteHalfWord(addr,data) (*(u16*)addr=data)
+#define CPUWriteByte(addr,data) (*(u8*)addr=data)
+
+
+#define reg arm_Reg
+#define armNextPC arm_ArmNextPC
+
+
+#define CPUUpdateTicksAccesint(a) 1
+#define CPUUpdateTicksAccessSeq32(a) 1
+#define CPUUpdateTicksAccesshort(a) 1
+#define CPUUpdateTicksAccess32(a) 1
+#define CPUUpdateTicksAccess16(a) 1
+
+
+
+	typedef union
+	{
+		struct
+		{
+			u8 B0;
+			u8 B1;
+			u8 B2;
+			u8 B3;
+		} B;
+
+		struct
+		{
+			u16 W0;
+			u16 W1;
+		} W;
+
+		u32 I;
+	} reg_pair;
+
+	u32 arm_ArmNextPC;
+
+	reg_pair arm_Reg[45];
+
+	void CPUSwap(u32 *a, u32 *b)
+	{
+		u32 c = *b;
+		*b = *a;
+		*a = c;
+	}
+
+
+	bool N_FLAG;
+	bool Z_FLAG;
+	bool C_FLAG;
+	bool V_FLAG;
+	bool armIrqEnable;
+	bool armFiqEnable;
+
+	int armMode;
+
+	u8 cpuBitsSet[256];
+
+	void CPUSwitchMode(int mode, bool saveState, bool breakLoop=true);
+	void CPUFiq();
+	void CPUUpdateCPSR();
+	void CPUUpdateFlags();
+	void CPUSoftwareInterrupt(int comment);
+	void CPUUndefinedException();
+
+
+	void CPUInterrupt();
+
+	u32 virt_arm_op(u32 opcode)
+	{
+		u32 clockTicks=0;
+
+		armNextPC=reg[15].I=0;
+
+#include "arm-new.h"
+
+		verify(reg[15].I==0);
+		verify(arm_ArmNextPC==0);
+
+		return clockTicks;
+	}
+	
+	void CPUSwitchMode(int mode, bool saveState, bool breakLoop)
+	{
+		verify(mode==0x10);
+	}
+
+	void CPUUpdateCPSR()
+	{
+		u32 CPSR = reg[16].I & 0x40;
+		if(N_FLAG)
+			CPSR |= 0x80000000;
+		if(Z_FLAG)
+			CPSR |= 0x40000000;
+		if(C_FLAG)
+			CPSR |= 0x20000000;
+		if(V_FLAG)
+			CPSR |= 0x10000000;
+		/*if(!armState)
+		CPSR |= 0x00000020;*/
+		if (!armFiqEnable)
+			CPSR |= 0x40;
+		if(!armIrqEnable)
+			CPSR |= 0x80;
+		CPSR |= (armMode & 0x1F);
+		reg[16].I = CPSR;
+
+		verify(armMode==0);
+		verify(armFiqEnable==false);
+		verify(armIrqEnable==false);
+	}
+
+	void CPUUpdateFlags()
+	{
+		u32 CPSR = reg[16].I;
+
+		N_FLAG = (CPSR & 0x80000000) ? true: false;
+		Z_FLAG = (CPSR & 0x40000000) ? true: false;
+		C_FLAG = (CPSR & 0x20000000) ? true: false;
+		V_FLAG = (CPSR & 0x10000000) ? true: false;
+		//armState = (CPSR & 0x20) ? false : true;
+		armIrqEnable = (CPSR & 0x80) ? false : true;
+		armFiqEnable = (CPSR & 0x40) ? false : true;
+
+		verify(armMode==0);
+		verify(armFiqEnable==false);
+		verify(armIrqEnable==false);
+	}
+
+	void CPUSoftwareInterrupt(int comment)
+	{
+		die("Can't happen");
+	}
+
+	void CPUUndefinedException()
+	{
+		die("Can't happen");
+	}
+
+	void virt_arm_reset()
+	{
+		// clean registers
+		memset(&arm_Reg[0], 0, sizeof(arm_Reg));
+
+		armMode = 0x0;
+
+		reg[13].I = 0x03007F00;
+		reg[15].I = 0x0000000;
+		reg[16].I = 0x00000000;
+
+		// disable FIQ
+		reg[16].I |= 0x40;
+
+		CPUUpdateCPSR();
+
+		armNextPC = reg[15].I;
+		reg[15].I += 4;
+
+		//arm_FiqPending = false; 
+	}
+
+	void virt_arm_init()
+	{
+		virt_arm_reset();
+
+		for (int i = 0; i < 256; i++)
+		{
+			int count = 0;
+			for (int j = 0; j < 8; j++)
+				if (i & (1 << j))
+					count++;
+
+			cpuBitsSet[i] = count;
+		}
+	}
+}
+
+
+void virt_arm_reset()
+{
+	VARM::virt_arm_reset();
+}
+
+void virt_arm_init()
+{
+	VARM::virt_arm_init();
+}
+
+u32 DYNACALL virt_arm_op(u32 opcode)
+{
+	return VARM::virt_arm_op(opcode);
+}
+
+u32& virt_arm_reg(u32 id)
+{
+	return VARM::arm_Reg[id].I;
+}
+
+#endif
diff --git a/core/hw/arm7/virt_arm.h b/core/hw/arm7/virt_arm.h
new file mode 100644
index 0000000..4380bcc
--- /dev/null
+++ b/core/hw/arm7/virt_arm.h
@@ -0,0 +1,7 @@
+#pragma once
+#include "types.h"
+
+void virt_arm_reset();
+void virt_arm_init();
+u32 DYNACALL virt_arm_op(u32 opcode);
+u32& virt_arm_reg(u32 id);
\ No newline at end of file
diff --git a/core/hw/holly/sb.h b/core/hw/holly/sb.h
index 1984044..248dc8f 100644
--- a/core/hw/holly/sb.h
+++ b/core/hw/holly/sb.h
@@ -490,7 +490,7 @@ extern u32 SB_ISTNRM;
 #define SB_ADEN SB_REG_32(ADEN)
 
 //0x005F7818    SB_ADST RW  AICA:G2-DMA start
-//#define SB_ADST SB_REG_32(ADST)
+#define SB_ADST SB_REG_32(ADST)
 //0x005F781C    SB_ADSUSP   RW  AICA:G2-DMA suspend
 #define SB_ADSUSP SB_REG_32(ADSUSP)
 
diff --git a/core/hw/mem/vmem32.cpp b/core/hw/mem/vmem32.cpp
index a986944..ef8f95b 100644
--- a/core/hw/mem/vmem32.cpp
+++ b/core/hw/mem/vmem32.cpp
@@ -147,7 +147,7 @@ void vmem32_protect_vram(u32 addr, u32 size)
 {
 	if (!vmem32_inited)
 		return;
-	for (u32 page = (addr & VRAM_MASK) / VRAM_PROT_SEGMENT; page <= ((addr & VRAM_MASK) + size - 1) / VRAM_PROT_SEGMENT; page++)
+	for (int page = (addr & VRAM_MASK) / VRAM_PROT_SEGMENT; page <= ((addr & VRAM_MASK) + size - 1) / VRAM_PROT_SEGMENT; page++)
 	{
 		vram_blocks[page].push_back({ addr, addr + size - 1 });
 	}
@@ -156,7 +156,7 @@ void vmem32_unprotect_vram(u32 addr, u32 size)
 {
 	if (!vmem32_inited)
 		return;
-	for (u32 page = (addr & VRAM_MASK) / VRAM_PROT_SEGMENT; page <= ((addr & VRAM_MASK) + size - 1) / VRAM_PROT_SEGMENT; page++)
+	for (int page = (addr & VRAM_MASK) / VRAM_PROT_SEGMENT; page <= ((addr & VRAM_MASK) + size - 1) / VRAM_PROT_SEGMENT; page++)
 	{
 		std::vector<vram_lock>& block_list = vram_blocks[page];
 		for (auto it = block_list.begin(); it != block_list.end(); )
@@ -241,7 +241,7 @@ static u32 vmem32_map_mmu(u32 address, bool write)
 		u32 vpn = (entry->Address.VPN << 10) & ~(page_size - 1);
 		u32 ppn = (entry->Data.PPN << 10) & ~(page_size - 1);
 		u32 offset = vmem32_paddr_to_offset(ppn);
-		if (offset == (u32)-1)
+		if (offset == -1)
 			return VMEM32_ERROR_NOT_MAPPED;
 
 		bool allow_write = (entry->Data.PR & 1) != 0;
@@ -334,30 +334,27 @@ static u32 vmem32_map_address(u32 address, bool write)
 }
 
 #if !defined(NO_MMU) && defined(HOST_64BIT_CPU)
-// returns:
-//  0 if the fault address isn't handled by the mmu
-//  1 if the fault was handled and the access should be reattempted
-// -1 if an sh4 exception has been thrown
-int vmem32_handle_signal(void *fault_addr, bool write, u32 exception_pc)
+bool vmem32_handle_signal(void *fault_addr, bool write, u32 exception_pc)
 {
 	if (!vmem32_inited || (u8*)fault_addr < virt_ram_base || (u8*)fault_addr >= virt_ram_base + VMEM32_SIZE)
-		return 0;
+		return false;
 	//vmem32_page_faults++;
 	u32 guest_addr = (u8*)fault_addr - virt_ram_base;
 	u32 rv = vmem32_map_address(guest_addr, write);
 	DEBUG_LOG(VMEM, "vmem32_handle_signal handled signal %s @ %p -> %08x rv=%d", write ? "W" : "R", fault_addr, guest_addr, rv);
 	if (rv == MMU_ERROR_NONE)
-		return 1;
+		return true;
 	if (rv == VMEM32_ERROR_NOT_MAPPED)
-		return 0;
+		return false;
 #if HOST_CPU == CPU_ARM64
 	p_sh4rcb->cntx.pc = exception_pc;
 #else
 	p_sh4rcb->cntx.pc = p_sh4rcb->cntx.exception_pc;
 #endif
 	DoMMUException(guest_addr, rv, write ? MMU_TT_DWRITE : MMU_TT_DREAD);
-
-	return -1;
+	ngen_HandleException();
+	// not reached
+	return true;
 }
 #endif
 
diff --git a/core/hw/mem/vmem32.h b/core/hw/mem/vmem32.h
index 6bcc796..b233ee9 100644
--- a/core/hw/mem/vmem32.h
+++ b/core/hw/mem/vmem32.h
@@ -24,7 +24,7 @@
 
 bool vmem32_init();
 void vmem32_term();
-int vmem32_handle_signal(void *fault_addr, bool write, u32 exception_pc);
+bool vmem32_handle_signal(void *fault_addr, bool write, u32 exception_pc);
 void vmem32_flush_mmu();
 void vmem32_protect_vram(u32 addr, u32 size);
 void vmem32_unprotect_vram(u32 addr, u32 size);
diff --git a/core/hw/sh4/dyna/blockmanager.cpp b/core/hw/sh4/dyna/blockmanager.cpp
index 6d751b2..26df047 100644
--- a/core/hw/sh4/dyna/blockmanager.cpp
+++ b/core/hw/sh4/dyna/blockmanager.cpp
@@ -256,8 +256,8 @@ void bm_Reset()
 	}
 	if (_nvmem_4gb_space())
 	{
-		mem_region_unlock(virt_ram_base + 0x8C000000u, 0x90000000u - 0x8C000000u);
-		mem_region_unlock(virt_ram_base + 0xAC000000u, 0xB0000000u - 0xAC000000u);
+		mem_region_unlock(virt_ram_base + 0x8C000000, 0x90000000 - 0x8C000000);
+		mem_region_unlock(virt_ram_base + 0xAC000000, 0xB0000000 - 0xAC000000);
 	}
 }
 
diff --git a/core/hw/sh4/dyna/blockmanager.h b/core/hw/sh4/dyna/blockmanager.h
index c6d2823..8dda796 100644
--- a/core/hw/sh4/dyna/blockmanager.h
+++ b/core/hw/sh4/dyna/blockmanager.h
@@ -35,7 +35,7 @@ struct RuntimeBlockInfo: RuntimeBlockInfo_Core
 	fpscr_t fpu_cfg;
 	u32 guest_cycles;
 	u32 guest_opcodes;
-	u32 host_opcodes;	// set by host code generator, optional
+	u32 host_opcodes;
 	bool has_fpu_op;
 	u32 blockcheck_failures;
 	bool temp_block;
@@ -49,6 +49,7 @@ struct RuntimeBlockInfo: RuntimeBlockInfo_Core
 
 	u32 relink_offset;
 	u32 relink_data;
+	u32 csc_RetCache; //only for stats for now
 
 	BlockEndType BlockType;
 	bool has_jcond;
@@ -72,8 +73,12 @@ struct RuntimeBlockInfo: RuntimeBlockInfo_Core
 	void RemRef(RuntimeBlockInfoPtr other);
 
 	void Discard();
+	void UpdateRefs();
 	void SetProtectedFlags();
 
+	u32 memops;
+	u32 linkedmemops;
+	std::map<void*, u32> memory_accesses;	// key is host pc when access is made, value is opcode id
 	bool read_only;
 };
 
diff --git a/core/hw/sh4/dyna/decoder.cpp b/core/hw/sh4/dyna/decoder.cpp
index cd6fd4b..e804fb5 100644
--- a/core/hw/sh4/dyna/decoder.cpp
+++ b/core/hw/sh4/dyna/decoder.cpp
@@ -13,7 +13,6 @@
 #include "hw/sh4/sh4_opcode_list.h"
 #include "hw/sh4/sh4_core.h"
 #include "hw/sh4/sh4_mem.h"
-#include "hw/sh4/modules/mmu.h"
 #include "decoder_opcodes.h"
 #include "cfg/option.h"
 
@@ -103,13 +102,13 @@ static void dec_DynamicSet(u32 regbase,u32 offs=0)
 		Emit(shop_jdyn,reg_pc_dyn,mk_reg((Sh4RegType)regbase),mk_imm(offs));
 }
 
-static void dec_End(u32 dst, BlockEndType flags, bool delaySlot)
+static void dec_End(u32 dst,BlockEndType flags,bool delay)
 {
 	if (state.ngen.OnlyDynamicEnds && flags == BET_StaticJump)
 	{
-		Emit(shop_mov32, mk_reg(reg_nextpc), mk_imm(dst));
+		Emit(shop_mov32,mk_reg(reg_nextpc),mk_imm(dst));
 		dec_DynamicSet(reg_nextpc);
-		dec_End(NullAddress, BET_DynamicJump, delaySlot);
+		dec_End(0xFFFFFFFF,BET_DynamicJump,delay);
 		return;
 	}
 
@@ -118,14 +117,11 @@ static void dec_End(u32 dst, BlockEndType flags, bool delaySlot)
 		verify(flags == BET_DynamicJump);
 	}
 
-	state.BlockType = flags;
-	state.NextOp = delaySlot ? NDO_Delayslot : NDO_End;
-	state.DelayOp = NDO_End;
-	state.JumpAddr = dst;
-	if (flags != BET_StaticCall && flags != BET_StaticJump)
-		state.NextAddr = state.cpu.rpc + 2 + (delaySlot ? 2 : 0);
-	else
-		verify(state.JumpAddr != NullAddress);
+	state.BlockType=flags;
+	state.NextOp=delay?NDO_Delayslot:NDO_End;
+	state.DelayOp=NDO_End;
+	state.JumpAddr=dst;
+	state.NextAddr=state.cpu.rpc+2+(delay?2:0);
 }
 
 #define GetN(str) ((str>>8) & 0xf)
@@ -133,6 +129,9 @@ static void dec_End(u32 dst, BlockEndType flags, bool delaySlot)
 #define GetImm4(str) ((str>>0) & 0xf)
 #define GetImm8(str) ((str>>0) & 0xff)
 #define GetSImm8(str) ((s8)((str>>0) & 0xff))
+#define GetImm12(str) ((str>>0) & 0xfff)
+#define GetSImm12(str) (((s16)((GetImm12(str))<<4))>>4)
+
 
 #define SR_STATUS_MASK 0x700083F2
 #define SR_T_MASK 1
@@ -191,7 +190,7 @@ sh4dec(i0000_nnnn_0010_0011)
 	u32 n = GetN(op);
 
 	dec_DynamicSet(reg_r0+n,state.cpu.rpc + 4);
-	dec_End(NullAddress, BET_DynamicJump, true);
+	dec_End(0xFFFFFFFF,BET_DynamicJump,true);
 }
 //jmp @<REG_N>
 sh4dec(i0100_nnnn_0010_1011)
@@ -199,36 +198,39 @@ sh4dec(i0100_nnnn_0010_1011)
 	u32 n = GetN(op);
 
 	dec_DynamicSet(reg_r0+n);
-	dec_End(NullAddress, BET_DynamicJump, true);
+	dec_End(0xFFFFFFFF,BET_DynamicJump,true);
 }
 //bsr <bdisp12>
 sh4dec(i1011_iiii_iiii_iiii)
 {
+	//TODO: set PR
 	dec_set_pr();
-	dec_End(dec_jump_simm12(op), BET_StaticCall, true);
+	dec_End(dec_jump_simm12(op),BET_StaticCall,true);
 }
 //bsrf <REG_N>
 sh4dec(i0000_nnnn_0000_0011)
 {
 	u32 n = GetN(op);
+	//TODO: set PR
 	u32 retaddr=dec_set_pr();
 	dec_DynamicSet(reg_r0+n,retaddr);
-	dec_End(NullAddress, BET_DynamicCall, true);
+	dec_End(0xFFFFFFFF,BET_DynamicCall,true);
 }
 //jsr @<REG_N>
 sh4dec(i0100_nnnn_0000_1011) 
 {
 	u32 n = GetN(op);
 
+	//TODO: Set pr
 	dec_set_pr();
 	dec_DynamicSet(reg_r0+n);
-	dec_End(NullAddress, BET_DynamicCall, true);
+	dec_End(0xFFFFFFFF,BET_DynamicCall,true);
 }
 //rts
 sh4dec(i0000_0000_0000_1011)
 {
 	dec_DynamicSet(reg_pr);
-	dec_End(NullAddress, BET_DynamicRet, true);
+	dec_End(0xFFFFFFFF,BET_DynamicRet,true);
 }
 //rte
 sh4dec(i0000_0000_0010_1011)
@@ -237,7 +239,7 @@ sh4dec(i0000_0000_0010_1011)
 	dec_write_sr(reg_ssr);
 	Emit(shop_sync_sr);
 	dec_DynamicSet(reg_spc);
-	dec_End(NullAddress, BET_DynamicIntr, true);
+	dec_End(0xFFFFFFFF,BET_DynamicIntr,true);
 }
 //trapa #<imm>
 sh4dec(i1100_0011_iiii_iiii)
@@ -245,7 +247,7 @@ sh4dec(i1100_0011_iiii_iiii)
 	//TODO: ifb
 	dec_fallback(op);
 	dec_DynamicSet(reg_nextpc);
-	dec_End(NullAddress, BET_DynamicJump, false);
+	dec_End(0xFFFFFFFF,BET_DynamicJump,false);
 }
 //sleep
 sh4dec(i0000_0000_0001_1011)
@@ -253,7 +255,7 @@ sh4dec(i0000_0000_0001_1011)
 	//TODO: ifb
 	dec_fallback(op);
 	dec_DynamicSet(reg_nextpc);
-	dec_End(NullAddress, BET_DynamicJump, false);
+	dec_End(0xFFFFFFFF,BET_DynamicJump,false);
 }
 
 //ldc.l @<REG_N>+,SR
@@ -271,7 +273,7 @@ sh4dec(i0100_nnnn_0000_0111)
 		//FIXME only if interrupts got on .. :P
 		UpdateINTC();
 	}
-	dec_End(NullAddress,BET_StaticIntr,false);
+	dec_End(0xFFFFFFFF,BET_StaticIntr,false);
 }
 */
 
@@ -282,7 +284,7 @@ sh4dec(i0100_nnnn_0000_1110)
 
 	dec_write_sr((Sh4RegType)(reg_r0+n));
 	Emit(shop_sync_sr);
-	dec_End(NullAddress, BET_StaticIntr, false);
+	dec_End(0xFFFFFFFF,BET_StaticIntr,false);
 }
 
 //nop !
@@ -974,29 +976,16 @@ static void state_Setup(u32 rpc,fpscr_t fpu_cfg)
 	//verify(fpu_cfg.RM<2);	// Happens with many wince games (set to 3)
 	//what about fp/fs ?
 
-	state.NextOp = NDO_NextOp;
-	state.BlockType = BET_SCL_Intr;
-	state.JumpAddr = NullAddress;
-	state.NextAddr = NullAddress;
+	state.NextOp=NDO_NextOp;
+	state.BlockType=BET_SCL_Intr;
+	state.JumpAddr=0xFFFFFFFF;
+	state.NextAddr=0xFFFFFFFF;
 
 	state.info.has_readm=false;
 	state.info.has_writem=false;
 	state.info.has_fpu=false;
 }
 
-void dec_updateBlockCycles(RuntimeBlockInfo *block, u16 op)
-{
-	if (!mmu_enabled())
-	{
-		if (op < 0xF000)
-			block->guest_cycles++;
-	}
-	else
-	{
-		block->guest_cycles += std::max((int)OpDesc[op]->LatencyCycles, 1);
-	}
-}
-
 bool dec_DecodeBlock(RuntimeBlockInfo* rbi,u32 max_cycles)
 {
 	blk=rbi;
@@ -1027,8 +1016,15 @@ bool dec_DecodeBlock(RuntimeBlockInfo* rbi,u32 max_cycles)
 					u32 op = IReadMem16(state.cpu.rpc);
 
 					blk->guest_opcodes++;
-					dec_updateBlockCycles(blk, op);
-
+					if (!mmu_enabled())
+					{
+						if (op < 0xF000)
+							blk->guest_cycles++;
+					}
+					else
+					{
+						blk->guest_cycles += std::max((int)OpDesc[op]->LatencyCycles, 1);
+					}
 					if (OpDesc[op]->IsFloatingPoint())
 					{
 						if (sr.FD == 1)
@@ -1050,11 +1046,11 @@ bool dec_DecodeBlock(RuntimeBlockInfo* rbi,u32 max_cycles)
 							if (OpDesc[op]->SetPC())
 							{
 								dec_DynamicSet(reg_nextpc);
-								dec_End(NullAddress, BET_DynamicJump, false);
+								dec_End(0xFFFFFFFF,BET_DynamicJump,false);
 							}
-							else if (OpDesc[op]->SetFPSCR() && !state.cpu.is_delayslot)
+							if (OpDesc[op]->SetFPSCR() && !state.cpu.is_delayslot)
 							{
-								dec_End(state.cpu.rpc + 2, BET_StaticJump, false);
+								dec_End(state.cpu.rpc+2,BET_StaticJump,false);
 							}
 						}
 					}
@@ -1067,33 +1063,13 @@ bool dec_DecodeBlock(RuntimeBlockInfo* rbi,u32 max_cycles)
 			}
 			break;
 
+		case NDO_Jump:
+			die("Too old");
+			//state.NextOp=state.JumpOp;
+			//state.cpu.rpc=state.JumpAddr;
+			break;
+
 		case NDO_End:
-			// Disabled for now since we need to know if the block is read-only,
-			// which isn't determined until after the decoding.
-			// This is a relatively rare optimization anyway
-#if 0
-			// detect if calling an empty subroutine and skip it
-			if (state.BlockType == BET_StaticCall && blk->read_only)
-			{
-				if ((state.JumpAddr >> 12) == (blk->vaddr >> 12)
-						|| (state.JumpAddr >> 12) == ((blk->vaddr + (blk->guest_opcodes - 1) * 2) >> 12))
-				{
-					u32 op = IReadMem16(state.JumpAddr);
-					if (op == 0x000B)	// rts
-					{
-						u16 delayOp = IReadMem16(state.JumpAddr + 2);
-						if (delayOp == 0x0000 || delayOp == 0x0009)	// nop
-						{
-							state.NextOp = NDO_NextOp;
-							state.cpu.is_delayslot = false;
-							dec_updateBlockCycles(blk, op);
-							dec_updateBlockCycles(blk, delayOp);
-							continue;
-						}
-					}
-				}
-			}
-#endif
 			goto _end;
 		}
 	}
diff --git a/core/hw/sh4/dyna/decoder.h b/core/hw/sh4/dyna/decoder.h
index 5398e14..4fb843f 100644
--- a/core/hw/sh4/dyna/decoder.h
+++ b/core/hw/sh4/dyna/decoder.h
@@ -35,6 +35,7 @@ enum NextDecoderOperation
 	NDO_NextOp,     //pc+=2
 	NDO_End,        //End the block, Type = BlockEndType
 	NDO_Delayslot,  //pc+=2, NextOp=DelayOp
+	NDO_Jump,       //pc=JumpAddr,NextOp=JumpOp
 };
 //ngen features
 struct ngen_features
@@ -45,12 +46,12 @@ struct ngen_features
 
 struct RuntimeBlockInfo;
 bool dec_DecodeBlock(RuntimeBlockInfo* rbi,u32 max_cycles);
-void dec_updateBlockCycles(RuntimeBlockInfo *block, u16 op);
 
 struct state_t
 {
 	NextDecoderOperation NextOp;
 	NextDecoderOperation DelayOp;
+	NextDecoderOperation JumpOp;
 	u32 JumpAddr;
 	u32 NextAddr;
 	BlockEndType BlockType;
@@ -72,8 +73,5 @@ struct state_t
 		bool has_writem;
 		bool has_fpu;
 	} info;
-};
 
-const u32 NullAddress = 0xFFFFFFFF;
-#define GetImm12(str) ((str>>0) & 0xfff)
-#define GetSImm12(str) (((short)((GetImm12(str))<<4))>>4)
+} ;
diff --git a/core/hw/sh4/dyna/driver.cpp b/core/hw/sh4/dyna/driver.cpp
index b3adb8b..b3b5b03 100644
--- a/core/hw/sh4/dyna/driver.cpp
+++ b/core/hw/sh4/dyna/driver.cpp
@@ -150,9 +150,8 @@ bool RuntimeBlockInfo::Setup(u32 rpc,fpscr_t rfpu_cfg)
 	pBranchBlock=pNextBlock=0;
 	code=0;
 	has_jcond=false;
-	BranchBlock = NullAddress;
-	NextBlock = NullAddress;
-	BlockType = BET_SCL_Intr;
+	BranchBlock=NextBlock=csc_RetCache=0xFFFFFFFF;
+	BlockType=BET_SCL_Intr;
 	has_fpu_op = false;
 	temp_block = false;
 	
diff --git a/core/hw/sh4/dyna/ngen.h b/core/hw/sh4/dyna/ngen.h
index 212eee0..a45994f 100644
--- a/core/hw/sh4/dyna/ngen.h
+++ b/core/hw/sh4/dyna/ngen.h
@@ -43,7 +43,6 @@
 #pragma once
 #include "decoder.h"
 #include "blockmanager.h"
-#include "oslib/host_context.h"
 
 #define CODE_SIZE   (10*1024*1024)
 #ifdef NO_MMU
@@ -112,8 +111,7 @@ extern void (*ngen_FailedToFindBlock)();
 void ngen_mainloop(void* cntx);
 
 void ngen_GetFeatures(ngen_features* dst);
-void ngen_HandleException(host_context_t &context);
-bool ngen_Rewrite(host_context_t &context, void *faultAddress);
+void ngen_HandleException();
 
 //Canonical callback interface
 enum CanonicalParamType
diff --git a/core/hw/sh4/dyna/ssa.cpp b/core/hw/sh4/dyna/ssa.cpp
index 9288e62..8baee71 100644
--- a/core/hw/sh4/dyna/ssa.cpp
+++ b/core/hw/sh4/dyna/ssa.cpp
@@ -249,7 +249,7 @@ bool SSAOptimizer::ExecuteConstOp(shil_opcode* op)
 					block->BranchBlock = block->NextBlock;
 				}
 				block->BlockType = BET_StaticJump;
-				block->NextBlock = NullAddress;
+				block->NextBlock = 0xFFFFFFFF;
 				block->has_jcond = false;
 				// same remark regarding jdyn as in the previous case
 				block->oplist.erase(block->oplist.begin() + opnum);
diff --git a/core/hw/sh4/dyna/ssa.h b/core/hw/sh4/dyna/ssa.h
index e27b35e..73daff9 100644
--- a/core/hw/sh4/dyna/ssa.h
+++ b/core/hw/sh4/dyna/ssa.h
@@ -50,7 +50,6 @@ public:
 		CombineShiftsPass();
 		DeadRegisterPass();
 		IdentityMovePass();
-		SingleBranchTargetPass();
 
 #if DEBUG
 		if (stats.prop_constants > 0 || stats.dead_code_ops > 0 || stats.constant_ops_replaced > 0
@@ -715,50 +714,6 @@ private:
 		}
 	}
 
-	bool skipSingleBranchTarget(u32& addr, bool updateCycles)
-	{
-		if (addr == NullAddress)
-			return false;
-		bool success = false;
-		while (true)
-		{
-			if ((addr >> 12) != (block->vaddr >> 12)
-					&& (addr >> 12) != ((block->vaddr + (block->guest_opcodes - 1) * 2) >> 12))
-				break;
-
-			u32 op = IReadMem16(addr);
-			// Axxx: bra <bdisp12>
-			if ((op & 0xF000) != 0xA000)
-				break;
-
-			u16 delayOp = IReadMem16(addr + 2);
-			if (delayOp != 0x0000 && delayOp != 0x0009)	// nop
-				break;
-
-			int disp = GetSImm12(op) * 2 + 4;
-			if (disp == 0)
-				// infiniloop
-				break;
-			addr += disp;
-			if (updateCycles)
-			{
-				dec_updateBlockCycles(block, op);
-				dec_updateBlockCycles(block, delayOp);
-			}
-			success = true;
-		}
-		return success;
-	}
-
-	void SingleBranchTargetPass()
-	{
-		if (block->read_only)
-		{
-			bool updateCycles = !skipSingleBranchTarget(block->BranchBlock, true);
-			skipSingleBranchTarget(block->NextBlock, updateCycles);
-		}
-	}
-
 	RuntimeBlockInfo* block;
 	std::set<RegValue> writeback_values;
 
diff --git a/core/hw/sh4/interpr/sh4_opcodes.cpp b/core/hw/sh4/interpr/sh4_opcodes.cpp
index 0684a8e..56b75fd 100644
--- a/core/hw/sh4/interpr/sh4_opcodes.cpp
+++ b/core/hw/sh4/interpr/sh4_opcodes.cpp
@@ -28,6 +28,7 @@
 #define GetSImm12(str) (((s16)((GetImm12(str))<<4))>>4)
 
 #define iNimp cpu_iNimp
+#define iWarn cpu_iWarn
 
 //Read Mem macros
 
@@ -60,6 +61,11 @@ void cpu_iNimp(u32 op, const char* info)
 	//sh4_cpu.Stop();
 }
 
+void cpu_iWarn(u32 op, const char* info)
+{
+	INFO_LOG(INTERPRETER, "Check opcode : %X : %s @ %X", op, info, curr_pc);
+}
+
 //this file contains ALL register to register full moves
 //
 
@@ -819,6 +825,7 @@ sh4op(i0000_nnnn_1100_0011)
 {
 	u32 n = GetN(op);
 	WriteMemU32(r[n],r[0]);//at r[n],r[0]
+	//iWarn(op, "movca.l R0, @<REG_N>");
 	// TODO ocache
 }
 
@@ -946,6 +953,7 @@ sh4op(i1010_iiii_iiii_iiii)
 // bsr <bdisp12>
 sh4op(i1011_iiii_iiii_iiii)
 {
+	//TODO: check pr vs real h/w
 	u32 newpr = next_pc + 2; //return after delayslot
 	u32 newpc = branch_target_s12(op);
 	ExecuteDelayslot();
@@ -977,6 +985,7 @@ sh4op(i0100_nnnn_0000_1011)
 {
 	u32 n = GetN(op);
 
+	//TODO: check pr vs real h/w
 	u32 newpr = next_pc + 2;   //return after delayslot
 	u32 newpc= r[n];
 	ExecuteDelayslot(); //r[n]/pr can change here
@@ -1222,17 +1231,17 @@ INLINE void DYNACALL do_sqw(u32 Dest)
 }
 
 void DYNACALL do_sqw_mmu(u32 dst) { do_sqw<true>(dst); }
-#if HOST_CPU != CPU_ARM
+#if HOST_CPU != CPU_ARM && HOST_CPU != CPU_ARM64
 //yes, this micro optimization makes a difference
-extern "C" void DYNACALL do_sqw_nommu_area_3(u32 dst, u8 *sqb)
+extern "C" void DYNACALL do_sqw_nommu_area_3(u32 dst,u8* sqb)
 {
-	u8 *pmem = sqb + sizeof(Sh4RCB::sq_buffer) + sizeof(Sh4RCB::cntx) + 0x0C000000;
+	u8* pmem=sqb+512+0x0C000000;
 
-	memcpy((u64 *)&pmem[dst & (RAM_SIZE_MAX - 1 - 0x1F)], (u64 *)&sqb[dst & 0x20], 32);
+	memcpy((u64*)&pmem[dst&(RAM_MASK-0x1F)],(u64*)&sqb[dst & 0x20],32);
 }
 #endif
 
-void DYNACALL do_sqw_nommu_area_3_nonvmem(u32 dst,u8* sqb)
+extern "C" void DYNACALL do_sqw_nommu_area_3_nonvmem(u32 dst,u8* sqb)
 {
 	u8* pmem = mem_b.data;
 
diff --git a/core/hw/sh4/modules/fastmmu.cpp b/core/hw/sh4/modules/fastmmu.cpp
index c12c989..afebe60 100644
--- a/core/hw/sh4/modules/fastmmu.cpp
+++ b/core/hw/sh4/modules/fastmmu.cpp
@@ -82,6 +82,7 @@ bool find_entry_by_page_size(u32 address, const TLB_Entry **ret_entry)
 	u32 vpn = (address >> (10 + shift)) << shift;
 	u16 bucket = bucket_index(vpn << 10, size);
 	TLB_LinkedEntry *pEntry = entry_buckets[bucket];
+	u32 length = 0;
 	while (pEntry != NULL)
 	{
 		if (pEntry->entry.Address.VPN == vpn && (size >> 1) == pEntry->entry.Data.SZ1 && (size & 1) == pEntry->entry.Data.SZ0)
diff --git a/core/hw/sh4/modules/wince.h b/core/hw/sh4/modules/wince.h
index 696abed..1de81cf 100644
--- a/core/hw/sh4/modules/wince.h
+++ b/core/hw/sh4/modules/wince.h
@@ -360,17 +360,16 @@ static bool wince_resolve_address(u32 va, TLB_Entry &entry)
 	// WinCE hack
 	if ((va & 0x80000000) == 0)
 	{
-		const u32 ram_mask = RAM_MASK;
-		u32 page_group = *(u32 *)&mem_b[(CCN_TTB + ((va >> 25) << 2)) & ram_mask];
+		u32 page_group = ReadMem32_nommu(CCN_TTB + ((va >> 25) << 2));
 		u32 page = ((va >> 16) & 0x1ff) << 2;
-		u32 paddr = *(u32 *)&mem_b[(page_group + page) & ram_mask];
+		u32 paddr = ReadMem32_nommu(page_group + page);
 		if (paddr & 0x80000000)
 		{
-			u32 whatever = *(u32 *)&mem_b[(r_bank[4] + 0x14) & ram_mask];
-			if (whatever != *(u32 *)&mem_b[paddr & ram_mask])
+			u32 whatever = ReadMem32_nommu(r_bank[4] + 0x14);
+			if (whatever != ReadMem32_nommu(paddr))
 			{
 				paddr += 12;
-				u32 ptel = *(u32 *)&mem_b[(paddr + ((va >> 10) & 0x3c)) & ram_mask];
+				u32 ptel = ReadMem32_nommu(paddr + ((va >> 10) & 0x3c));
 				//FIXME CCN_PTEA = paddr >> 29;
 				if (ptel != 0)
 				{
diff --git a/core/hw/sh4/sh4_if.h b/core/hw/sh4/sh4_if.h
index ff4f34c..6e1fda9 100644
--- a/core/hw/sh4/sh4_if.h
+++ b/core/hw/sh4/sh4_if.h
@@ -296,7 +296,7 @@ struct Sh4Context
 
 void DYNACALL do_sqw_mmu(u32 dst);
 extern "C" void DYNACALL do_sqw_nommu_area_3(u32 dst, u8* sqb);
-void DYNACALL do_sqw_nommu_area_3_nonvmem(u32 dst, u8* sqb);
+extern "C" void DYNACALL do_sqw_nommu_area_3_nonvmem(u32 dst, u8* sqb);
 void DYNACALL do_sqw_nommu_full(u32 dst, u8* sqb);
 
 typedef void DYNACALL sqw_fp(u32 dst,u8* sqb);
diff --git a/core/linux/common.cpp b/core/linux/common.cpp
index 9a53137..05ecc0f 100644
--- a/core/linux/common.cpp
+++ b/core/linux/common.cpp
@@ -16,21 +16,20 @@
 #include "hw/sh4/dyna/blockmanager.h"
 #include "hw/mem/vmem32.h"
 
-#include "oslib/host_context.h"
+#include "linux/context.h"
 
 #include "hw/sh4/dyna/ngen.h"
 
 #if !defined(TARGET_NO_EXCEPTIONS)
+bool ngen_Rewrite(unat& addr,unat retadr,unat acc);
+u32* ngen_readm_fail_v2(u32* ptr,u32* regs,u32 saddr);
 bool VramLockedWrite(u8* address);
 bool BM_LockedWrite(u8* address);
 
-void context_from_segfault(host_context_t* hctx, void* segfault_ctx);
-void context_to_segfault(host_context_t* hctx, void* segfault_ctx);
-
 #if defined(__APPLE__)
 void sigill_handler(int sn, siginfo_t * si, void *segfault_ctx) {
 	
-	host_context_t ctx;
+    rei_host_context_t ctx;
     
     context_from_segfault(&ctx, segfault_ctx);
 
@@ -46,12 +45,13 @@ void sigill_handler(int sn, siginfo_t * si, void *segfault_ctx) {
 
 void fault_handler (int sn, siginfo_t * si, void *segfault_ctx)
 {
+	rei_host_context_t ctx;
+	context_from_segfault(&ctx, segfault_ctx);
+
+	bool dyna_cde = ((unat)CC_RX2RW(ctx.pc) > (unat)CodeCache) && ((unat)CC_RX2RW(ctx.pc) < (unat)(CodeCache + CODE_SIZE + TEMP_CODE_SIZE));
+
 #if !defined(NO_MMU) && defined(HOST_64BIT_CPU)
-	// WinCE virtual memory
 #if HOST_CPU == CPU_ARM64
-#define HOST_CTX_READY
-	host_context_t ctx;
-	context_from_segfault(&ctx, segfault_ctx);
 	u32 op = *(u32*)ctx.pc;
 	bool write = (op & 0x00400000) == 0;
 	u32 exception_pc = ctx.x2;
@@ -59,49 +59,52 @@ void fault_handler (int sn, siginfo_t * si, void *segfault_ctx)
 	bool write = false;	// TODO?
 	u32 exception_pc = 0;
 #endif
-	int rv = vmem32_handle_signal(si->si_addr, write, exception_pc);
-	if (rv == 1)
+	if (vmem32_handle_signal(si->si_addr, write, exception_pc))
 		return;
-	if (rv == -1)
-	{
-#ifndef HOST_CTX_READY
-		host_context_t ctx;
-		context_from_segfault(&ctx, segfault_ctx);
-#endif
-		ngen_HandleException(ctx);
-		context_to_segfault(&ctx, segfault_ctx);
-		return;
-	}
 #endif
-	// code protection in RAM
 	if (bm_RamWriteAccess(si->si_addr))
 		return;
-	// texture protection in VRAM
-	if (VramLockedWrite((u8*)si->si_addr))
+	if (VramLockedWrite((u8*)si->si_addr) || BM_LockedWrite((u8*)si->si_addr))
 		return;
-	// FPCB jump table protection
-	if (BM_LockedWrite((u8*)si->si_addr))
-		return;
-
-#if FEAT_SHREC == DYNAREC_JIT
-	// fast mem access rewriting
-#ifndef HOST_CTX_READY
-	host_context_t ctx;
-	context_from_segfault(&ctx, segfault_ctx);
-#endif
-	bool dyna_cde = ((unat)CC_RX2RW(ctx.pc) >= (unat)CodeCache) && ((unat)CC_RX2RW(ctx.pc) < (unat)(CodeCache + CODE_SIZE + TEMP_CODE_SIZE));
-
-	if (dyna_cde && ngen_Rewrite(ctx, si->si_addr))
+	#if FEAT_SHREC == DYNAREC_JIT
+		#if HOST_CPU==CPU_ARM
+			else if (dyna_cde)
+			{
+				ctx.pc = (u32)ngen_readm_fail_v2((u32*)ctx.pc, ctx.r, (unat)si->si_addr);
+
+				context_to_segfault(&ctx, segfault_ctx);
+			}
+		#elif HOST_CPU==CPU_X86
+			else if (ngen_Rewrite((unat&)ctx.pc, *(unat*)ctx.esp, ctx.eax))
+			{
+				//remove the call from call stack
+				ctx.esp += 4;
+				//restore the addr from eax to ecx so it's valid again
+				ctx.ecx = ctx.eax;
+
+				context_to_segfault(&ctx, segfault_ctx);
+			}
+		#elif HOST_CPU == CPU_X64
+			else if (dyna_cde && ngen_Rewrite((unat&)ctx.pc, 0, 0))
+			{
+				context_to_segfault(&ctx, segfault_ctx);
+			}
+		#elif HOST_CPU == CPU_ARM64
+			else if (dyna_cde && ngen_Rewrite(ctx.pc, 0, 0))
+			{
+				context_to_segfault(&ctx, segfault_ctx);
+			}
+		#else
+			#error JIT: Not supported arch
+		#endif
+	#endif
+	else
 	{
-		context_to_segfault(&ctx, segfault_ctx);
-		return;
+		ERROR_LOG(COMMON, "SIGSEGV @ %zx -> %p was not in vram, dynacode:%d", ctx.pc, si->si_addr, dyna_cde);
+		die("segfault");
+		signal(SIGSEGV, SIG_DFL);
 	}
-#endif
-	ERROR_LOG(COMMON, "SIGSEGV @ %p -> %p was not in vram, dynacode:%d", (void *)ctx.pc, si->si_addr, dyna_cde);
-	die("segfault");
-	signal(SIGSEGV, SIG_DFL);
 }
-#undef HOST_CTX_READY
 
 void install_fault_handler(void)
 {
diff --git a/core/linux/context.cpp b/core/linux/context.cpp
index 293b899..b61c3b4 100644
--- a/core/linux/context.cpp
+++ b/core/linux/context.cpp
@@ -1,4 +1,4 @@
-#include "oslib/host_context.h"
+#include "context.h"
 
 #if defined(__ANDROID__)
 	#include <asm/sigcontext.h>
@@ -17,93 +17,76 @@
 //////
 
 #define MCTX(p) (((ucontext_t *)(segfault_ctx))->uc_mcontext p)
-template <bool ToSegfault, typename Tctx, typename Tseg>
-static void bicopy(Tctx& ctx, Tseg& seg)
-{
-	static_assert(sizeof(Tctx) == sizeof(Tseg), "Invalid assignment");
-	if (ToSegfault)
-		seg = (Tseg)ctx;
-	else
-		ctx = (Tctx)seg;
+template <typename Ta, typename Tb>
+void bicopy(Ta& rei, Tb& seg, bool to_segfault) {
+	if (to_segfault) {
+		seg = rei;
+	}
+	else {
+		rei = seg;
+	}
 }
 
-template<bool ToSegfault>
-static void context_segfault(host_context_t* hostctx, void* segfault_ctx)
-{
+void context_segfault(rei_host_context_t* reictx, void* segfault_ctx, bool to_segfault) {
+
 #if !defined(TARGET_NO_EXCEPTIONS)
 #if HOST_CPU == CPU_ARM
 	#if defined(__FreeBSD__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.__gregs[_REG_PC]));
+		bicopy(reictx->pc, MCTX(.__gregs[_REG_PC]), to_segfault);
 
 		for (int i = 0; i < 15; i++)
-			bicopy<ToSegfault>(hostctx->reg[i], MCTX(.__gregs[i]));
+			bicopy(reictx->r[i], MCTX(.__gregs[i]), to_segfault);
 	#elif HOST_OS == OS_LINUX
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.arm_pc));
-		u32* reg =(u32*) &MCTX(.arm_r0);
+		bicopy(reictx->pc, MCTX(.arm_pc), to_segfault);
+		u32* r =(u32*) &MCTX(.arm_r0);
 
 		for (int i = 0; i < 15; i++)
-			bicopy<ToSegfault>(hostctx->reg[i], reg[i]);
+			bicopy(reictx->r[i], r[i], to_segfault);
 
 	#elif defined(__APPLE__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(->__ss.__pc));
+		bicopy(reictx->pc, MCTX(->__ss.__pc), to_segfault);
 
 		for (int i = 0; i < 15; i++)
-			bicopy<ToSegfault>(hostctx->reg[i], MCTX(->__ss.__r[i]));
+			bicopy(reictx->r[i], MCTX(->__ss.__r[i]), to_segfault);
 	#else
 		#error HOST_OS
 	#endif
 #elif HOST_CPU == CPU_ARM64
-	#if defined(__APPLE__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(->__ss.__pc));
-		bicopy<ToSegfault>(hostctx->sp, MCTX(->__ss.__sp));
-		bicopy<ToSegfault>(hostctx->x2, MCTX(->__ss.__x[2]));
- 	#else
- 		bicopy<ToSegfault>(hostctx->pc, MCTX(.pc));
- 		bicopy<ToSegfault>(hostctx->sp, MCTX(.sp));
- 		bicopy<ToSegfault>(hostctx->x2, MCTX(.regs[2]));
- 	#endif
+	bicopy(reictx->pc, MCTX(.pc), to_segfault);
+	bicopy(reictx->x2, MCTX(.regs[2]), to_segfault);
 #elif HOST_CPU == CPU_X86
 	#if defined(__FreeBSD__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.mc_eip));
-		bicopy<ToSegfault>(hostctx->esp, MCTX(.mc_esp));
-		bicopy<ToSegfault>(hostctx->eax, MCTX(.mc_eax));
-		bicopy<ToSegfault>(hostctx->ecx, MCTX(.mc_ecx));
+		bicopy(reictx->pc, MCTX(.mc_eip), to_segfault);
+		bicopy(reictx->esp, MCTX(.mc_esp), to_segfault);
+		bicopy(reictx->eax, MCTX(.mc_eax), to_segfault);
+		bicopy(reictx->ecx, MCTX(.mc_ecx), to_segfault);
 	#elif HOST_OS == OS_LINUX
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.gregs[REG_EIP]));
-		bicopy<ToSegfault>(hostctx->esp, MCTX(.gregs[REG_ESP]));
-		bicopy<ToSegfault>(hostctx->eax, MCTX(.gregs[REG_EAX]));
-		bicopy<ToSegfault>(hostctx->ecx, MCTX(.gregs[REG_ECX]));
+		bicopy(reictx->pc, MCTX(.gregs[REG_EIP]), to_segfault);
+		bicopy(reictx->esp, MCTX(.gregs[REG_ESP]), to_segfault);
+		bicopy(reictx->eax, MCTX(.gregs[REG_EAX]), to_segfault);
+		bicopy(reictx->ecx, MCTX(.gregs[REG_ECX]), to_segfault);
 	#elif defined(__APPLE__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(->__ss.__eip));
-		bicopy<ToSegfault>(hostctx->esp, MCTX(->__ss.__esp));
-		bicopy<ToSegfault>(hostctx->eax, MCTX(->__ss.__eax));
-		bicopy<ToSegfault>(hostctx->ecx, MCTX(->__ss.__ecx));
+		bicopy(reictx->pc, MCTX(->__ss.__eip), to_segfault);
+		bicopy(reictx->esp, MCTX(->__ss.__esp), to_segfault);
+		bicopy(reictx->eax, MCTX(->__ss.__eax), to_segfault);
+		bicopy(reictx->ecx, MCTX(->__ss.__ecx), to_segfault);
 	#else
 		#error HOST_OS
 	#endif
 #elif HOST_CPU == CPU_X64
 	#if defined(__FreeBSD__) || defined(__DragonFly__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.mc_rip));
+		bicopy(reictx->pc, MCTX(.mc_rip), to_segfault);
 	#elif defined(__NetBSD__)
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.__gregs[_REG_RIP]));
-		bicopy<ToSegfault>(hostctx->rsp, MCTX(.__gregs[REG_RSP]));
-		bicopy<ToSegfault>(hostctx->r9, MCTX(.__gregs[REG_R9]));
-		bicopy<ToSegfault>(hostctx->rdi, MCTX(.__gregs[REG_RDI]));
+		bicopy(reictx->pc, MCTX(.__gregs[_REG_RIP]), to_segfault);
 	#elif HOST_OS == OS_LINUX
-		bicopy<ToSegfault>(hostctx->pc, MCTX(.gregs[REG_RIP]));
-		bicopy<ToSegfault>(hostctx->rsp, MCTX(.gregs[REG_RSP]));
-		bicopy<ToSegfault>(hostctx->r9, MCTX(.gregs[REG_R9]));
-		bicopy<ToSegfault>(hostctx->rdi, MCTX(.gregs[REG_RDI]));
+		bicopy(reictx->pc, MCTX(.gregs[REG_RIP]), to_segfault);
     #elif defined(__APPLE__)
-        bicopy<ToSegfault>(hostctx->pc, MCTX(->__ss.__rip));
-		bicopy<ToSegfault>(hostctx->rsp, MCTX(->__ss.__rsp));
-		bicopy<ToSegfault>(hostctx->r9, MCTX(->__ss.__r9));
-		bicopy<ToSegfault>(hostctx->rdi, MCTX(->__ss.__rdi));
+        bicopy(reictx->pc, MCTX(->__ss.__rip), to_segfault);
     #else
 	    #error HOST_OS
 	#endif
 #elif HOST_CPU == CPU_MIPS
-	bicopy<ToSegfault>(hostctx->pc, MCTX(.pc));
+	bicopy(reictx->pc, MCTX(.pc), to_segfault);
 #elif HOST_CPU == CPU_GENERIC
     //nothing!
 #else
@@ -113,10 +96,10 @@ static void context_segfault(host_context_t* hostctx, void* segfault_ctx)
 	
 }
 
-void context_from_segfault(host_context_t* hostctx, void* segfault_ctx) {
-	context_segfault<false>(hostctx, segfault_ctx);
+void context_from_segfault(rei_host_context_t* reictx, void* segfault_ctx) {
+	context_segfault(reictx, segfault_ctx, false);
 }
 
-void context_to_segfault(host_context_t* hostctx, void* segfault_ctx) {
-	context_segfault<true>(hostctx, segfault_ctx);
+void context_to_segfault(rei_host_context_t* reictx, void* segfault_ctx) {
+	context_segfault(reictx, segfault_ctx, true);
 }
diff --git a/core/oslib/host_context.h b/core/linux/context.h
similarity index 51%
rename from core/oslib/host_context.h
rename to core/linux/context.h
index 3048ba7..bcfceaa 100644
--- a/core/oslib/host_context.h
+++ b/core/linux/context.h
@@ -1,7 +1,9 @@
 #pragma once
+
 #include "types.h"
 
-struct host_context_t {
+
+struct rei_host_context_t {
 #if HOST_CPU != CPU_GENERIC
 	unat pc;
 #endif
@@ -10,18 +12,12 @@ struct host_context_t {
 	u32 eax;
 	u32 ecx;
 	u32 esp;
-#elif HOST_CPU == CPU_X64
-	u64 rsp;
-	u64 r9;
-#ifdef _WIN32
-	u64 rcx;
-#else
-	u64 rdi;
-#endif
 #elif HOST_CPU == CPU_ARM
-	u32 reg[15];
+	u32 r[15];
 #elif HOST_CPU == CPU_ARM64
-	u64 sp;
 	u64 x2;
 #endif
 };
+
+void context_from_segfault(rei_host_context_t* reictx, void* segfault_ctx);
+void context_to_segfault(rei_host_context_t* reictx, void* segfault_ctx);
diff --git a/core/linux/posix_vmem.cpp b/core/linux/posix_vmem.cpp
index 6916e3d..cc94f11 100644
--- a/core/linux/posix_vmem.cpp
+++ b/core/linux/posix_vmem.cpp
@@ -291,10 +291,6 @@ bool vmem_platform_prepare_jit_block(void *code_area, unsigned size, void **code
 
 #if HOST_CPU == CPU_ARM64
 
-#if defined(__APPLE__)
-#include <libkern/OSCacheControl.h>
-#endif
-
 // Code borrowed from Dolphin https://github.com/dolphin-emu/dolphin
 static void Arm64_CacheFlush(void* start, void* end) {
 	if (start == end)
@@ -302,7 +298,7 @@ static void Arm64_CacheFlush(void* start, void* end) {
 
 #if defined(__APPLE__)
 	// Header file says this is equivalent to: sys_icache_invalidate(start, end - start);
-	sys_cache_control(kCacheFunctionPrepareForExecution, start, (uintptr_t)end - (uintptr_t)start);
+	sys_cache_control(kCacheFunctionPrepareForExecution, start, end - start);
 #else
 	// Don't rely on GCC's __clear_cache implementation, as it caches
 	// icache/dcache cache line sizes, that can vary between cores on
@@ -344,131 +340,5 @@ void vmem_platform_flush_cache(void *icache_start, void *icache_end, void *dcach
 		Arm64_CacheFlush(icache_start, icache_end);
 }
 
-#elif HOST_CPU == CPU_ARM
-
-#if HOST_OS == OS_DARWIN
-
-#include <libkern/OSCacheControl.h>
-static void CacheFlush(void* code, void* pEnd)
-{
-    sys_dcache_flush(code, (u8*)pEnd - (u8*)code + 1);
-    sys_icache_invalidate(code, (u8*)pEnd - (u8*)code + 1);
-}
-
-#elif !defined(ARMCC)
-
-#ifdef __ANDROID__
-#include <sys/syscall.h>  // for cache flushing.
-#endif
-
-static void CacheFlush(void* code, void* pEnd)
-{
-#if !defined(__ANDROID__)
-	__clear_cache((void*)code, pEnd);
-#else // defined(__ANDROID__)
-	void* start=code;
-	size_t size=(u8*)pEnd-(u8*)start+4;
-
-  // Ideally, we would call
-  //   syscall(__ARM_NR_cacheflush, start,
-  //           reinterpret_cast<intptr_t>(start) + size, 0);
-  // however, syscall(int, ...) is not supported on all platforms, especially
-  // not when using EABI, so we call the __ARM_NR_cacheflush syscall directly.
-
-  register uint32_t beg asm("a1") = reinterpret_cast<uint32_t>(start);
-  register uint32_t end asm("a2") = reinterpret_cast<uint32_t>(start) + size;
-  register uint32_t flg asm("a3") = 0;
-
-  #ifdef __ARM_EABI__
-    #if defined (__arm__) && !defined(__thumb__)
-      // __arm__ may be defined in thumb mode.
-      register uint32_t scno asm("r7") = __ARM_NR_cacheflush;
-      asm volatile(
-          "svc 0x0"
-          : "=r" (beg)
-          : "0" (beg), "r" (end), "r" (flg), "r" (scno));
-    #else
-      // r7 is reserved by the EABI in thumb mode.
-      asm volatile(
-      "@   Enter ARM Mode  \n\t"
-          "adr r3, 1f      \n\t"
-          "bx  r3          \n\t"
-          ".ALIGN 4        \n\t"
-          ".ARM            \n"
-      "1:  push {r7}       \n\t"
-          "mov r7, %4      \n\t"
-          "svc 0x0         \n\t"
-          "pop {r7}        \n\t"
-      "@   Enter THUMB Mode\n\t"
-          "adr r3, 2f+1    \n\t"
-          "bx  r3          \n\t"
-          ".THUMB          \n"
-      "2:                  \n\t"
-          : "=r" (beg)
-          : "0" (beg), "r" (end), "r" (flg), "r" (__ARM_NR_cacheflush)
-          : "r3");
-    #endif // !defined (__arm__) || defined(__thumb__)
-  #else // ! __ARM_EABI__
-    #if defined (__arm__) && !defined(__thumb__)
-      // __arm__ may be defined in thumb mode.
-      asm volatile(
-          "svc %1"
-          : "=r" (beg)
-          : "i" (__ARM_NR_cacheflush), "0" (beg), "r" (end), "r" (flg));
-    #else
-      // Do not use the value of __ARM_NR_cacheflush in the inline assembly
-      // below, because the thumb mode value would be used, which would be
-      // wrong, since we switch to ARM mode before executing the svc instruction
-      asm volatile(
-      "@   Enter ARM Mode  \n\t"
-          "adr r3, 1f      \n\t"
-          "bx  r3          \n\t"
-          ".ALIGN 4        \n\t"
-          ".ARM            \n"
-      "1:  svc 0x9f0002    \n"
-      "@   Enter THUMB Mode\n\t"
-          "adr r3, 2f+1    \n\t"
-          "bx  r3          \n\t"
-          ".THUMB          \n"
-      "2:                  \n\t"
-          : "=r" (beg)
-          : "0" (beg), "r" (end), "r" (flg)
-          : "r3");
-    #endif // !defined (__arm__) || defined(__thumb__)
-  #endif // !__ARM_EABI__
-	#if 0
-		const int syscall = 0xf0002;
-		__asm __volatile (
-			"mov     r0, %0\n"
-			"mov     r1, %1\n"
-			"mov     r7, %2\n"
-			"mov     r2, #0x0\n"
-			"svc     0x00000000\n"
-			:
-			:   "r" (code), "r" (pEnd), "r" (syscall)
-			:   "r0", "r1", "r7"
-			);
-	#endif
-#endif // defined(__ANDROID__)
-}
-#else // defined(ARMCC)
-asm static void CacheFlush(void* code, void* pEnd)
-{
-	ARM
-	push {r7}
-	//add r1, r1, r0
-	mov r7, #0xf0000
-	add r7, r7, #0x2
-	mov r2, #0x0
-	svc #0x0
-	pop {r7}
-	bx lr
-}
-#endif
-
-void vmem_platform_flush_cache(void *icache_start, void *icache_end, void *dcache_start, void *dcache_end)
-{
-	CacheFlush(icache_start, icache_end);
-}
-#endif // #if HOST_CPU == CPU_ARM
+#endif // #if HOST_CPU == CPU_ARM64
 
diff --git a/core/nullDC.cpp b/core/nullDC.cpp
index ed8dbe1..b1f583e 100644
--- a/core/nullDC.cpp
+++ b/core/nullDC.cpp
@@ -24,7 +24,6 @@
 #include "hw/pvr/spg.h"
 #include "hw/aica/aica_if.h"
 #include "hw/aica/dsp.h"
-#include "hw/arm7/arm7_rec.h"
 #include "imgread/common.h"
 #include "rend/gui.h"
 #include "profiler/profiler.h"
@@ -38,6 +37,8 @@
 #include "rend/mainui.h"
 #include "archive/rzip.h"
 
+void FlushCache();
+
 extern bool fast_forward_mode;
 
 settings_t settings;
@@ -897,7 +898,7 @@ void dc_loadstate()
 
 	custom_texture.Terminate();
 #if FEAT_AREC == DYNAREC_JIT
-	aicaarm::recompiler::flush();
+    FlushCache();
 #endif
 #ifndef NO_MMU
     mmu_flush_table();
diff --git a/core/rec-ARM/ngen_arm.S b/core/rec-ARM/ngen_arm.S
index dbb72ac..85f5a7a 100644
--- a/core/rec-ARM/ngen_arm.S
+++ b/core/rec-ARM/ngen_arm.S
@@ -201,6 +201,66 @@ bx lr
 end_ngen_mainloop:
 @@@@@@@@@@ ngen_mainloop @@@@@@@@@@
 
+#if FEAT_AREC == DYNAREC_JIT
+.global CSYM(arm_compilecode)
+HIDDEN(arm_compilecode)
+CSYM(arm_compilecode):
+bl CSYM(CompileCode)
+b CSYM(arm_dispatch)
+#endif
+
+#ifdef TARGET_IPHONE
+Xarm_Reg: .word CSYM(arm_Reg)
+XEntryPoints: .word CSYM(EntryPoints)
+#endif
+
+.global CSYM(arm_mainloop)
+HIDDEN(arm_mainloop)
+CSYM(arm_mainloop): @(cntx,lookup_base,cycles)
+
+#if defined(__APPLE__)
+push {r4,r5,r8,r11,lr}
+#else
+push {r4,r5,r8,r9,lr}
+#endif
+
+	#ifdef TARGET_IPHONE
+	ldr r8,Xarm_Reg			@load cntx
+	ldr r4,XEntryPoints		@load lookup base
+	#else
+	mov r8,r1			@load cntx
+	mov r4,r2		@load lookup base
+	#endif
+
+	ldr r5,[r8,#192]	@load cycle count
+	add r5,r0			@add cycles for this timeslice
+
+	b CSYM(arm_dispatch)
+
+.global CSYM(arm_dispatch)
+HIDDEN(arm_dispatch)
+CSYM(arm_dispatch):
+	ldrd r0,r1,[r8,#184]		@load: Next PC, interrupt
+	ubfx r2,r0,#2,#21		@ assuming 8 MB address space max (23 bits)
+	cmp r1,#0
+	bne arm_dofiq
+
+	ldr pc,[r4,r2,lsl #2]
+	
+arm_dofiq:
+	bl CSYM(CPUFiq)
+	b CSYM(arm_dispatch)
+
+.global CSYM(arm_exit)
+HIDDEN(arm_exit)
+CSYM(arm_exit):
+	str r5,[r8,#192]		@if timeslice is over, save remaining cycles
+#if defined(__APPLE__)
+	pop {r4,r5,r8,r11,pc}
+#else
+	pop {r4,r5,r8,r9,pc}
+#endif
+
 @@@@@@
 @matrix mul
 #ifndef __ANDROID__
diff --git a/core/rec-ARM/rec_arm.cpp b/core/rec-ARM/rec_arm.cpp
index 915be11..087e1ab 100644
--- a/core/rec-ARM/rec_arm.cpp
+++ b/core/rec-ARM/rec_arm.cpp
@@ -57,6 +57,124 @@ struct DynaRBI: RuntimeBlockInfo
 	ARM::eReg T_reg;
 };
 
+
+#ifdef __ANDROID__
+#include <sys/syscall.h>  // for cache flushing.
+#endif
+
+#if defined(__APPLE__)
+#include <libkern/OSCacheControl.h>
+void CacheFlush(void* code, void* pEnd)
+{
+    sys_dcache_flush(code, (u8*)pEnd - (u8*)code + 1);
+    sys_icache_invalidate(code, (u8*)pEnd - (u8*)code + 1);
+}
+#elif !defined(ARMCC)
+void CacheFlush(void* code, void* pEnd)
+{
+#if !defined(__ANDROID__) && !defined(__APPLE__)
+	__builtin___clear_cache((char *)code, pEnd);
+#else
+	void* start=code;
+	size_t size=(u8*)pEnd-(u8*)start+4;
+
+  // Ideally, we would call
+  //   syscall(__ARM_NR_cacheflush, start,
+  //           reinterpret_cast<intptr_t>(start) + size, 0);
+  // however, syscall(int, ...) is not supported on all platforms, especially
+  // not when using EABI, so we call the __ARM_NR_cacheflush syscall directly.
+
+  register uint32_t beg asm("a1") = reinterpret_cast<uint32_t>(start);
+  register uint32_t end asm("a2") = reinterpret_cast<uint32_t>(start) + size;
+  register uint32_t flg asm("a3") = 0;
+
+  #ifdef __ARM_EABI__
+    #if defined (__arm__) && !defined(__thumb__)
+      // __arm__ may be defined in thumb mode.
+      register uint32_t scno asm("r7") = __ARM_NR_cacheflush;
+      asm volatile(
+          "svc 0x0"
+          : "=r" (beg)
+          : "0" (beg), "r" (end), "r" (flg), "r" (scno));
+    #else
+      // r7 is reserved by the EABI in thumb mode.
+      asm volatile(
+      "@   Enter ARM Mode  \n\t"
+          "adr r3, 1f      \n\t"
+          "bx  r3          \n\t"
+          ".ALIGN 4        \n\t"
+          ".ARM            \n"
+      "1:  push {r7}       \n\t"
+          "mov r7, %4      \n\t"
+          "svc 0x0         \n\t"
+          "pop {r7}        \n\t"
+      "@   Enter THUMB Mode\n\t"
+          "adr r3, 2f+1    \n\t"
+          "bx  r3          \n\t"
+          ".THUMB          \n"
+      "2:                  \n\t"
+          : "=r" (beg)
+          : "0" (beg), "r" (end), "r" (flg), "r" (__ARM_NR_cacheflush)
+          : "r3");
+    #endif
+  #else
+    #if defined (__arm__) && !defined(__thumb__)
+      // __arm__ may be defined in thumb mode.
+      asm volatile(
+          "svc %1"
+          : "=r" (beg)
+          : "i" (__ARM_NR_cacheflush), "0" (beg), "r" (end), "r" (flg));
+    #else
+      // Do not use the value of __ARM_NR_cacheflush in the inline assembly
+      // below, because the thumb mode value would be used, which would be
+      // wrong, since we switch to ARM mode before executing the svc instruction
+      asm volatile(
+      "@   Enter ARM Mode  \n\t"
+          "adr r3, 1f      \n\t"
+          "bx  r3          \n\t"
+          ".ALIGN 4        \n\t"
+          ".ARM            \n"
+      "1:  svc 0x9f0002    \n"
+      "@   Enter THUMB Mode\n\t"
+          "adr r3, 2f+1    \n\t"
+          "bx  r3          \n\t"
+          ".THUMB          \n"
+      "2:                  \n\t"
+          : "=r" (beg)
+          : "0" (beg), "r" (end), "r" (flg)
+          : "r3");
+    #endif
+  #endif
+	#if 0
+		const int syscall = 0xf0002;
+		__asm __volatile (
+			"mov     r0, %0\n"
+			"mov     r1, %1\n"
+			"mov     r7, %2\n"
+			"mov     r2, #0x0\n"
+			"svc     0x00000000\n"
+			:
+			:   "r" (code), "r" (pEnd), "r" (syscall)
+			:   "r0", "r1", "r7"
+			);
+	#endif
+#endif
+}
+#else
+asm void CacheFlush(void* code, void* pEnd)
+{
+	ARM
+	push {r7}
+	//add r1, r1, r0
+	mov r7, #0xf0000
+	add r7, r7, #0x2
+	mov r2, #0x0
+	svc #0x0
+	pop {r7}
+	bx lr
+}
+#endif
+
 using namespace ARM;
 
 
@@ -353,7 +471,7 @@ u32 DynaRBI::Relink()
 		break;
 	}
 
-	vmem_platform_flush_cache(code_start, emit_ptr - 1, code_start, emit_ptr - 1);
+	CacheFlush(code_start,emit_ptr);
 
 	u32 sz=(u8*)emit_ptr-code_start;
 
@@ -748,12 +866,11 @@ void vmem_slowpath(eReg raddr, eReg rt, eFSReg ft, eFDReg fd, mem_op_type optp,
 	}
 }
 
-bool ngen_Rewrite(host_context_t &context, void *faultAddress)
+u32* ngen_readm_fail_v2(u32* ptrv,u32* regs,u32 fault_addr)
 {
-	u32 *regs = context.reg;
-	arm_mem_op *ptr = (arm_mem_op *)context.pc;
+	arm_mem_op* ptr=(arm_mem_op*)ptrv;
 
-	static_assert(sizeof(*ptr) == 4, "sizeof(arm_mem_op) == 4");
+	verify(sizeof(*ptr)==4);
 
 	mem_op_type optp;
 	u32 read=0;
@@ -806,7 +923,7 @@ bool ngen_Rewrite(host_context_t &context, void *faultAddress)
 
 	//get some other relevant data
 	u32 sh4_addr=regs[raddr];
-	u32 fault_offs = (uintptr_t)faultAddress - regs[8];
+	u32 fault_offs=fault_addr-regs[8];
 	u8* sh4_ctr=(u8*)regs[8];
 	bool is_sq=(sh4_addr>>26)==0x38;
 
@@ -901,11 +1018,10 @@ bool ngen_Rewrite(host_context_t &context, void *faultAddress)
 	}
 
 
-	vmem_platform_flush_cache((void*)ptr, (u8*)emit_ptr - 1, (void*)ptr, (u8*)emit_ptr - 1);
-	emit_ptr = 0;
-	context.pc = (size_t)ptr;
+	CacheFlush((void*)ptr, (void*)emit_ptr);
+	emit_ptr=0;
 
-	return true;
+	return (u32*)ptr;
 }
 
 EAPI NEG(eReg Rd, eReg Rs)
@@ -1595,10 +1711,10 @@ void ngen_compile_opcode(RuntimeBlockInfo* block, shil_opcode* op, bool staging,
 				EOR(r1, rs1, rs2);
 				MOVW(reg.mapg(op->rd), 0);
 				
-				TST(r1, 0xFF000000u);
-				TST(r1, 0x00FF0000u, CC_NE);
-				TST(r1, 0x0000FF00u, CC_NE);
-				TST(r1, 0x000000FFu, CC_NE);
+				TST(r1, 0xFF000000);
+				TST(r1, 0x00FF0000, CC_NE);
+				TST(r1, 0x0000FF00, CC_NE);
+				TST(r1, 0x000000FF, CC_NE);
 				MOVW(reg.mapg(op->rd), 1, CC_EQ);
 			}
 			break;
@@ -2239,13 +2355,16 @@ void ngen_Compile(RuntimeBlockInfo* block, bool force_checks, bool reset, bool s
 	u8* pEnd = (u8*)EMIT_GET_PTR();
 
 	// Clear the area we've written to for cache
-	vmem_platform_flush_cache((void*)block->code, pEnd - 1, (void*)block->code, pEnd - 1);
+	CacheFlush((void*)block->code, pEnd);
 
 	//blk_start might not be the same, due to profiling counters ..
 	block->host_opcodes=(pEnd-blk_start)/4;
 
 	//host code size needs to cover the entire range of the block
 	block->host_code_size=(pEnd-(u8*)block->code);
+
+	void emit_WriteCodeCache();
+//	emit_WriteCodeCache();
 }
 
 void ngen_ResetBlocks()
@@ -2263,7 +2382,7 @@ void ngen_ResetBlocks()
 void ngen_init()
 {
 	INFO_LOG(DYNAREC, "Initializing the ARM32 dynarec");
-    static_assert(FPCB_OFFSET == -0x2100000 || FPCB_OFFSET == -0x4100000, "Invalid FPCB_OFFSET");
+    verify(FPCB_OFFSET == -0x2100000 || FPCB_OFFSET == -0x4100000);
     verify(rcb_noffs(p_sh4rcb->fpcb) == FPCB_OFFSET);
     
     ngen_FailedToFindBlock = &ngen_FailedToFindBlock_;
diff --git a/core/rec-ARM64/arm64_regalloc.h b/core/rec-ARM64/arm64_regalloc.h
index 976f284..cbdf470 100644
--- a/core/rec-ARM64/arm64_regalloc.h
+++ b/core/rec-ARM64/arm64_regalloc.h
@@ -25,7 +25,7 @@
 #else
 #include "hw/sh4/dyna/ssa_regalloc.h"
 #endif
-#include <aarch64/macro-assembler-aarch64.h>
+#include "deps/vixl/aarch64/macro-assembler-aarch64.h"
 using namespace vixl::aarch64;
 
 enum eReg {
diff --git a/core/rec-ARM64/rec_arm64.cpp b/core/rec-ARM64/rec_arm64.cpp
index 00cd059..77684ed 100644
--- a/core/rec-ARM64/rec_arm64.cpp
+++ b/core/rec-ARM64/rec_arm64.cpp
@@ -19,12 +19,13 @@
 
 #include "types.h"
 
-#if FEAT_SHREC == DYNAREC_JIT && HOST_CPU == CPU_ARM64
+#if FEAT_SHREC == DYNAREC_JIT
 
 #include <unistd.h>
 #include <map>
+#include <setjmp.h>
 
-#include <aarch64/macro-assembler-aarch64.h>
+#include "deps/vixl/aarch64/macro-assembler-aarch64.h"
 using namespace vixl::aarch64;
 
 //#define NO_BLOCK_LINKING
@@ -39,12 +40,21 @@ using namespace vixl::aarch64;
 #include "hw/sh4/sh4_rom.h"
 #include "hw/mem/vmem32.h"
 #include "arm64_regalloc.h"
-#include "hw/mem/_vmem.h"
 
 #undef do_sqw_nommu
 
+extern "C" void ngen_blockcheckfail(u32 pc);
+extern "C" void ngen_LinkBlock_Generic_stub();
+extern "C" void ngen_LinkBlock_cond_Branch_stub();
+extern "C" void ngen_LinkBlock_cond_Next_stub();
+extern "C" void ngen_FailedToFindBlock_mmu();
+extern "C" void ngen_FailedToFindBlock_nommu();
+extern void vmem_platform_flush_cache(void *icache_start, void *icache_end, void *dcache_start, void *dcache_end);
 static void generate_mainloop();
 
+u32 mem_writes, mem_reads;
+u32 mem_rewrites_w, mem_rewrites_r;
+
 struct DynaRBI : RuntimeBlockInfo
 {
 	virtual u32 Relink() override;
@@ -54,20 +64,83 @@ struct DynaRBI : RuntimeBlockInfo
 	}
 };
 
+double host_cpu_time;
+u64 guest_cpu_cycles;
+static jmp_buf jmp_env;
 static u32 cycle_counter;
-static u64 jmp_stack;
 
 static void (*mainloop)(void *context);
-static void (*handleException)();
+static int (*arm64_intc_sched)();
+static void (*arm64_no_update)();
 
-struct DynaCode;
+#ifdef PROFILING
+#include <time.h>
 
-static DynaCode *arm64_intc_sched;
-static DynaCode *arm64_no_update;
-static DynaCode *blockCheckFail;
-static DynaCode *linkBlockGenericStub;
-static DynaCode *linkBlockBranchStub;
-static DynaCode *linkBlockNextStub;
+static clock_t slice_start;
+extern "C"
+{
+static __attribute((used)) void start_slice()
+{
+	slice_start = clock();
+}
+static __attribute((used)) void end_slice()
+{
+	host_cpu_time += (double)(clock() - slice_start) / CLOCKS_PER_SEC;
+}
+}
+#endif
+
+__asm__
+(
+		".hidden ngen_LinkBlock_cond_Branch_stub	\n\t"
+		".globl ngen_LinkBlock_cond_Branch_stub		\n\t"
+	"ngen_LinkBlock_cond_Branch_stub:		\n\t"
+		"mov w1, #1							\n\t"
+		"b ngen_LinkBlock_Shared_stub		\n"
+
+		".hidden ngen_LinkBlock_cond_Next_stub	\n\t"
+		".globl ngen_LinkBlock_cond_Next_stub	\n\t"
+	"ngen_LinkBlock_cond_Next_stub:			\n\t"
+		"mov w1, #0							\n\t"
+		"b ngen_LinkBlock_Shared_stub		\n"
+
+		".hidden ngen_LinkBlock_Generic_stub	\n\t"
+		".globl ngen_LinkBlock_Generic_stub	\n\t"
+	"ngen_LinkBlock_Generic_stub:			\n\t"
+		"mov w1, w29						\n\t"	// djump/pc -> in case we need it ..
+		//"b ngen_LinkBlock_Shared_stub		\n"
+
+		".hidden ngen_LinkBlock_Shared_stub	\n\t"
+		".globl ngen_LinkBlock_Shared_stub	\n\t"
+	"ngen_LinkBlock_Shared_stub:			\n\t"
+		"sub x0, lr, #4						\n\t"	// go before the call
+		"bl rdv_LinkBlock					\n\t"   // returns an RX addr
+		"br x0								\n"
+
+		".hidden ngen_FailedToFindBlock_nommu	\n\t"
+		".globl ngen_FailedToFindBlock_nommu	\n\t"
+	"ngen_FailedToFindBlock_nommu:			\n\t"
+		"mov w0, w29						\n\t"
+		"bl rdv_FailedToFindBlock			\n\t"
+		"br x0								\n"
+
+		".hidden ngen_FailedToFindBlock_mmu	\n\t"
+		".globl ngen_FailedToFindBlock_mmu	\n\t"
+	"ngen_FailedToFindBlock_mmu:			\n\t"
+		"bl rdv_FailedToFindBlock_pc		\n\t"
+		"br x0								\n"
+
+		".hidden ngen_blockcheckfail		\n\t"
+		".globl ngen_blockcheckfail			\n\t"
+	"ngen_blockcheckfail:					\n\t"
+		"bl rdv_BlockCheckFail				\n\t"
+		"cbnz x0, jumpblock				    \n\t"
+		"ldr w0, [x28, 264]					\n\t"	// pc
+		"bl bm_GetCodeByVAddr		        \n"
+	"jumpblock:								\n\t"
+		"br x0								\n"
+);
+static_assert(offsetof(Sh4Context, pc) == 264, "offsetof pc unexpected");
 
 static bool restarting;
 
@@ -86,20 +159,22 @@ void ngen_mainloop(void* v_cntx)
 void ngen_init()
 {
 	INFO_LOG(DYNAREC, "Initializing the ARM64 dynarec");
+	ngen_FailedToFindBlock = &ngen_FailedToFindBlock_nommu;
 }
 
 void ngen_ResetBlocks()
 {
-	mainloop = nullptr;
-
+	mainloop = NULL;
+	if (mmu_enabled())
+		ngen_FailedToFindBlock = &ngen_FailedToFindBlock_mmu;
+	else
+		ngen_FailedToFindBlock = &ngen_FailedToFindBlock_nommu;
 	if (p_sh4rcb->cntx.CpuRunning)
 	{
 		// Force the dynarec out of mainloop() to regenerate it
 		p_sh4rcb->cntx.CpuRunning = 0;
 		restarting = true;
 	}
-	else
-		generate_mainloop();
 }
 
 void ngen_GetFeatures(ngen_features* dst)
@@ -117,7 +192,7 @@ static T ReadMemNoEx(u32 addr, u32, u32 pc)
 	if (ex)
 	{
 		spc = pc;
-		handleException();
+		longjmp(jmp_env, 1);
 	}
 	return rv;
 #else
@@ -133,7 +208,7 @@ static void WriteMemNoEx(u32 addr, T data, u32 pc)
 	if (ex)
 	{
 		spc = pc;
-		handleException();
+		longjmp(jmp_env, 1);
 	}
 #endif
 }
@@ -150,7 +225,7 @@ static void interpreter_fallback(u16 op, OpCallFP *oph, u32 pc)
 			pc--;
 		}
 		Do_Exception(pc, ex.expEvn, ex.callVect);
-		handleException();
+		longjmp(jmp_env, 1);
 	}
 }
 
@@ -166,7 +241,7 @@ static void do_sqw_mmu_no_ex(u32 addr, u32 pc)
 			pc--;
 		}
 		Do_Exception(pc, ex.expEvn, ex.callVect);
-		handleException();
+		longjmp(jmp_env, 1);
 	}
 }
 
@@ -307,6 +382,9 @@ public:
 	void ngen_Compile(RuntimeBlockInfo* block, bool force_checks, bool reset, bool staging, bool optimise)
 	{
 		//printf("REC-ARM64 compiling %08x\n", block->addr);
+#ifdef PROFILING
+		SaveFramePointer();
+#endif
 		this->block = block;
 		CheckBlock(force_checks, block);
 		
@@ -327,15 +405,21 @@ public:
 		}
 		Label cycles_remaining;
 		B(&cycles_remaining, pl);
-		GenCall(arm64_intc_sched);
+		GenCall(*arm64_intc_sched);
 		Label cpu_running;
 		Cbnz(w0, &cpu_running);
 		Mov(w29, block->vaddr);
 		Str(w29, sh4_context_mem_operand(&next_pc));
-		GenBranch(arm64_no_update);
+		GenBranch(*arm64_no_update);
 		Bind(&cpu_running);
 		Bind(&cycles_remaining);
 
+#ifdef PROFILING
+		Ldr(x11, (uintptr_t)&guest_cpu_cycles);
+		Ldr(x0, MemOperand(x11));
+		Add(x0, x0, block->guest_cycles);
+		Str(x0, MemOperand(x11));
+#endif
 		for (size_t i = 0; i < block->oplist.size(); i++)
 		{
 			shil_opcode& op  = block->oplist[i];
@@ -1174,11 +1258,11 @@ public:
 			// next_pc = block->BranchBlock;
 #ifndef NO_BLOCK_LINKING
 			if (block->pBranchBlock != NULL)
-				GenBranch((DynaCode *)block->pBranchBlock->code);
+				GenBranch(block->pBranchBlock->code);
 			else
 			{
 				if (!mmu_enabled())
-					GenCall(linkBlockGenericStub);
+					GenCallRuntime(ngen_LinkBlock_Generic_stub);
 				else
 #else
 			{
@@ -1186,7 +1270,7 @@ public:
 				{
 					Mov(w29, block->BranchBlock);
 					Str(w29, sh4_context_mem_operand(&next_pc));
-					GenBranch(arm64_no_update);
+					GenBranch(*arm64_no_update);
 				}
 			}
 			break;
@@ -1210,11 +1294,11 @@ public:
 				B(ne, &branch_not_taken);
 #ifndef NO_BLOCK_LINKING
 				if (block->pBranchBlock != NULL)
-					GenBranch((DynaCode *)block->pBranchBlock->code);
+					GenBranch(block->pBranchBlock->code);
 				else
 				{
 					if (!mmu_enabled())
-						GenCall(linkBlockBranchStub);
+						GenCallRuntime(ngen_LinkBlock_cond_Branch_stub);
 					else
 #else
 				{
@@ -1222,7 +1306,7 @@ public:
 					{
 						Mov(w29, block->BranchBlock);
 						Str(w29, sh4_context_mem_operand(&next_pc));
-						GenBranch(arm64_no_update);
+						GenBranch(*arm64_no_update);
 					}
 				}
 
@@ -1230,11 +1314,11 @@ public:
 
 #ifndef NO_BLOCK_LINKING
 				if (block->pNextBlock != NULL)
-					GenBranch((DynaCode *)block->pNextBlock->code);
+					GenBranch(block->pNextBlock->code);
 				else
 				{
 					if (!mmu_enabled())
-						GenCall(linkBlockNextStub);
+						GenCallRuntime(ngen_LinkBlock_cond_Next_stub);
 					else
 #else
 				{
@@ -1242,7 +1326,7 @@ public:
 					{
 						Mov(w29, block->NextBlock);
 						Str(w29, sh4_context_mem_operand(&next_pc));
-						GenBranch(arm64_no_update);
+						GenBranch(*arm64_no_update);
 					}
 				}
 			}
@@ -1270,7 +1354,7 @@ public:
 			}
 			else
 			{
-				GenBranch(arm64_no_update);
+				GenBranch(*arm64_no_update);
 			}
 
 			break;
@@ -1287,7 +1371,7 @@ public:
 			GenCallRuntime(UpdateINTC);
 
 			Ldr(w29, sh4_context_mem_operand(&next_pc));
-			GenBranch(arm64_no_update);
+			GenBranch(*arm64_no_update);
 
 			break;
 
@@ -1346,7 +1430,7 @@ public:
 		Label end_mainloop;
 
 		// int intc_sched()
-		arm64_intc_sched = GetCursorAddress<DynaCode *>();
+		arm64_intc_sched = GetCursorAddress<int (*)()>();
 		B(&intc_sched);
 
 		// void no_update()
@@ -1388,7 +1472,6 @@ public:
 		Stp(x29, x30, MemOperand(sp, 144));
 
 		Sub(x0, x0, sizeof(Sh4Context));
-		Label reenterLabel;
 		if (mmu_enabled())
 		{
 			Ldr(x1, reinterpret_cast<uintptr_t>(&cycle_counter));
@@ -1397,11 +1480,10 @@ public:
 			Mov(w0, SH4_TIMESLICE);
 			Str(w0, MemOperand(x1));
 
-			Ldr(x0, reinterpret_cast<uintptr_t>(&jmp_stack));
-			Mov(x1, sp);
-			Str(x1, MemOperand(x0));
+			Ldr(x0, reinterpret_cast<uintptr_t>(jmp_env));
+			Ldr(x1, reinterpret_cast<uintptr_t>(&setjmp));
+			Blr(x1);
 
-			Bind(&reenterLabel);
 			Ldr(x28, MemOperand(sp));	// Set context
 		}
 		else
@@ -1462,66 +1544,10 @@ public:
 		Ldp(x19, x20, MemOperand(sp, 160, PostIndex));
 		Ret();
 
-		// Exception handler
-		Label handleExceptionLabel;
-		Bind(&handleExceptionLabel);
-		if (mmu_enabled())
-		{
-			Ldr(x0, reinterpret_cast<uintptr_t>(&jmp_stack));
-			Ldr(x1, MemOperand(x0));
-			Mov(sp, x1);
-			B(&reenterLabel);
-		}
-
-		// Block check fail
-		blockCheckFail = GetCursorAddress<DynaCode *>();
-		GenCallRuntime(rdv_BlockCheckFail);
-		if (mmu_enabled())
-		{
-			Label jumpblockLabel;
-			Cbnz(x0, &jumpblockLabel);
-			Ldr(w0, MemOperand(x28, offsetof(Sh4Context, pc)));
-			GenCallRuntime(bm_GetCodeByVAddr);
-			Bind(&jumpblockLabel);
-		}
-		Br(x0);
-
-		// Block linking stubs
-		linkBlockBranchStub = GetCursorAddress<DynaCode *>();
-		Label linkBlockShared;
-		Mov(w1, 1);
-		B(&linkBlockShared);
-
-		linkBlockNextStub = GetCursorAddress<DynaCode *>();
-		Mov(w1, 0);
-		B(&linkBlockShared);
-
-		linkBlockGenericStub = GetCursorAddress<DynaCode *>();
-		Mov(w1, w29);	// djump/pc -> in case we need it ..
-
-		Bind(&linkBlockShared);
-		Sub(x0, lr, 4);	// go before the call
-		GenCallRuntime(rdv_LinkBlock);	// returns an RX addr
-		Br(x0);
-
-		// Not yet compiled block stub
-		ngen_FailedToFindBlock = (void (*)())CC_RW2RX(GetCursorAddress<uintptr_t>());
-		if (mmu_enabled())
-		{
-			GenCallRuntime(rdv_FailedToFindBlock_pc);
-		}
-		else
-		{
-			Mov(w0, w29);
-			GenCallRuntime(rdv_FailedToFindBlock);
-		}
-		Br(x0);
-
 		FinalizeCode();
 		emit_Skip(GetBuffer()->GetSizeInBytes());
 
-		arm64_no_update = GetLabelAddress<DynaCode *>(&no_update);
-		handleException = (void (*)())CC_RW2RX(GetLabelAddress<uintptr_t>(&handleExceptionLabel));
+		arm64_no_update = GetLabelAddress<void (*)()>(&no_update);
 
 		// Flush and invalidate caches
 		vmem_platform_flush_cache(
@@ -1545,7 +1571,8 @@ private:
 		Bl(&function_label);
 	}
 
-	void GenCall(DynaCode *function)
+	template <typename R, typename... P>
+	void GenCall(R (*function)(P...))
 	{
 		ptrdiff_t offset = reinterpret_cast<uintptr_t>(function) - GetBuffer()->GetStartAddress<uintptr_t>();
 		verify(offset >= -128 * 1024 * 1024 && offset <= 128 * 1024 * 1024);
@@ -1566,7 +1593,8 @@ private:
 		B(&target_label);
 	}
 
-	void GenBranch(DynaCode *code, Condition cond = al)
+	template <typename R, typename... P>
+	void GenBranch(R (*code)(P...), Condition cond = al)
 	{
 		ptrdiff_t offset = reinterpret_cast<uintptr_t>(code) - GetBuffer()->GetStartAddress<uintptr_t>();
 		verify(offset >= -128 * 1024 * 1024 && offset < 128 * 1024 * 1024);
@@ -1750,6 +1778,7 @@ private:
 		// Direct memory access. Need to handle SIGSEGV and rewrite block as needed. See ngen_Rewrite()
 		if (!_nvmem_enabled() || (mmu_enabled() && !vmem32_enabled()))
 			return false;
+		mem_reads++;
 
 		Instruction *start_instruction = GetCursorAddress<Instruction *>();
 
@@ -1941,6 +1970,7 @@ private:
 		// Direct memory access. Need to handle SIGSEGV and rewrite block as needed. See ngen_Rewrite()
 		if (!_nvmem_enabled() || (mmu_enabled() && !vmem32_enabled()))
 			return false;
+		mem_writes++;
 
 		Instruction *start_instruction = GetCursorAddress<Instruction *>();
 
@@ -2043,7 +2073,7 @@ private:
 		B(&blockcheck_success);
 		Bind(&blockcheck_fail);
 		Mov(w0, block->addr);
-		GenBranch(blockCheckFail);
+		TailCallRuntime(ngen_blockcheckfail);
 
 		Bind(&blockcheck_success);
 
@@ -2058,7 +2088,7 @@ private:
 			Mov(*call_regs[2], 0x100);			// vector
 			CallRuntime(Do_Exception);
 			Ldr(w29, sh4_context_mem_operand(&next_pc));
-			GenBranch(arm64_no_update);
+			GenBranch(*arm64_no_update);
 
 			Bind(&fpu_enabled);
 		}
@@ -2202,10 +2232,10 @@ static const u32 op_sizes[] = {
 		4,
 		8,
 };
-bool ngen_Rewrite(host_context_t &context, void *faultAddress)
+bool ngen_Rewrite(unat& host_pc, unat, unat)
 {
-	//LOGI("ngen_Rewrite pc %zx\n", context.pc);
-	u32 *code_ptr = (u32 *)CC_RX2RW(context.pc);
+	//LOGI("ngen_Rewrite pc %zx\n", host_pc);
+	u32 *code_ptr = (u32 *)CC_RX2RW(host_pc);
 	u32 armv8_op = *code_ptr;
 	bool is_read;
 	u32 size;
@@ -2227,12 +2257,18 @@ bool ngen_Rewrite(host_context_t &context, void *faultAddress)
 	u32 *code_rewrite = code_ptr - 1 - (!_nvmem_4gb_space() ? 1 : 0);
 	Arm64Assembler *assembler = new Arm64Assembler(code_rewrite);
 	if (is_read)
+	{
+		mem_rewrites_r++;
 		assembler->GenReadMemorySlow(size);
+	}
 	else
+	{
+		mem_rewrites_w++;
 		assembler->GenWriteMemorySlow(size);
+	}
 	assembler->Finalize(true);
 	delete assembler;
-	context.pc = (unat)CC_RW2RX(code_rewrite);
+	host_pc = (unat)CC_RW2RX(code_rewrite);
 
 	return true;
 }
@@ -2255,9 +2291,9 @@ RuntimeBlockInfo* ngen_AllocateBlock()
 	return new DynaRBI();
 }
 
-void ngen_HandleException(host_context_t &context)
+void ngen_HandleException()
 {
-	context.pc = (uintptr_t)handleException;
+	longjmp(jmp_env, 1);
 }
 
 u32 DynaRBI::Relink()
@@ -2292,4 +2328,24 @@ void Arm64RegAlloc::Writeback_FPU(u32 reg, eFReg nreg)
 {
 	assembler->Str(VRegister(nreg, 32), assembler->sh4_context_mem_operand(GetRegPtr(reg)));
 }
+
+
+extern "C" naked void do_sqw_nommu_area_3(u32 dst, u8* sqb)
+{
+	__asm__
+	(
+		"and x12, x0, #0x20			\n\t"	// SQ# selection, isolate
+		"add x12, x12, x1			\n\t"	// SQ# selection, add to SQ ptr
+		"ld2 { v0.2D, v1.2D }, [x12]\n\t"
+		"movz x11, #0x0C00, lsl #16 \n\t"
+		"add x11, x1, x11			\n\t"	// get ram ptr from x1, part 1
+		"ubfx x0, x0, #5, #20		\n\t"	// get ram offset
+		"add x11, x11, #512			\n\t"	// get ram ptr from x1, part 2
+		"add x11, x11, x0, lsl #5	\n\t"	// ram + offset
+		"st2 { v0.2D, v1.2D }, [x11] \n\t"
+		"ret						\n"
+
+		: : : "memory"
+	);
+}
 #endif	// FEAT_SHREC == DYNAREC_JIT
diff --git a/core/rec-cpp/rec_cpp.cpp b/core/rec-cpp/rec_cpp.cpp
index 4b638eb..975e8cb 100644
--- a/core/rec-cpp/rec_cpp.cpp
+++ b/core/rec-cpp/rec_cpp.cpp
@@ -1956,7 +1956,7 @@ void ngen_ResetBlocks()
 	*/
 }
 
-void ngen_HandleException(host_context_t &context)
+void ngen_HandleException()
 {
 	die("rec-cpp exceptions not supported");
 }
diff --git a/core/rec-x64/msvc.asm b/core/rec-x64/msvc.asm
new file mode 100644
index 0000000..9f77391
--- /dev/null
+++ b/core/rec-x64/msvc.asm
@@ -0,0 +1,77 @@
+_TEXT    SEGMENT
+
+SH4_TIMESLICE = 448
+CPU_RUNNING = 135266148
+PC = 135266120
+
+EXTERN bm_GetCodeByVAddr: PROC
+EXTERN UpdateSystem_INTC: PROC
+EXTERN setjmp: PROC
+EXTERN cycle_counter: dword
+EXTERN p_sh4rcb: qword
+EXTERN jmp_env: qword
+
+PUBLIC ngen_mainloop
+ngen_mainloop PROC FRAME
+
+	push rbx
+	.pushreg rbx
+	push rbp
+	.pushreg rbp
+	push rdi
+	.pushreg rdi
+	push rsi
+	.pushreg rsi
+	push r12
+	.pushreg r12
+	push r13
+	.pushreg r13
+	push r14
+	.pushreg r14
+	push r15
+	.pushreg r15
+	sub rsp, 40                 ; 32-byte shadow space + 8 for stack 16-byte alignment
+	.allocstack 40
+	.endprolog
+
+	mov dword ptr [cycle_counter], SH4_TIMESLICE
+
+	lea rcx, qword ptr[jmp_env]
+	xor rdx, rdx
+	call setjmp
+
+run_loop:
+	mov rax, qword ptr [p_sh4rcb]
+	mov edx, dword ptr[CPU_RUNNING + rax]
+	test edx, edx
+	je end_run_loop
+
+slice_loop:
+	mov rax, qword ptr [p_sh4rcb]
+	mov ecx, dword ptr[PC + rax]
+	call bm_GetCodeByVAddr
+	call rax
+	mov ecx, dword ptr [cycle_counter]
+	test ecx, ecx
+	jg slice_loop
+
+	add ecx, SH4_TIMESLICE
+	mov dword ptr [cycle_counter], ecx
+	call UpdateSystem_INTC
+	jmp run_loop
+
+end_run_loop:
+
+	add rsp, 40
+	pop r15
+	pop r14
+	pop r13
+	pop r12
+	pop rsi
+	pop rdi
+	pop rbp
+	pop rbx
+	ret
+ngen_mainloop ENDP
+_TEXT    ENDS
+END
diff --git a/core/rec-x64/rec_x64.cpp b/core/rec-x64/rec_x64.cpp
index c8c96e3..6d00c91 100644
--- a/core/rec-x64/rec_x64.cpp
+++ b/core/rec-x64/rec_x64.cpp
@@ -1,13 +1,14 @@
 #include "build.h"
 
 #if FEAT_SHREC == DYNAREC_JIT && HOST_CPU == CPU_X64
+#include <setjmp.h>
 
+//#define PROFILING
 //#define CANONICAL_TEST
 
 #define XBYAK_NO_OP_NAMES
 #include <xbyak/xbyak.h>
 #include <xbyak/xbyak_util.h>
-using namespace Xbyak::util;
 
 #include "types.h"
 #include "hw/sh4/sh4_opcode_list.h"
@@ -19,6 +20,7 @@ using namespace Xbyak::util;
 #include "hw/sh4/sh4_core.h"
 #include "hw/sh4/sh4_mem.h"
 #include "hw/mem/vmem32.h"
+#include "profiler/profiler.h"
 #include "oslib/oslib.h"
 #include "x64_regalloc.h"
 #include "xbyak_base.h"
@@ -34,56 +36,190 @@ struct DynaRBI : RuntimeBlockInfo
 	}
 };
 
-static int cycle_counter;
-static void (*mainloop)();
-static void (*handleException)();
+extern "C" {
+	int cycle_counter;
+}
+
+u64 host_cpu_time;
 
 u32 mem_writes, mem_reads;
 u32 mem_rewrites_w, mem_rewrites_r;
 
-static u32 exception_raised;
-static u64 jmp_rsp;
-
-namespace MemSize {
-	enum {
-		S8,
-		S16,
-		S32,
-		S64,
-		Count
-	};
+#ifdef PROFILING
+static clock_t slice_start;
+int start_cycle;
+extern "C"
+{
+static __attribute((used)) void* start_slice(void *p)
+{
+	slice_start = clock();
+	start_cycle = cycle_counter;
+	return p;
 }
-namespace MemOp {
-	enum {
-		R,
-		W,
-		Count
-	};
+static __attribute((used)) void end_slice()
+{
+	clock_t now = clock();
+	if (slice_start != 0)
+	{
+		host_cpu_time += now - slice_start;
+		guest_cpu_cycles += start_cycle - cycle_counter;
+	}
+	slice_start = now;
+	start_cycle = cycle_counter;
 }
-namespace MemType {
-	enum {
-		Fast,
-		Slow,
-		Count
-	};
+}
+#endif
+
+#if defined(__APPLE__)
+#define _U "_"
+#else
+#define _U
+#endif
+
+#ifdef _WIN32
+#define WIN32_ONLY(x) x
+#else
+#define WIN32_ONLY(x)
+#endif
+
+#define STRINGIFY(x) #x
+#define _S(x) STRINGIFY(x)
+#if RAM_SIZE_MAX == 16*1024*1024
+#define CPU_RUNNING 68157284
+#define PC 68157256
+#elif RAM_SIZE_MAX == 32*1024*1024
+#define CPU_RUNNING 135266148
+#define PC 135266120
+#else
+#error RAM_SIZE_MAX unknown
+#endif
+
+extern "C" {
+	jmp_buf jmp_env;
 }
 
-static const void *MemHandlers[MemType::Count][MemSize::Count][MemOp::Count];
-static const u8 *MemHandlerStart, *MemHandlerEnd;
+#ifndef _MSC_VER
 
-void ngen_mainloop(void *)
+#ifdef _WIN32
+        // Fully naked function in win32 for proper SEH prologue
+	__asm__ (
+			".text                          \n\t"
+			".p2align 4,,15                 \n\t"
+			".globl ngen_mainloop           \n\t"
+			".def   ngen_mainloop;  .scl    2;      .type   32;     .endef  \n\t"
+			".seh_proc      ngen_mainloop   \n\t"
+		"ngen_mainloop:                     \n\t"
+#else
+void ngen_mainloop(void* v_cntx)
 {
-	verify(mainloop != nullptr);
-	try {
-		mainloop();
-	} catch (const SH4ThrownException&) {
-		ERROR_LOG(DYNAREC, "SH4ThrownException in mainloop");
-	} catch (...) {
-		ERROR_LOG(DYNAREC, "Uncaught unknown exception in mainloop");
-	}
+	__asm__ (
+#endif
+			"pushq %rbx						\n\t"
+WIN32_ONLY( ".seh_pushreg %rbx				\n\t")
+#if !defined(__APPLE__)	// rbp is pushed in the standard function prologue
+			"pushq %rbp                     \n\t"
+#endif
+#ifdef _WIN32
+			".seh_pushreg %rbp              \n\t"
+			"pushq %rdi                     \n\t"
+			".seh_pushreg %rdi              \n\t"
+			"pushq %rsi                     \n\t"
+			".seh_pushreg %rsi              \n\t"
+#endif
+			"pushq %r12                     \n\t"
+WIN32_ONLY( ".seh_pushreg %r12              \n\t")
+			"pushq %r13                     \n\t"
+WIN32_ONLY( ".seh_pushreg %r13              \n\t")
+			"pushq %r14                     \n\t"
+WIN32_ONLY( ".seh_pushreg %r14              \n\t")
+			"pushq %r15                     \n\t"
+#ifdef _WIN32
+			".seh_pushreg %r15              \n\t"
+			"subq $40, %rsp                 \n\t"   // 32-byte shadow space + 8 for stack 16-byte alignment
+			".seh_stackalloc 40             \n\t"
+			".seh_endprologue               \n\t"
+#else
+			"subq $8, %rsp                  \n\t"   // 8 for stack 16-byte alignment
+#endif
+			"movl $" _S(SH4_TIMESLICE) "," _U "cycle_counter(%rip)  \n\t"
+
+#ifdef _WIN32
+			"leaq " _U "jmp_env(%rip), %rcx	\n\t"	// SETJMP
+			"xor %rdx, %rdx					\n\t"	// no frame pointer
+#else
+			"leaq " _U "jmp_env(%rip), %rdi	\n\t"
+#endif
+			"call " _U "setjmp				\n"
+
+		"1:                                 \n\t"   // run_loop
+			"movq " _U "p_sh4rcb(%rip), %rax		\n\t"
+			"movl " _S(CPU_RUNNING) "(%rax), %edx	\n\t"
+			"testl %edx, %edx               \n\t"
+			"je 3f                          \n"     // end_run_loop
+#ifdef PROFILING
+			"call start_slice				\n\t"
+#endif
+
+		"2:                                 \n\t"   // slice_loop
+			"movq " _U "p_sh4rcb(%rip), %rax	\n\t"
+#ifdef _WIN32
+			"movl " _S(PC)"(%rax), %ecx     \n\t"
+#else
+			"movl " _S(PC)"(%rax), %edi     \n\t"
+#endif
+			"call " _U "bm_GetCodeByVAddr	\n\t"
+			"call *%rax                     \n\t"
+#ifdef PROFILING
+			"call end_slice					\n\t"
+#endif
+			"movl " _U "cycle_counter(%rip), %ecx \n\t"
+			"testl %ecx, %ecx               \n\t"
+			"jg 2b                          \n\t"   // slice_loop
+
+			"addl $" _S(SH4_TIMESLICE) ", %ecx		\n\t"
+			"movl %ecx, " _U "cycle_counter(%rip)	\n\t"
+			"call " _U "UpdateSystem_INTC   \n\t"
+			"jmp 1b                         \n"     // run_loop
+
+		"3:                                 \n\t"   // end_run_loop
+
+#ifdef _WIN32
+			"addq $40, %rsp                 \n\t"
+#else
+			"addq $8, %rsp                  \n\t"
+#endif
+			"popq %r15                      \n\t"
+			"popq %r14                      \n\t"
+			"popq %r13                      \n\t"
+			"popq %r12                      \n\t"
+#ifdef _WIN32
+			"popq %rsi                      \n\t"
+			"popq %rdi                      \n\t"
+#endif
+#if !defined(__APPLE__)
+			"popq %rbp                      \n\t"
+#endif
+			"popq %rbx                      \n\t"
+#ifdef _WIN32
+			"ret                            \n\t"
+			".seh_endproc                   \n"
+	);
+#else
+	);
 }
+#endif
+
+#endif	// !_MSC_VER
+#undef _U
+#undef _S
 
 void ngen_init()
+{
+	verify(CPU_RUNNING == offsetof(Sh4RCB, cntx.CpuRunning));
+	verify(PC == offsetof(Sh4RCB, cntx.pc));
+}
+
+void ngen_ResetBlocks()
 {
 }
 
@@ -107,12 +243,18 @@ static void handle_mem_exception(u32 exception_raised, u32 pc)
 {
 	if (exception_raised)
 	{
-		spc = pc;
+		if (pc & 1)
+			// Delay slot
+			spc = pc - 1;
+		else
+			spc = pc;
 		cycle_counter += 2;	// probably more is needed but no easy way to find out
-		handleException();
+		longjmp(jmp_env, 1);
 	}
 }
 
+static u32 exception_raised;
+
 template<typename T>
 static T ReadMemNoEx(u32 addr, u32 pc)
 {
@@ -147,7 +289,7 @@ static void handle_sh4_exception(SH4ThrownException& ex, u32 pc)
 	}
 	Do_Exception(pc, ex.expEvn, ex.callVect);
 	cycle_counter += 4;	// probably more is needed
-	handleException();
+	longjmp(jmp_env, 1);
 }
 
 static void interpreter_fallback(u16 op, OpCallFP *oph, u32 pc)
@@ -168,19 +310,24 @@ static void do_sqw_mmu_no_ex(u32 addr, u32 pc)
 	}
 }
 
+static void do_sqw_nommu_local(u32 addr, u8* sqb)
+{
+	do_sqw_nommu(addr, sqb);
+}
+
 const std::array<Xbyak::Reg32, 4> call_regs
 #ifdef _WIN32
-	{ ecx, edx, r8d, r9d };
+	{ Xbyak::util::ecx, Xbyak::util::edx, Xbyak::util::r8d, Xbyak::util::r9d };
 #else
-	{ edi, esi, edx, ecx };
+	{ Xbyak::util::edi, Xbyak::util::esi, Xbyak::util::edx, Xbyak::util::ecx };
 #endif
 const std::array<Xbyak::Reg64, 4> call_regs64
 #ifdef _WIN32
-	{ rcx, rdx, r8, r9 };
+	{ Xbyak::util::rcx, Xbyak::util::rdx, Xbyak::util::r8, Xbyak::util::r9 };
 #else
-	{ rdi, rsi, rdx, rcx };
+	{ Xbyak::util::rdi, Xbyak::util::rsi, Xbyak::util::rdx, Xbyak::util::rcx };
 #endif
-const std::array<Xbyak::Xmm, 4> call_regsxmm { xmm0, xmm1, xmm2, xmm3 };
+const std::array<Xbyak::Xmm, 4> call_regsxmm { Xbyak::util::xmm0, Xbyak::util::xmm1, Xbyak::util::xmm2, Xbyak::util::xmm3 };
 
 class BlockCompiler : public BaseXbyakRec<BlockCompiler, true>
 {
@@ -285,14 +432,11 @@ public:
 							add(call_regs[0], dword[rax]);
 						}
 					}
-					int size = op.flags & 0x7f;
-
-					if (mmu_enabled())
-						mov(call_regs[2], block->vaddr + op.guest_offs - (op.delay_slot ? 2 : 0));	// pc
-					size = size == 1 ? MemSize::S8 : size == 2 ? MemSize::S16 : size == 4 ? MemSize::S32 : MemSize::S64;
-					GenCall((void (*)())MemHandlers[optimise ? MemType::Fast : MemType::Slow][size][MemOp::R], mmu_enabled());
+					if (!optimise || !GenReadMemoryFast(op, block))
+						GenReadMemorySlow(op, block);
 
-					if (size != MemSize::S64)
+					u32 size = op.flags & 0x7f;
+					if (size != 8)
 						host_reg_to_shil_param(op.rd, eax);
 					else {
 						mov(rcx, (uintptr_t)op.rd.reg_ptr());
@@ -326,11 +470,8 @@ public:
 						mov(rax, (uintptr_t)op.rs2.reg_ptr());
 						mov(call_regs64[1], qword[rax]);
 					}
-
-					if (mmu_enabled())
-						mov(call_regs[2], block->vaddr + op.guest_offs - (op.delay_slot ? 2 : 0));	// pc
-					size = size == 1 ? MemSize::S8 : size == 2 ? MemSize::S16 : size == 4 ? MemSize::S32 : MemSize::S64;
-					GenCall((void (*)())MemHandlers[optimise ? MemType::Fast : MemType::Slow][size][MemOp::W], mmu_enabled());
+					if (!optimise || !GenWriteMemoryFast(op, block))
+						GenWriteMemorySlow(op, block);
 				}
 			}
 			break;
@@ -385,36 +526,52 @@ public:
 				break;
 
 			case shop_pref:
+				if (op.rs1.is_imm())
 				{
-					Xbyak::Label no_sqw;
-					if (op.rs1.is_imm())
+					// this test shouldn't be necessary
+					if ((op.rs1._imm & 0xFC000000) == 0xE0000000)
 					{
-						// this test shouldn't be necessary
-						if ((op.rs1._imm & 0xFC000000) != 0xE0000000)
-							break;
-
 						mov(call_regs[0], op.rs1._imm);
-					}
-					else
-					{
-						Xbyak::Reg32 rn;
-						if (regalloc.IsAllocg(op.rs1))
+						if (mmu_enabled())
 						{
-							rn = regalloc.MapRegister(op.rs1);
+							mov(call_regs[1], block->vaddr + op.guest_offs - (op.delay_slot ? 1 : 0));      // pc
+
+							GenCall(do_sqw_mmu_no_ex);
 						}
 						else
 						{
-							mov(rax, (uintptr_t)op.rs1.reg_ptr());
-							mov(eax, dword[rax]);
-							rn = eax;
+							if (CCN_MMUCR.AT == 1)
+							{
+								GenCall(do_sqw_mmu);
+							}
+							else
+							{
+								mov(call_regs64[1], (uintptr_t)sq_both);
+								GenCall(&do_sqw_nommu_local);
+							}
 						}
-						mov(ecx, rn);
-						shr(ecx, 26);
-						cmp(ecx, 0x38);
-						jne(no_sqw);
-
-						mov(call_regs[0], rn);
 					}
+				}
+				else
+				{
+					Xbyak::Reg32 rn;
+					if (regalloc.IsAllocg(op.rs1))
+					{
+						rn = regalloc.MapRegister(op.rs1);
+					}
+					else
+					{
+						mov(rax, (uintptr_t)op.rs1.reg_ptr());
+						mov(eax, dword[rax]);
+						rn = eax;
+					}
+					mov(ecx, rn);
+					shr(ecx, 26);
+					cmp(ecx, 0x38);
+					Xbyak::Label no_sqw;
+					jne(no_sqw);
+
+					mov(call_regs[0], rn);
 					if (mmu_enabled())
 					{
 						mov(call_regs[1], block->vaddr + op.guest_offs - (op.delay_slot ? 1 : 0));	// pc
@@ -430,10 +587,7 @@ public:
 						else
 						{
 							mov(call_regs64[1], (uintptr_t)sq_both);
-							mov(rax, (size_t)&do_sqw_nommu);
-							saveXmmRegisters();
-							call(qword[rax]);
-							restoreXmmRegisters();
+							GenCall(&do_sqw_nommu_local);
 						}
 					}
 					L(no_sqw);
@@ -443,14 +597,14 @@ public:
 			case shop_frswap:
 				mov(rax, (uintptr_t)op.rs1.reg_ptr());
 				mov(rcx, (uintptr_t)op.rd.reg_ptr());
-				if (cpu.has(Cpu::tAVX512F))
+				if (cpu.has(Xbyak::util::Cpu::tAVX512F))
 				{
 					vmovaps(zmm0, zword[rax]);
 					vmovaps(zmm1, zword[rcx]);
 					vmovaps(zword[rax], zmm1);
 					vmovaps(zword[rcx], zmm0);
 				}
-				else if (cpu.has(Cpu::tAVX))
+				else if (cpu.has(Xbyak::util::Cpu::tAVX))
 				{
 					vmovaps(ymm0, yword[rax]);
 					vmovaps(ymm1, yword[rcx]);
@@ -565,6 +719,113 @@ public:
 		emit_Skip(getSize());
 	}
 
+	void GenReadMemorySlow(const shil_opcode& op, RuntimeBlockInfo* block)
+	{
+		const u8 *start_addr = getCurr();
+		if (mmu_enabled())
+			mov(call_regs[1], block->vaddr + op.guest_offs - (op.delay_slot ? 1 : 0));	// pc
+
+		u32 size = op.flags & 0x7f;
+		switch (size) {
+		case 1:
+			if (!mmu_enabled())
+				GenCall(ReadMem8);
+			else
+				GenCall(ReadMemNoEx<u8>, true);
+			movsx(eax, al);
+			break;
+		case 2:
+			if (!mmu_enabled())
+				GenCall(ReadMem16);
+			else
+				GenCall(ReadMemNoEx<u16>, true);
+			movsx(eax, ax);
+			break;
+
+		case 4:
+			if (!mmu_enabled())
+				GenCall(ReadMem32);
+			else
+				GenCall(ReadMemNoEx<u32>, true);
+			break;
+		case 8:
+			if (!mmu_enabled())
+				GenCall(ReadMem64);
+			else
+				GenCall(ReadMemNoEx<u64>, true);
+			break;
+		default:
+			die("1..8 bytes");
+		}
+
+		if (mmu_enabled() && vmem32_enabled())
+		{
+			Xbyak::Label quick_exit;
+			if (getCurr() - start_addr <= read_mem_op_size - 6)
+				jmp(quick_exit, T_NEAR);
+			while (getCurr() - start_addr < read_mem_op_size)
+				nop();
+			L(quick_exit);
+			verify(getCurr() - start_addr == read_mem_op_size);
+		}
+	}
+
+	void GenWriteMemorySlow(const shil_opcode& op, RuntimeBlockInfo* block)
+	{
+		const u8 *start_addr = getCurr();
+		if (mmu_enabled())
+			mov(call_regs[2], block->vaddr + op.guest_offs - (op.delay_slot ? 1 : 0));	// pc
+
+		u32 size = op.flags & 0x7f;
+		switch (size) {
+		case 1:
+			if (!mmu_enabled())
+				GenCall(WriteMem8);
+			else
+				GenCall(WriteMemNoEx<u8>, true);
+			break;
+		case 2:
+			if (!mmu_enabled())
+				GenCall(WriteMem16);
+			else
+				GenCall(WriteMemNoEx<u16>, true);
+			break;
+		case 4:
+			if (!mmu_enabled())
+				GenCall(WriteMem32);
+			else
+				GenCall(WriteMemNoEx<u32>, true);
+			break;
+		case 8:
+			if (!mmu_enabled())
+				GenCall(WriteMem64);
+			else
+				GenCall(WriteMemNoEx<u64>, true);
+			break;
+		default:
+			die("1..8 bytes");
+		}
+		if (mmu_enabled() && vmem32_enabled())
+		{
+			Xbyak::Label quick_exit;
+			if (getCurr() - start_addr <= write_mem_op_size - 6)
+				jmp(quick_exit, T_NEAR);
+			while (getCurr() - start_addr < write_mem_op_size)
+				nop();
+			L(quick_exit);
+			verify(getCurr() - start_addr == write_mem_op_size);
+		}
+	}
+
+	void InitializeRewrite(RuntimeBlockInfo *block, size_t opid)
+	{
+	}
+
+	void FinalizeRewrite()
+	{
+		ready();
+	}
+
 	void ngen_CC_Start(const shil_opcode& op)
 	{
 		CC_pars.clear();
@@ -660,132 +921,6 @@ public:
 		movss(dword[rax], Xbyak::Xmm(nreg));
 	}
 
-	void genMainloop()
-	{
-		push(rbx);
-		push(rbp);
-#ifdef _WIN32
-		push(rdi);
-		push(rsi);
-#endif
-		push(r12);
-		push(r13);
-		push(r14);
-		push(r15);
-#ifdef _WIN32
-		sub(rsp, 40);				// 32-byte shadow space + 8 for stack 16-byte alignment
-#else
-		sub(rsp, 8);				// stack 16-byte alignment
-#endif
-
-		mov(dword[rip + &cycle_counter], SH4_TIMESLICE);
-		mov(qword[rip + &jmp_rsp], rsp);
-
-	//run_loop:
-		Xbyak::Label run_loop;
-		L(run_loop);
-		Xbyak::Label end_run_loop;
-		mov(rax, (size_t)&p_sh4rcb->cntx.CpuRunning);
-		mov(edx, dword[rax]);
-
-		test(edx, edx);
-		je(end_run_loop);
-
-	//slice_loop:
-		Xbyak::Label slice_loop;
-		L(slice_loop);
-		mov(rax, (size_t)&p_sh4rcb->cntx.pc);
-		mov(call_regs[0], dword[rax]);
-		call(bm_GetCodeByVAddr);
-		call(rax);
-		mov(ecx, dword[rip + &cycle_counter]);
-		test(ecx, ecx);
-		jg(slice_loop);
-
-		add(ecx, SH4_TIMESLICE);
-		mov(dword[rip + &cycle_counter], ecx);
-		call(UpdateSystem_INTC);
-		jmp(run_loop);
-
-	//end_run_loop:
-		L(end_run_loop);
-#ifdef _WIN32
-		add(rsp, 40);
-#else
-		add(rsp, 8);
-#endif
-		pop(r15);
-		pop(r14);
-		pop(r13);
-		pop(r12);
-#ifdef _WIN32
-		pop(rsi);
-		pop(rdi);
-#endif
-		pop(rbp);
-		pop(rbx);
-		ret();
-
-	//handleException:
-		Xbyak::Label handleExceptionLabel;
-		L(handleExceptionLabel);
-		mov(rsp, qword[rip + &jmp_rsp]);
-		jmp(run_loop);
-
-		genMemHandlers();
-
-		ready();
-		mainloop = (void (*)())getCode();
-		handleException = (void(*)())handleExceptionLabel.getAddress();
-
-		emit_Skip(getSize());
-	}
-
-	bool rewriteMemAccess(host_context_t &context)
-	{
-		if (!_nvmem_enabled() || (mmu_enabled() && !vmem32_enabled()))
-			return false;
-
-		//printf("ngen_Rewrite pc %p\n", context.pc);
-		if (context.pc < (size_t)MemHandlerStart || context.pc >= (size_t)MemHandlerEnd)
-			return false;
-
-		u8 *retAddr = *(u8 **)context.rsp;
-		void *ca = *(s32 *)(retAddr - 4) + retAddr;
-		for (int size = 0; size < MemSize::Count; size++)
-		{
-			for (int op = 0; op < MemOp::Count; op++)
-			{
-				if ((void *)MemHandlers[MemType::Fast][size][op] != ca)
-					continue;
-
-				//found !
-				const u8 *start = getCurr();
-				call(MemHandlers[MemType::Slow][size][op]);
-				verify(getCurr() - start == 5);
-
-				ready();
-
-				context.pc = (uintptr_t)(retAddr - 5);
-				// remove the call from the stack
-				context.rsp += 8;
-				if (!_nvmem_4gb_space())
-					//restore the addr from r9 to arg0 (rcx or rdi) so it's valid again
-#ifdef _WIN32
-					context.rcx = context.r9;
-#else
-					context.rdi = context.r9;
-#endif
-
-				return true;
-			}
-		}
-		ERROR_LOG(DYNAREC, "rewriteMemAccess code not found: host pc %p", (void *)context.pc);
-		die("Failed to match the code");
-
-		return false;
-	}
-
 private:
 	bool GenReadMemImmediate(const shil_opcode& op, RuntimeBlockInfo* block)
 	{
@@ -1034,10 +1169,106 @@ private:
 		return true;
 	}
 
-	void CheckBlock(bool force_checks, RuntimeBlockInfo* block)
+	bool GenReadMemoryFast(const shil_opcode& op, RuntimeBlockInfo* block)
 	{
-		if (mmu_enabled() || force_checks)
-			mov(call_regs[0], block->addr);
+		if (!mmu_enabled() || !vmem32_enabled())
+			return false;
+		mem_reads++;
+		const u8 *start_addr = getCurr();
+
+		mov(rax, (uintptr_t)&p_sh4rcb->cntx.exception_pc);
+		mov(dword[rax], block->vaddr + op.guest_offs - (op.delay_slot ? 2 : 0));
+
+		mov(rax, (uintptr_t)virt_ram_base);
+
+		u32 size = op.flags & 0x7f;
+		//verify(getCurr() - start_addr == 26);
+		if (mem_access_offset == 0)
+			mem_access_offset = getCurr() - start_addr;
+		else
+			verify(getCurr() - start_addr == mem_access_offset);
+
+		block->memory_accesses[(void*)getCurr()] = (u32)current_opid;
+		switch (size)
+		{
+		case 1:
+			movsx(eax, byte[rax + call_regs64[0]]);
+			break;
+
+		case 2:
+			movsx(eax, word[rax + call_regs64[0]]);
+			break;
+
+		case 4:
+			mov(eax, dword[rax + call_regs64[0]]);
+			break;
+
+		case 8:
+			mov(rax, qword[rax + call_regs64[0]]);
+			break;
+
+		default:
+			die("1..8 bytes");
+		}
+
+		while (getCurr() - start_addr < read_mem_op_size)
+			nop();
+		verify(getCurr() - start_addr == read_mem_op_size);
+
+		return true;
+	}
+
+	bool GenWriteMemoryFast(const shil_opcode& op, RuntimeBlockInfo* block)
+	{
+		if (!mmu_enabled() || !vmem32_enabled())
+			return false;
+		mem_writes++;
+		const u8 *start_addr = getCurr();
+
+		mov(rax, (uintptr_t)&p_sh4rcb->cntx.exception_pc);
+		mov(dword[rax], block->vaddr + op.guest_offs - (op.delay_slot ? 2 : 0));
+
+		mov(rax, (uintptr_t)virt_ram_base);
+
+		u32 size = op.flags & 0x7f;
+		//verify(getCurr() - start_addr == 26);
+		if (mem_access_offset == 0)
+			mem_access_offset = getCurr() - start_addr;
+		else
+			verify(getCurr() - start_addr == mem_access_offset);
+
+		block->memory_accesses[(void*)getCurr()] = (u32)current_opid;
+		switch (size)
+		{
+		case 1:
+			mov(byte[rax + call_regs64[0] + 0], call_regs[1].cvt8());
+			break;
+
+		case 2:
+			mov(word[rax + call_regs64[0]], call_regs[1].cvt16());
+			break;
+
+		case 4:
+			mov(dword[rax + call_regs64[0]], call_regs[1]);
+			break;
+
+		case 8:
+			mov(qword[rax + call_regs64[0]], call_regs64[1]);
+			break;
+
+		default:
+			die("1..8 bytes");
+		}
+
+		while (getCurr() - start_addr < write_mem_op_size)
+			nop();
+		verify(getCurr() - start_addr == write_mem_op_size);
+
+		return true;
+	}
+
+	void CheckBlock(bool force_checks, RuntimeBlockInfo* block) {
+		mov(call_regs[0], block->addr);
 
 		// FIXME This test shouldn't be necessary
 		// However the decoder makes various assumptions about the current PC value, which are simply not
@@ -1088,162 +1319,23 @@ private:
 		}
 	}
 
-	void genMemHandlers()
-	{
-		// make sure the memory handlers are set
-		verify(ReadMem8 != nullptr);
-
-		MemHandlerStart = getCurr();
-		for (int type = 0; type < MemOp::Count; type++)
-		{
-			for (int size = 0; size < MemSize::Count; size++)
-			{
-				for (int op = 0; op < MemOp::Count; op++)
-				{
-					MemHandlers[type][size][op] = getCurr();
-					if (type == MemType::Fast && _nvmem_enabled() && (!mmu_enabled() || vmem32_enabled()))
-					{
-						if (mmu_enabled())
-						{
-							mov(rax, (uintptr_t)&p_sh4rcb->cntx.exception_pc);
-							mov(dword[rax], call_regs[2]);
-						}
-						mov(rax, (uintptr_t)virt_ram_base);
-						if (!_nvmem_4gb_space())
-						{
-							mov(r9, call_regs64[0]);
-							and_(call_regs[0], 0x1FFFFFFF);
-						}
-						switch (size)
-						{
-						case MemSize::S8:
-							if (op == MemOp::R)
-								movsx(eax, byte[rax + call_regs64[0]]);
-							else
-								mov(byte[rax + call_regs64[0]], call_regs[1].cvt8());
-							break;
-
-						case MemSize::S16:
-							if (op == MemOp::R)
-								movsx(eax, word[rax + call_regs64[0]]);
-							else
-								mov(word[rax + call_regs64[0]], call_regs[1].cvt16());
-							break;
-
-						case MemSize::S32:
-							if (op == MemOp::R)
-								mov(eax, dword[rax + call_regs64[0]]);
-							else
-								mov(dword[rax + call_regs64[0]], call_regs[1]);
-							break;
-
-						case MemSize::S64:
-							if (op == MemOp::R)
-								mov(rax, qword[rax + call_regs64[0]]);
-							else
-								mov(qword[rax + call_regs64[0]], call_regs64[1]);
-							break;
-						}
-					}
-					else
-					{
-						// Slow path
-						if (op == MemOp::R)
-						{
-							if (mmu_enabled())
-								mov(call_regs[1], call_regs[2]);
-							switch (size) {
-							case MemSize::S8:
-								sub(rsp, 8);
-								if (mmu_enabled())
-									call((const void *)ReadMemNoEx<u8>);
-								else
-									call((const void *)ReadMem8);
-								movsx(eax, al);
-								add(rsp, 8);
-								break;
-							case MemSize::S16:
-								sub(rsp, 8);
-								if (mmu_enabled())
-									call((const void *)ReadMemNoEx<u16>);
-								else
-									call((const void *)ReadMem16);
-								movsx(eax, ax);
-								add(rsp, 8);
-								break;
-							case MemSize::S32:
-								if (mmu_enabled())
-									jmp((const void *)ReadMemNoEx<u32>);
-								else
-									jmp((const void *)ReadMem32);	// tail call
-								continue;
-							case MemSize::S64:
-								if (mmu_enabled())
-									jmp((const void *)ReadMemNoEx<u64>);
-								else
-									jmp((const void *)ReadMem64);	// tail call
-								continue;
-							default:
-								die("1..8 bytes");
-							}
-						}
-						else
-						{
-							switch (size) {
-							case MemSize::S8:
-								if (mmu_enabled())
-									jmp((const void *)WriteMemNoEx<u8>);
-								else
-									jmp((const void *)WriteMem8);	// tail call
-								continue;
-							case MemSize::S16:
-								if (mmu_enabled())
-									jmp((const void *)WriteMemNoEx<u16>);
-								else
-									jmp((const void *)WriteMem16);	// tail call
-								continue;
-							case MemSize::S32:
-								if (mmu_enabled())
-									jmp((const void *)WriteMemNoEx<u32>);
-								else
-									jmp((const void *)WriteMem32);	// tail call
-								continue;
-							case MemSize::S64:
-								if (mmu_enabled())
-									jmp((const void *)WriteMemNoEx<u64>);
-								else
-									jmp((const void *)WriteMem64);	// tail call
-								continue;
-							default:
-								die("1..8 bytes");
-							}
-						}
-					}
-					ret();
-				}
-			}
-		}
-		MemHandlerEnd = getCurr();
-	}
-
-	void saveXmmRegisters()
+	template<class Ret, class... Params>
+	void GenCall(Ret(*function)(Params...), bool skip_floats = false)
 	{
 #ifndef _WIN32
-		if (current_opid == (size_t)-1)
-			return;
-
-		bool xmm8_mapped = regalloc.IsMapped(xmm8, current_opid);
-		bool xmm9_mapped = regalloc.IsMapped(xmm9, current_opid);
-		bool xmm10_mapped = regalloc.IsMapped(xmm10, current_opid);
-		bool xmm11_mapped = regalloc.IsMapped(xmm11, current_opid);
+		bool xmm8_mapped = !skip_floats && current_opid != (size_t)-1 && regalloc.IsMapped(xmm8, current_opid);
+		bool xmm9_mapped = !skip_floats && current_opid != (size_t)-1 && regalloc.IsMapped(xmm9, current_opid);
+		bool xmm10_mapped = !skip_floats && current_opid != (size_t)-1 && regalloc.IsMapped(xmm10, current_opid);
+		bool xmm11_mapped = !skip_floats && current_opid != (size_t)-1 && regalloc.IsMapped(xmm11, current_opid);
 
 		// Need to save xmm registers as they are not preserved in linux/mach
+		int offset = 0;
+		u32 stack_size = 0;
 		if (xmm8_mapped || xmm9_mapped || xmm10_mapped || xmm11_mapped)
 		{
-			u32 stack_size = 4 * (xmm8_mapped + xmm9_mapped + xmm10_mapped + xmm11_mapped);
+			stack_size = 4 * (xmm8_mapped + xmm9_mapped + xmm10_mapped + xmm11_mapped);
 			stack_size = (((stack_size + 15) >> 4) << 4); // Stack needs to be 16-byte aligned before the call
 			sub(rsp, stack_size);
-			int offset = 0;
 			if (xmm8_mapped)
 			{
 				movd(ptr[rsp + offset], xmm8);
@@ -1260,62 +1352,43 @@ private:
 				offset += 4;
 			}
 			if (xmm11_mapped)
+			{
 				movd(ptr[rsp + offset], xmm11);
+				offset += 4;
+			}
 		}
 #endif
-	}
 
-	void restoreXmmRegisters()
-	{
-#ifndef _WIN32
-		if (current_opid == (size_t)-1)
-			return;
+		call(CC_RX2RW(function));
 
-		bool xmm8_mapped = regalloc.IsMapped(xmm8, current_opid);
-		bool xmm9_mapped = regalloc.IsMapped(xmm9, current_opid);
-		bool xmm10_mapped = regalloc.IsMapped(xmm10, current_opid);
-		bool xmm11_mapped = regalloc.IsMapped(xmm11, current_opid);
+#ifndef _WIN32
 		if (xmm8_mapped || xmm9_mapped || xmm10_mapped || xmm11_mapped)
 		{
-			u32 stack_size = 4 * (xmm8_mapped + xmm9_mapped + xmm10_mapped + xmm11_mapped);
-			int offset = stack_size - 4;
-			stack_size = (((stack_size + 15) >> 4) << 4); // Stack needs to be 16-byte aligned before the call
 			if (xmm11_mapped)
 			{
-				movd(xmm11, ptr[rsp + offset]);
 				offset -= 4;
+				movd(xmm11, ptr[rsp + offset]);
 			}
 			if (xmm10_mapped)
 			{
-				movd(xmm10, ptr[rsp + offset]);
 				offset -= 4;
+				movd(xmm10, ptr[rsp + offset]);
 			}
 			if (xmm9_mapped)
 			{
-				movd(xmm9, ptr[rsp + offset]);
 				offset -= 4;
+				movd(xmm9, ptr[rsp + offset]);
 			}
 			if (xmm8_mapped)
 			{
-				movd(xmm8, ptr[rsp + offset]);
 				offset -= 4;
+				movd(xmm8, ptr[rsp + offset]);
 			}
-			verify(offset == -4);
 			add(rsp, stack_size);
 		}
 #endif
 	}
 
-	template<class Ret, class... Params>
-	void GenCall(Ret(*function)(Params...), bool skip_floats = false)
-	{
-		if (!skip_floats)
-			saveXmmRegisters();
-		call(CC_RX2RW(function));
-		if (!skip_floats)
-			restoreXmmRegisters();
-	}
-
 	struct CC_PS
 	{
 		CanonicalParamType type;
@@ -1327,8 +1400,16 @@ private:
 	Xbyak::util::Cpu cpu;
 	size_t current_opid;
 	Xbyak::Label exit_block;
+	static const u32 read_mem_op_size;
+	static const u32 write_mem_op_size;
+public:
+	static u32 mem_access_offset;
 };
 
+const u32 BlockCompiler::read_mem_op_size = 30;
+const u32 BlockCompiler::write_mem_op_size = 30;
+u32 BlockCompiler::mem_access_offset = 0;
+
 void X64RegAlloc::Preload(u32 reg, Xbyak::Operand::Code nreg)
 {
 	compiler->RegPreload(reg, nreg);
@@ -1346,70 +1427,84 @@ void X64RegAlloc::Writeback_FPU(u32 reg, s8 nreg)
 	compiler->RegWriteback_FPU(reg, nreg);
 }
 
-static BlockCompiler* ccCompiler;
+static BlockCompiler* compiler;
 
 void ngen_Compile(RuntimeBlockInfo* block, bool smc_checks, bool reset, bool staging, bool optimise)
 {
 	verify(emit_FreeSpace() >= 16 * 1024);
 
-	BlockCompiler compiler;
-	::ccCompiler = &compiler;
-	try {
-		compiler.compile(block, smc_checks, reset, staging, optimise);
-	} catch (const Xbyak::Error& e) {
-		ERROR_LOG(DYNAREC, "Fatal xbyak error: %s", e.what());
-	}
-	::ccCompiler = nullptr;
+	compiler = new BlockCompiler();
+	
+	compiler->compile(block, smc_checks, reset, staging, optimise);
+
+	delete compiler;
 }
 
 void ngen_CC_Start(shil_opcode* op)
 {
-	ccCompiler->ngen_CC_Start(*op);
+	compiler->ngen_CC_Start(*op);
 }
 
 void ngen_CC_Param(shil_opcode* op, shil_param* par, CanonicalParamType tp)
 {
-	ccCompiler->ngen_CC_param(*op, *par, tp);
+	compiler->ngen_CC_param(*op, *par, tp);
 }
 
 void ngen_CC_Call(shil_opcode* op, void* function)
 {
-	ccCompiler->ngen_CC_Call(*op, function);
+	compiler->ngen_CC_Call(*op, function);
 }
 
 void ngen_CC_Finish(shil_opcode* op)
 {
 }
 
-bool ngen_Rewrite(host_context_t &context, void *faultAddress)
+bool ngen_Rewrite(unat& host_pc, unat, unat)
 {
-	u8 *retAddr = *(u8 **)context.rsp - 5;
-	BlockCompiler compiler(retAddr);
-	try {
-		return compiler.rewriteMemAccess(context);
-	} catch (const Xbyak::Error& e) {
-		ERROR_LOG(DYNAREC, "Fatal xbyak error: %s", e.what());
+	if (!mmu_enabled() || !vmem32_enabled())
+		return false;
+
+	//printf("ngen_Rewrite pc %p\n", host_pc);
+	RuntimeBlockInfoPtr block = bm_GetBlock((void *)host_pc);
+	if (block == NULL)
+	{
+		WARN_LOG(DYNAREC, "ngen_Rewrite: Block at %p not found", (void *)host_pc);
 		return false;
 	}
-}
+	u8 *code_ptr = (u8*)host_pc;
+	auto it = block->memory_accesses.find(code_ptr);
+	if (it == block->memory_accesses.end())
+	{
+		WARN_LOG(DYNAREC, "ngen_Rewrite: memory access at %p not found (%lu entries)", code_ptr, block->memory_accesses.size());
+		return false;
+	}
+	u32 opid = it->second;
+	verify(opid < block->oplist.size());
+	const shil_opcode& op = block->oplist[opid];
 
-void ngen_HandleException(host_context_t &context)
-{
-	context.pc = (uintptr_t)handleException;
+	BlockCompiler *assembler = new BlockCompiler(code_ptr - BlockCompiler::mem_access_offset);
+	assembler->InitializeRewrite(block.get(), opid);
+	if (op.op == shop_readm)
+	{
+		mem_rewrites_r++;
+		assembler->GenReadMemorySlow(op, block.get());
+	}
+	else
+	{
+		mem_rewrites_w++;
+		assembler->GenWriteMemorySlow(op, block.get());
+	}
+	assembler->FinalizeRewrite();
+	verify(block->host_code_size >= assembler->getSize());
+	delete assembler;
+	block->memory_accesses.erase(it);
+	host_pc = (unat)(code_ptr - BlockCompiler::mem_access_offset);
+
+	return true;
 }
 
-void ngen_ResetBlocks()
+void ngen_HandleException()
 {
-	// Avoid generating the main loop more than once
-	if (mainloop != nullptr && mainloop != emit_GetCCPtr())
-		return;
-
-	BlockCompiler compiler;
-	try {
-		compiler.genMainloop();
-	} catch (const Xbyak::Error& e) {
-		ERROR_LOG(DYNAREC, "Fatal xbyak error: %s", e.what());
-	}
+	longjmp(jmp_env, 1);
 }
-
 #endif
diff --git a/core/rec-x86/rec_x86.cpp b/core/rec-x86/rec_x86.cpp
index 9405607..85f8137 100644
--- a/core/rec-x86/rec_x86.cpp
+++ b/core/rec-x86/rec_x86.cpp
@@ -752,11 +752,10 @@ void ngen_Compile(RuntimeBlockInfo* block, bool smc_checks, bool, bool, bool opt
 	delete compiler;
 }
 
-bool ngen_Rewrite(host_context_t &context, void *faultAddress)
+bool ngen_Rewrite(size_t& host_pc, size_t addr, size_t acc)
 {
-	u8 *rewriteAddr = *(u8 **)context.esp - 5;
-	X86Compiler *compiler = new X86Compiler(rewriteAddr);
-	bool rv = compiler->rewriteMemAccess(context);
+	X86Compiler *compiler = new X86Compiler((u8*)(addr - 5));
+	bool rv = compiler->rewriteMemAccess(host_pc, addr, acc);
 	delete compiler;
 
 	return rv;
diff --git a/core/rec-x86/rec_x86.h b/core/rec-x86/rec_x86.h
index 42f47ee..2a6fc98 100644
--- a/core/rec-x86/rec_x86.h
+++ b/core/rec-x86/rec_x86.h
@@ -75,7 +75,7 @@ public:
 
 	void genMainloop();
 	u32 relinkBlock(RuntimeBlockInfo *block);
-	bool rewriteMemAccess(host_context_t &context);
+	bool rewriteMemAccess(size_t& host_pc, size_t retadr, size_t acc);
 
 private:
 	void genOpcode(RuntimeBlockInfo *block, bool optimise, shil_opcode& op);
diff --git a/core/rec-x86/x86_ops.cpp b/core/rec-x86/x86_ops.cpp
index 75cfcb4..46fcd54 100644
--- a/core/rec-x86/x86_ops.cpp
+++ b/core/rec-x86/x86_ops.cpp
@@ -433,20 +433,19 @@ void X86Compiler::genOpcode(RuntimeBlockInfo* block, bool optimise, shil_opcode&
 	}
 }
 
-bool X86Compiler::rewriteMemAccess(host_context_t &context)
+bool X86Compiler::rewriteMemAccess(size_t& host_pc, size_t retadr, size_t acc)
 {
-	u8 *retAddr = *(u8 **)context.esp;
-	//DEBUG_LOG(DYNAREC, "rewriteMemAccess hpc %08x retadr %08x", context.pc, (size_t)retAddr);
-	if (context.pc < (size_t)MemHandlerStart || context.pc >= (size_t)MemHandlerEnd)
+	//DEBUG_LOG(DYNAREC, "rewriteMemAccess hpc %08x retadr %08x", host_pc, retadr);
+	if (host_pc < (size_t)MemHandlerStart || host_pc >= (size_t)MemHandlerEnd)
 		return false;
 
-	void *ca = *(u32 *)(retAddr - 4) + retAddr;
+	u32 ca = *(u32 *)(retadr - 4) + retadr;
 
 	for (int size = 0; size < MemOp::SizeCount; size++)
 	{
 		for (int op = 0; op < MemOp::OpCount; op++)
 		{
-			if ((void *)MemHandlers[MemOp::Fast][size][op] != ca)
+			if ((u32)MemHandlers[MemOp::Fast][size][op] != ca)
 				continue;
 
 			//found !
@@ -456,16 +455,12 @@ bool X86Compiler::rewriteMemAccess(host_context_t &context)
 
 			ready();
 
-			context.pc = (size_t)(retAddr - 5);
-			//remove the call from call stack
-			context.esp += 4;
-			//restore the addr from eax to ecx so it's valid again
-			context.ecx = context.eax;
+			host_pc = retadr - 5;
 
 			return true;
 		}
 	}
-	ERROR_LOG(DYNAREC, "rewriteMemAccess code not found: hpc %08x retadr %p acc %08x", context.pc, retAddr, context.eax);
+	ERROR_LOG(DYNAREC, "rewriteMemAccess code not found: hpc %08x retadr %08x acc %08x", host_pc, retadr, acc);
 	die("Failed to match the code");
 
 	return false;
diff --git a/core/serialize.cpp b/core/serialize.cpp
index cbd9827..58efbd3 100644
--- a/core/serialize.cpp
+++ b/core/serialize.cpp
@@ -32,6 +32,7 @@ extern u32 e68k_reg_L;
 extern u32 e68k_reg_M;
 
 //./core/hw/arm7/arm7.cpp
+alignas(8) extern reg_pair arm_Reg[RN_ARM_REG_COUNT];
 extern bool armIrqEnable;
 extern bool armFiqEnable;
 extern int armMode;
@@ -49,7 +50,6 @@ extern u32 ARMRST;//arm reset reg
 extern u32 rtc_EN;
 extern int dma_sched_id;
 extern u32 RealTimeClock;
-extern u32 SB_ADST;
 
 //./core/hw/aica/aica_mem.o
 extern u8 aica_reg[0x8000];
@@ -267,7 +267,7 @@ bool dc_serialize(void **data, unsigned int *total_size)
 	REICAST_S(e68k_reg_L) ;
 	REICAST_S(e68k_reg_M) ;
 
-	REICAST_SA(arm_Reg,RN_ARM_REG_COUNT - 1);	// Too lazy to create a new version and the scratch register is not used between blocks anyway
+	REICAST_SA(arm_Reg,RN_ARM_REG_COUNT);
 	REICAST_S(armIrqEnable);
 	REICAST_S(armFiqEnable);
 	REICAST_S(armMode);
@@ -298,7 +298,7 @@ bool dc_serialize(void **data, unsigned int *total_size)
 	REICAST_S(SB_ISTNRM);
 	REICAST_S(SB_FFST_rc);
 	REICAST_S(SB_FFST);
-	REICAST_S(SB_ADST);
+
 
 	sys_rom->Serialize(data, total_size);
 	sys_nvmem->Serialize(data, total_size);
@@ -499,7 +499,7 @@ static bool dc_unserialize_libretro(void **data, unsigned int *total_size)
 	REICAST_US(e68k_reg_L) ;
 	REICAST_US(e68k_reg_M) ;
 
-	REICAST_USA(arm_Reg,RN_ARM_REG_COUNT - 1);
+	REICAST_USA(arm_Reg,RN_ARM_REG_COUNT);
 	REICAST_US(armIrqEnable);
 	REICAST_US(armFiqEnable);
 	REICAST_US(armMode);
@@ -529,7 +529,6 @@ static bool dc_unserialize_libretro(void **data, unsigned int *total_size)
 	REICAST_US(SB_ISTNRM);
 	REICAST_US(SB_FFST_rc);
 	REICAST_US(SB_FFST);
-	SB_ADST = 0;
 
 	if (settings.platform.system == DC_PLATFORM_NAOMI || settings.platform.system == DC_PLATFORM_ATOMISWAVE)
 	{
@@ -774,7 +773,7 @@ bool dc_unserialize(void **data, unsigned int *total_size)
 	REICAST_US(e68k_reg_L) ;
 	REICAST_US(e68k_reg_M) ;
 
-	REICAST_USA(arm_Reg,RN_ARM_REG_COUNT - 1);
+	REICAST_USA(arm_Reg,RN_ARM_REG_COUNT);
 	REICAST_US(armIrqEnable);
 	REICAST_US(armFiqEnable);
 	REICAST_US(armMode);
@@ -822,10 +821,6 @@ bool dc_unserialize(void **data, unsigned int *total_size)
 	REICAST_US(SB_ISTNRM);
 	REICAST_US(SB_FFST_rc);
 	REICAST_US(SB_FFST);
-	if (version >= V15)
-		REICAST_US(SB_ADST);
-	else
-		SB_ADST = 0;
 
 	if (version < V5)
 	{
diff --git a/core/types.h b/core/types.h
index 7e2917b..ca519f2 100644
--- a/core/types.h
+++ b/core/types.h
@@ -476,6 +476,5 @@ enum serialize_version_enum {
 	V12 = 807,
 	V13 = 808,
 	V14 = 809,
-	V15 = 810,
-	VCUR_FLYCAST = V15,
+	VCUR_FLYCAST = V14,
 } ;
diff --git a/core/windows/winmain.cpp b/core/windows/winmain.cpp
index a0379aa..2af647e 100644
--- a/core/windows/winmain.cpp
+++ b/core/windows/winmain.cpp
@@ -15,8 +15,6 @@
 #include "hw/maple/maple_devs.h"
 #include "emulator.h"
 #include "rend/mainui.h"
-#include "hw/sh4/dyna/ngen.h"
-#include "oslib/host_context.h"
 
 #include <windows.h>
 #include <windowsx.h>
@@ -116,6 +114,7 @@ PCHAR*
 }
 
 bool VramLockedWrite(u8* address);
+bool ngen_Rewrite(unat& addr,unat retadr,unat acc);
 bool BM_LockedWrite(u8* address);
 
 static std::shared_ptr<WinKbGamepadDevice> kb_gamepad;
@@ -134,75 +133,59 @@ void os_SetupInput()
 #endif
 }
 
-static void readContext(const EXCEPTION_POINTERS *ep, host_context_t &context)
+LONG ExeptionHandler(EXCEPTION_POINTERS *ExceptionInfo)
 {
-#if HOST_CPU == CPU_X86
-	context.pc = ep->ContextRecord->Eip;
-	context.esp = ep->ContextRecord->Esp;
-	context.eax = ep->ContextRecord->Eax;
-	context.ecx = ep->ContextRecord->Ecx;
-#elif HOST_CPU == CPU_X64
-	context.pc = ep->ContextRecord->Rip;
-	context.rsp = ep->ContextRecord->Rsp;
-	context.r9 = ep->ContextRecord->R9;
-	context.rcx = ep->ContextRecord->Rcx;
-#endif
-}
+	EXCEPTION_POINTERS* ep = ExceptionInfo;
 
-static void writeContext(EXCEPTION_POINTERS *ep, const host_context_t &context)
-{
-#if HOST_CPU == CPU_X86
-	ep->ContextRecord->Eip = context.pc;
-	ep->ContextRecord->Esp = context.esp;
-	ep->ContextRecord->Eax = context.eax;
-	ep->ContextRecord->Ecx = context.ecx;
-#elif HOST_CPU == CPU_X64
-	ep->ContextRecord->Rip = context.pc;
-	ep->ContextRecord->Rsp = context.rsp;
-	ep->ContextRecord->R9 = context.r9;
-	ep->ContextRecord->Rcx = context.rcx;
-#endif
-}
-LONG ExeptionHandler(EXCEPTION_POINTERS *ep)
-{
 	u32 dwCode = ep->ExceptionRecord->ExceptionCode;
 
+	EXCEPTION_RECORD* pExceptionRecord=ep->ExceptionRecord;
+
 	if (dwCode != EXCEPTION_ACCESS_VIOLATION)
 		return EXCEPTION_CONTINUE_SEARCH;
 
-	EXCEPTION_RECORD* pExceptionRecord = ep->ExceptionRecord;
-	u8* address = (u8 *)pExceptionRecord->ExceptionInformation[1];
+	u8* address=(u8*)pExceptionRecord->ExceptionInformation[1];
 
 	//printf("[EXC] During access to : 0x%X\n", address);
 #if 0
-	// WinCE virtual memory
-	bool write = false;
+	bool write = false;	// TODO?
 	if (vmem32_handle_signal(address, write, 0))
 		return EXCEPTION_CONTINUE_EXECUTION;
 #endif
-	// code protection in RAM
 	if (bm_RamWriteAccess(address))
+	{
 		return EXCEPTION_CONTINUE_EXECUTION;
-	// texture protection in VRAM
-	if (VramLockedWrite(address))
-		return EXCEPTION_CONTINUE_EXECUTION;
-	// FPCB jump table protection
-	if (BM_LockedWrite(address))
+	}
+	else if (VramLockedWrite(address))
+	{
 		return EXCEPTION_CONTINUE_EXECUTION;
-
-	host_context_t context;
-	readContext(ep, context);
-#if FEAT_SHREC == DYNAREC_JIT
-	// fast mem access rewriting
-	if (ngen_Rewrite(context, address))
+	}
+	else if (BM_LockedWrite(address))
 	{
-		writeContext(ep, context);
 		return EXCEPTION_CONTINUE_EXECUTION;
 	}
+#if FEAT_SHREC == DYNAREC_JIT
+#if HOST_CPU == CPU_X86
+		else if (ngen_Rewrite((unat&)ep->ContextRecord->Eip, *(unat*)ep->ContextRecord->Esp, ep->ContextRecord->Eax))
+		{
+			//remove the call from call stack
+			ep->ContextRecord->Esp += 4;
+			//restore the addr from eax to ecx so its valid again
+			ep->ContextRecord->Ecx = ep->ContextRecord->Eax;
+			return EXCEPTION_CONTINUE_EXECUTION;
+		}
+#elif HOST_CPU == CPU_X64
+		else if (ngen_Rewrite((unat&)ep->ContextRecord->Rip, 0, 0))
+		{
+			return EXCEPTION_CONTINUE_EXECUTION;
+		}
 #endif
-
-    ERROR_LOG(COMMON, "[GPF] PC %p unhandled access to %p", (void *)context.pc, address);
-    os_DebugBreak();
+#endif
+	else
+	{
+	    ERROR_LOG(COMMON, "[GPF]Unhandled access to : %p", address);
+	    os_DebugBreak();
+	}
 
 	return EXCEPTION_CONTINUE_SEARCH;
 }
@@ -616,6 +599,7 @@ void ReserveBottomMemory()
 }
 
 #ifdef _WIN64
+#include "hw/sh4/dyna/ngen.h"
 
 typedef union _UNWIND_CODE {
 	struct {
diff --git a/shell/apple/emulator-osx/reicast-osx.xcodeproj/project.pbxproj b/shell/apple/emulator-osx/reicast-osx.xcodeproj/project.pbxproj
index 7a2f599..01f7df0 100644
--- a/shell/apple/emulator-osx/reicast-osx.xcodeproj/project.pbxproj
+++ b/shell/apple/emulator-osx/reicast-osx.xcodeproj/project.pbxproj
@@ -40,6 +40,7 @@
 		84B7BF2A1B72720200F9733F /* arm7.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDD41B72720100F9733F /* arm7.cpp */; };
 		84B7BF2B1B72720200F9733F /* arm_mem.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDD61B72720100F9733F /* arm_mem.cpp */; };
 		84B7BF2C1B72720200F9733F /* vbaARM.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDD91B72720100F9733F /* vbaARM.cpp */; };
+		84B7BF2D1B72720200F9733F /* virt_arm.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDDA1B72720100F9733F /* virt_arm.cpp */; };
 		84B7BF2E1B72720200F9733F /* gdrom_response.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDE01B72720100F9733F /* gdrom_response.cpp */; };
 		84B7BF2F1B72720200F9733F /* gdromv3.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDE11B72720100F9733F /* gdromv3.cpp */; };
 		84B7BF301B72720200F9733F /* holly_intc.cpp in Sources */ = {isa = PBXBuildFile; fileRef = 84B7BDE41B72720100F9733F /* holly_intc.cpp */; };
@@ -181,8 +182,6 @@
 		AE7BCB62243DDD92007285F8 /* Carbon.framework in Frameworks */ = {isa = PBXBuildFile; fileRef = AE7BCB61243DDD92007285F8 /* Carbon.framework */; };
 		AE7BCB6B244608B6007285F8 /* naomi_network.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE7BCB69244608B5007285F8 /* naomi_network.cpp */; };
 		AE7BCB6E24460910007285F8 /* naomi_m3comm.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE7BCB6C24460910007285F8 /* naomi_m3comm.cpp */; };
-		AE7BCB582415515B007285F8 /* arm7_rec_x64.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE7BCB562415515B007285F8 /* arm7_rec_x64.cpp */; };
-		AE7BCB592415515B007285F8 /* arm7_rec.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE7BCB572415515B007285F8 /* arm7_rec.cpp */; };
 		AE80EDB72157D4D500F7800F /* serialize.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE80EDB62157D4D500F7800F /* serialize.cpp */; };
 		AE80EDBE2157D4E600F7800F /* naomi.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE80EDB92157D4E600F7800F /* naomi.cpp */; };
 		AE80EDBF2157D4E600F7800F /* naomi_cart.cpp in Sources */ = {isa = PBXBuildFile; fileRef = AE80EDBB2157D4E600F7800F /* naomi_cart.cpp */; };
@@ -458,6 +457,8 @@
 		84B7BDD61B72720100F9733F /* arm_mem.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = arm_mem.cpp; sourceTree = "<group>"; };
 		84B7BDD71B72720100F9733F /* arm_mem.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = arm_mem.h; sourceTree = "<group>"; };
 		84B7BDD91B72720100F9733F /* vbaARM.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = vbaARM.cpp; sourceTree = "<group>"; };
+		84B7BDDA1B72720100F9733F /* virt_arm.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = virt_arm.cpp; sourceTree = "<group>"; };
+		84B7BDDB1B72720100F9733F /* virt_arm.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = virt_arm.h; sourceTree = "<group>"; };
 		84B7BDDD1B72720100F9733F /* flashrom.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = flashrom.h; sourceTree = "<group>"; };
 		84B7BDDF1B72720100F9733F /* gdrom_if.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = gdrom_if.h; sourceTree = "<group>"; };
 		84B7BDE01B72720100F9733F /* gdrom_response.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = gdrom_response.cpp; sourceTree = "<group>"; };
@@ -569,6 +570,7 @@
 		84B7BE631B72720100F9733F /* khrplatform.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = khrplatform.h; sourceTree = "<group>"; };
 		84B7BE651B72720100F9733F /* common.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = common.cpp; sourceTree = "<group>"; };
 		84B7BE661B72720100F9733F /* context.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = context.cpp; sourceTree = "<group>"; };
+		84B7BE671B72720100F9733F /* context.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = context.h; sourceTree = "<group>"; };
 		84B7BE6E1B72720200F9733F /* nullDC.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; name = nullDC.cpp; path = ../../../core/nullDC.cpp; sourceTree = "<group>"; };
 		84B7BE701B72720200F9733F /* audiobackend_alsa.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = audiobackend_alsa.cpp; sourceTree = "<group>"; };
 		84B7BE711B72720200F9733F /* audiobackend_alsa.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = audiobackend_alsa.h; sourceTree = "<group>"; };
@@ -761,9 +763,6 @@
 		AE7BCB6A244608B6007285F8 /* naomi_network.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = naomi_network.h; sourceTree = "<group>"; };
 		AE7BCB6C24460910007285F8 /* naomi_m3comm.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = naomi_m3comm.cpp; sourceTree = "<group>"; };
 		AE7BCB6D24460910007285F8 /* naomi_m3comm.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = naomi_m3comm.h; sourceTree = "<group>"; };
-		AE7BCB552415515B007285F8 /* arm7_rec.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = arm7_rec.h; sourceTree = "<group>"; };
-		AE7BCB562415515B007285F8 /* arm7_rec_x64.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = arm7_rec_x64.cpp; sourceTree = "<group>"; };
-		AE7BCB572415515B007285F8 /* arm7_rec.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = arm7_rec.cpp; sourceTree = "<group>"; };
 		AE80EDB62157D4D500F7800F /* serialize.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; name = serialize.cpp; path = ../../../core/serialize.cpp; sourceTree = "<group>"; };
 		AE80EDB92157D4E600F7800F /* naomi.cpp */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.cpp.cpp; path = naomi.cpp; sourceTree = "<group>"; };
 		AE80EDBA2157D4E600F7800F /* naomi.h */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = sourcecode.c.h; path = naomi.h; sourceTree = "<group>"; };
@@ -1541,15 +1540,14 @@
 		84B7BDD21B72720100F9733F /* arm7 */ = {
 			isa = PBXGroup;
 			children = (
-				AE7BCB562415515B007285F8 /* arm7_rec_x64.cpp */,
-				AE7BCB572415515B007285F8 /* arm7_rec.cpp */,
-				AE7BCB552415515B007285F8 /* arm7_rec.h */,
 				84B7BDD31B72720100F9733F /* arm-new.h */,
 				84B7BDD41B72720100F9733F /* arm7.cpp */,
 				84B7BDD51B72720100F9733F /* arm7.h */,
 				84B7BDD61B72720100F9733F /* arm_mem.cpp */,
 				84B7BDD71B72720100F9733F /* arm_mem.h */,
 				84B7BDD91B72720100F9733F /* vbaARM.cpp */,
+				84B7BDDA1B72720100F9733F /* virt_arm.cpp */,
+				84B7BDDB1B72720100F9733F /* virt_arm.h */,
 			);
 			path = arm7;
 			sourceTree = "<group>";
@@ -1809,6 +1807,7 @@
 			children = (
 				84B7BE651B72720100F9733F /* common.cpp */,
 				84B7BE661B72720100F9733F /* context.cpp */,
+				84B7BE671B72720100F9733F /* context.h */,
 				AEF2564722886A2E00348550 /* posix_vmem.cpp */,
 			);
 			name = linux;
@@ -2809,7 +2808,6 @@
 				AEE6278722131BB500EC7E89 /* gamepad_device.cpp in Sources */,
 				AE82C68625B64AE200C79BC2 /* zip_set_archive_comment.c in Sources */,
 				84B7BF171B72720200F9733F /* compress.c in Sources */,
-				AE7BCB592415515B007285F8 /* arm7_rec.cpp in Sources */,
 				AE649C3C218C555600EF4A81 /* cdrom.c in Sources */,
 				AE649BF3218C552500EF4A81 /* bitmath.c in Sources */,
 				AE649C30218C553A00EF4A81 /* Sort.c in Sources */,
@@ -2988,6 +2986,7 @@
 				AE649BF4218C552500EF4A81 /* bitreader.c in Sources */,
 				84B7BF491B72720200F9733F /* bsc.cpp in Sources */,
 				AE649BFB218C552500EF4A81 /* format.c in Sources */,
+				84B7BF2D1B72720200F9733F /* virt_arm.cpp in Sources */,
 				AE43537222C9420C005E19CE /* ConsoleListenerDroid.cpp in Sources */,
 				84A388B91B1CDD3E000166C0 /* AppDelegate.swift in Sources */,
 				AEFF7F75214D9D590068CE11 /* pico_stack.c in Sources */,
@@ -2997,7 +2996,6 @@
 				AE649BFC218C552500EF4A81 /* lpc.c in Sources */,
 				AEF9986B2598900A0038E0B8 /* upnpcommands.c in Sources */,
 				AEF998622598900A0038E0B8 /* connecthostport.c in Sources */,
-				AE7BCB582415515B007285F8 /* arm7_rec_x64.cpp in Sources */,
 				AEFF7F54214D9D590068CE11 /* pico_dns_client.c in Sources */,
 				AEF998752598900A0038E0B8 /* minissdpc.c in Sources */,
 				AEFF7F57214D9D590068CE11 /* pico_fragments.c in Sources */,
diff --git a/shell/linux/Makefile b/shell/linux/Makefile
index 553517f..6486127 100644
--- a/shell/linux/Makefile
+++ b/shell/linux/Makefile
@@ -458,6 +458,10 @@ ifdef DEBUGFAST
     CFLAGS += -DDEBUGFAST
 endif
 
+ifdef UNIT_TESTS
+    CFLAGS += -DUNIT_TESTS
+endif
+
 ifdef ASAN
 	CFLAGS += -fsanitize=address -static-libasan
 	LDFLAGS += -fsanitize=address -static-libasan
@@ -467,20 +471,11 @@ ifdef LOG_TO_PTY
     CFLAGS += -D LOG_TO_PTY
 endif
 
-ifdef UNIT_TESTS
-    CFLAGS += -DUNIT_TESTS
-	EXECUTABLE_STRIPPED=nosym-alltests
-	DC_PLATFORM=tests
-	EXECUTABLE=alltests.$(PLATFORM_EXT)
-	EXECUTABLE_NAME=alltests
-	TEST_SRC_DIR:=$(RZDCY_SRC_DIR)/../tests/src
-	RZDCY_FILES += $(wildcard $(TEST_SRC_DIR)/*.cpp) $(RZDCY_SRC_DIR)/deps/gtest/src/gtest_main.cc $(RZDCY_SRC_DIR)/deps/gtest/src/gtest-all.cc
-else
-	EXECUTABLE_STRIPPED=nosym-reicast.$(PLATFORM_EXT)
-	DC_PLATFORM=dreamcast
-	EXECUTABLE=reicast.$(PLATFORM_EXT)
-	EXECUTABLE_NAME=flycast
-endif
+
+EXECUTABLE_STRIPPED=nosym-reicast.$(PLATFORM_EXT)
+DC_PLATFORM=dreamcast
+EXECUTABLE=reicast.$(PLATFORM_EXT)
+EXECUTABLE_NAME=flycast
 
 ifndef NOT_ARM
     AS=$(CC)
@@ -602,10 +597,27 @@ uninstall:
 	rm -f $(DESTDIR)$(ICON_DIR)/flycast.png
 
 clean:
-	rm -f $(OBJECTS) $(EXECUTABLE) $(EXECUTABLE_STRIPPED) .map $(VERSION_HEADER)
+	rm -f $(OBJECTS) $(EXECUTABLE) $(EXECUTABLE_STRIPPED) .map $(VERSION_HEADER) $(TEST_OBJ) alltests
+
+TEST_SRC_DIR:=$(LOCAL_PATH)/../../tests/src
+TEST_SRC:=$(wildcard $(TEST_SRC_DIR)/*.cpp) $(RZDCY_SRC_DIR)/deps/gtest/src/gtest_main.cc $(RZDCY_SRC_DIR)/deps/gtest/src/gtest-all.cc
+TEST_OBJ:=$(TEST_SRC:.cpp=.build_obj)
+TEST_OBJ:=$(TEST_OBJ:.cc=.build_obj)
+TEST_OBJ:=$(patsubst $(TEST_SRC_DIR)/%,$(BUILDDIR)/%,$(TEST_OBJ))
+TEST_OBJ:=$(patsubst $(RZDCY_SRC_DIR)/%,$(BUILDDIR)/%,$(TEST_OBJ))
+
+$(BUILDDIR)/%.build_obj : $(TEST_SRC_DIR)/%.cpp
+$(BUILDDIR)/%.build_obj: $(TEST_SRC_DIR)/%.cpp $(DEPDIR)/%.d
+	mkdir -p $(dir $@)
+	mkdir -p .dep-$(dir $@)
+	$(CXX) $(EXTRAFLAGS) $(INCS) $(DEPFLAGS) $(CFLAGS) $(MFLAGS) $(CXXFLAGS) $< -o $@
+	$(POSTCOMPILE)
+
+tests: alltests
+	./alltests
 
-tests: alltests.$(PLATFORM_EXT)
-	./alltests.$(PLATFORM_EXT)
+alltests: $(TEST_OBJ) $(OBJECTS)
+	$(CXX) $(MFLAGS) $(EXTRAFLAGS) $(LDFLAGS) $(TEST_OBJ) $(OBJECTS) $(LIBS) -o $@
 
 .PRECIOUS = $(DEPDIR)/%.d
 $(DEPDIR)/%.d: ;
diff --git a/tests/src/AicaArmTest.cpp b/tests/src/AicaArmTest.cpp
deleted file mode 100644
index a786ae6..0000000
--- a/tests/src/AicaArmTest.cpp
+++ /dev/null
@@ -1,1078 +0,0 @@
-#include "gtest/gtest.h"
-#include "types.h"
-#include "hw/mem/_vmem.h"
-#include "hw/arm7/arm7.h"
-#include "hw/aica/aica_if.h"
-#include "hw/arm7/arm7_rec.h"
-
-extern bool Arm7Enabled;
-
-void dc_init();
-void dc_reset(bool hard);
-
-static const u32 N_FLAG = 1 << 31;
-static const u32 Z_FLAG = 1 << 30;
-static const u32 C_FLAG = 1 << 29;
-static const u32 V_FLAG = 1 << 28;
-static const u32 NZCV_MASK = N_FLAG | Z_FLAG | C_FLAG | V_FLAG;
-
-
-namespace aicaarm::recompiler {
-
-extern void (*EntryPoints[])();
-
-class AicaArmTest : public ::testing::Test {
-protected:
-	void SetUp() override {
-		if (!_vmem_reserve())
-			die("_vmem_reserve failed");
-		dc_init();
-		dc_reset(true);
-		Arm7Enabled = true;
-	}
-
-	void PrepareOp(u32 op)
-	{
-		PrepareOps(1, &op);
-	}
-
-	void PrepareOps(int count, u32 *ops)
-	{
-		arm_Reg[R15_ARM_NEXT].I = 0x1000;
-		for (int i = 0; i < count; i++)
-			*(u32*)&aica_ram[0x1000 + i * 4] = ops[i];
-		*(u32*)&aica_ram[0x1000 + count * 4] = 0xea000000 | ((u32)(-count * 4 - 8) << 2);	// b pc+8-12
-		flush();
-		compile();
-	}
-
-	void RunOp()
-	{
-		arm_Reg[R15_ARM_NEXT].I = 0x1000;
-		arm_Reg[CYCL_CNT].I = 1;
-		arm_mainloop(arm_Reg, EntryPoints);
-	}
-	void ResetNZCV()
-	{
-		arm_Reg[RN_PSR_FLAGS].I &= ~NZCV_MASK;
-	}
-};
-#define ASSERT_NZCV_EQ(expected) ASSERT_EQ(arm_Reg[RN_PSR_FLAGS].I & NZCV_MASK, (expected));
-
-TEST_F(AicaArmTest, ArithmeticOpsTest)
-{
-	PrepareOp(0xe0810002);	// add r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xbaad0000;
-	arm_Reg[2].I = 0x0000cafe;
-	arm_Reg[RN_PSR_FLAGS].I |= NZCV_MASK;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-	ASSERT_NZCV_EQ(NZCV_MASK);
-
-	PrepareOp(0xe0810000);	// add r0, r1, r0
-	arm_Reg[0].I = 11;
-	arm_Reg[1].I = 22;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 33);
-
-	PrepareOp(0xe0410002);	// sub r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xbaadcafe;
-	arm_Reg[2].I = 0x0000cafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaad0000);
-	ASSERT_NZCV_EQ(NZCV_MASK);
-
-	PrepareOp(0xe0410000);	// sub r0, r1, r0
-	arm_Reg[0].I = 11;
-	arm_Reg[1].I = 22;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 11);
-
-	PrepareOp(0xe0910002);	// adds r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x80000000;
-	arm_Reg[2].I = 0x80000000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG | V_FLAG);	// Z,C,V
-
-	PrepareOp(0xe0510002);	// subs r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xbaadcafe;
-	arm_Reg[2].I = 0x0000cafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaad0000);
-	ASSERT_NZCV_EQ(N_FLAG | C_FLAG);	// N,C
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xbaadcafe;
-	arm_Reg[2].I = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);	// Z,C
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x80000000;
-	arm_Reg[2].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x7fffffff);
-	ASSERT_NZCV_EQ(C_FLAG | V_FLAG);	// C,V
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xffffffff;
-	arm_Reg[2].I = 0xffffffff;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);	// Z,C
-
-	PrepareOp(0xe0b10002);	// adcs r0, r1, r2
-	arm_Reg[RN_PSR_FLAGS].I &= ~NZCV_MASK;
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 3);
-	ASSERT_NZCV_EQ(0);	//
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG; // set C
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 4);
-	ASSERT_NZCV_EQ(0);	//
-
-	// from armwrestler
-	PrepareOp(0xe0d22002);	// sbcs r2,r2,r2
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;	// set C
-	arm_Reg[2].I = 0xFFFFFFFF;
-	RunOp();
-	ASSERT_EQ(arm_Reg[2].I, 0);
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);
-
-	// from armwrestler
-	PrepareOp(0xe2d22000);	// sbcs r2,r2,#0
-	ResetNZCV();
-	arm_Reg[2].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[2].I, -1);
-	ASSERT_NZCV_EQ(N_FLAG);
-
-	PrepareOp(0xe0d10002);	// sbcs r0, r1, r2
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, -2);
-	ASSERT_NZCV_EQ(N_FLAG);	// N
-
-	PrepareOp(0xe0710002);	// rsbs r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ASSERT_NZCV_EQ(C_FLAG);	// C, confirmed by interpreter and online arm sim
-
-	PrepareOp(0xe0f10002);	// rscs r0, r1, r2
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);	// Z,C
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG; // C set
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ASSERT_NZCV_EQ(C_FLAG);	// C
-
-	PrepareOp(0xe1500001);	// cmp r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 2;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_NZCV_EQ(C_FLAG);	// C
-
-	PrepareOp(0xe1700001);	// cmn r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 2;
-	arm_Reg[1].I = -1;
-	RunOp();
-	ASSERT_NZCV_EQ(C_FLAG);	// C
-}
-
-TEST_F(AicaArmTest, LogicOpsTest)
-{
-	PrepareOp(0xe1a00001);	// mov r0, r1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-
-	PrepareOp(0xe3c100ff);	// bic r0, r1, 0xff
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xffff;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xff00);
-
-	PrepareOp(0xe0010002);	// and r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xff0f;
-	arm_Reg[2].I = 0xf0f0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xf000);
-
-	PrepareOp(0xe0010000);	// and r0, r1, r0
-	arm_Reg[0].I = 0xf0f0f0f0;
-	arm_Reg[1].I = 0xffffffff;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xf0f0f0f0);
-
-	PrepareOp(0xe1a00251);	// asr r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xfffffff8;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xfffffffe);
-
-	PrepareOp(0xe1a00241); // asr r0, r1, 4
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x0ffffff0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x00ffffff);
-
-	PrepareOp(0xe0210002);	// eor r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0xffff0000;
-	arm_Reg[2].I = 0xf0f0f0f0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x0f0ff0f0);
-
-	PrepareOp(0xe0210000);	// eor r0, r1, r0
-	arm_Reg[0].I = 0xf0f0f0f0;
-	arm_Reg[1].I = 0xffffffff;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x0f0f0f0f);
-
-	PrepareOp(0xe1810000);	// orr r0, r1, r0
-	arm_Reg[0].I = 0xf0f0f0f0;
-	arm_Reg[1].I = 0x0f0f0f0f;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xffffffff);
-
-	PrepareOp(0xe1a00211);	// lsl r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 8;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x100);
-
-	PrepareOp(0xe1a00231);	// lsr r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x100;
-	arm_Reg[2].I = 4;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x10);
-
-	PrepareOp(0xe1a00271);	// ror r0, r1, r2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x12345678;
-	arm_Reg[2].I = 16;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x56781234);
-
-	PrepareOp(0xe1300001);	// teq r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_NZCV_EQ(0);
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG | V_FLAG;	// set C,V
-	arm_Reg[0].I = 1;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG | V_FLAG);	// Z,C,V
-
-	PrepareOp(0xe1100001);	// tst r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 1;
-	arm_Reg[1].I = 2;
-	RunOp();
-	ASSERT_NZCV_EQ(0x40000000);	// Z
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG | V_FLAG;	// set C,V
-	arm_Reg[0].I = 3;
-	arm_Reg[1].I = 2;
-	RunOp();
-	ASSERT_NZCV_EQ(C_FLAG | V_FLAG);	// C,V
-}
-
-TEST_F(AicaArmTest, Operand2ImmTest)
-{
-	PrepareOp(0xe2810003);	// add r0, r1, #3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 4);
-
-	PrepareOp(0xe2a10003);	// adc r0, r1, #3
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 5);
-
-	PrepareOp(0xe2410003);	// sub r0, r1, #3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 7;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 4);
-
-	PrepareOp(0xe2610003);	// rsb r0, r1, #3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 2);
-
-	PrepareOp(0xe2c10003);	// sbc r0, r1, #3
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 10;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 6);
-
-	PrepareOp(0xe2e10010);	// rsc r0, r1, #16
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 6;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 9);
-
-	PrepareOp(0xe3500010);	// cmp r0, #16
-	ResetNZCV();
-	arm_Reg[0].I = 16;
-	RunOp();
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);
-
-	PrepareOp(0xe3700001);	// cmn r0, #1
-	ResetNZCV();
-	arm_Reg[0].I = 0xffffffff;
-	RunOp();
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);
-
-	PrepareOp(0xe2010001);	// and r0, r1, #1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 3;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0xe3810001);	// orr r0, r1, #1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 3);
-
-	PrepareOp(0xe2210001);	// eor r0, r1, #1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 3;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 2);
-
-	PrepareOp(0xe3c10001);	// bic r0, r1, #1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 3;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 2);
-
-	PrepareOp(0xe3100001);	// tst r0, #1
-	ResetNZCV();
-	arm_Reg[0].I = 2;
-	RunOp();
-	ASSERT_NZCV_EQ(Z_FLAG);
-	ResetNZCV();
-	arm_Reg[0].I = 1;
-	RunOp();
-	ASSERT_NZCV_EQ(0);
-
-	PrepareOp(0xe3300001);	// teq r0, #1
-	ResetNZCV();
-	arm_Reg[0].I = 1;
-	RunOp();
-	ASSERT_NZCV_EQ(Z_FLAG);
-	ResetNZCV();
-	arm_Reg[0].I = 2;
-	RunOp();
-	ASSERT_NZCV_EQ(0);
-
-	PrepareOp(0xe2522001);	// subs r2, #1
-	ResetNZCV();
-	arm_Reg[2].I = 1;
-	RunOp();
-	ASSERT_NZCV_EQ(Z_FLAG | C_FLAG);
-	ResetNZCV();
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_NZCV_EQ(C_FLAG);
-	ResetNZCV();
-	arm_Reg[2].I = 0;
-	RunOp();
-	ASSERT_NZCV_EQ(N_FLAG);
-}
-
-TEST_F(AicaArmTest, Operand2ShiftImmTest)
-{
-	PrepareOp(0xe0810202);	// add r0, r1, r2, LSL #4
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x21);
-
-	PrepareOp(0xe0810142); // add r0, r1, r2, ASR #2
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = -8;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, -1);
-
-	PrepareOp(0xe08100a2); // add r0, r1, r2, LSR #1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x80000000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x40000001);
-
-	PrepareOp(0xe0810862); // add r0, r1, r2, ROR #16
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x56771234;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x12345678);
-
-	PrepareOp(0xe0810062);	// add r0, r1, r2, RRX
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x22222221;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x11111111);
-	ASSERT_NZCV_EQ(0);	//
-
-	PrepareOp(0xe1910062);	// orrs r0, r1, r2, RRX
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;	// set C
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x22222221;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x91111111);
-	ASSERT_NZCV_EQ(N_FLAG | C_FLAG); // N,C
-
-	// When an Operand2 constant is used with the instructions MOVS, MVNS, ANDS, ORRS, ORNS, EORS, BICS, TEQ or TST, the carry flag is updated to bit[31] of the constant,
-	// if the constant is greater than 255 and can be produced by shifting an 8-bit value.
-	PrepareOp(0xe3b00102);	// movs r0, #0x80000000
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x80000000);
-	ASSERT_NZCV_EQ(N_FLAG | C_FLAG); // N,C
-
-	PrepareOp(0xe3f00000);	// mvns r0, #0
-	arm_Reg[RN_PSR_FLAGS].I &= ~NZCV_MASK;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xffffffff);
-	ASSERT_NZCV_EQ(N_FLAG); // N
-}
-
-TEST_F(AicaArmTest, Operand2RegShiftTest)
-{
-	PrepareOp(0xe1810312);	// orr r0, r1, r2, LSL r3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x10;
-	arm_Reg[3].I = 8;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x1001);
-
-	PrepareOp(0xe1810352);	// orr r0, r1, r2, ASR r3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x80000000;
-	arm_Reg[3].I = 30;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xffffffff);
-
-	PrepareOp(0xe1810332);	// orr r0, r1, r2, LSR r3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x80000000;
-	arm_Reg[3].I = 30;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 3);
-
-	PrepareOp(0xe1810372);	// orr r0, r1, r2, ROR r3
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x43208765;
-	arm_Reg[3].I = 16;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x87654321);
-
-	PrepareOp(0xe1b0431f);	// movs r4, r15, lsl r3
-	ResetNZCV();
-	arm_Reg[3].I = 0;
-	arm_Reg[4].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[4].I, 0x1000 + 12);
-	ASSERT_NZCV_EQ(0);
-
-	PrepareOp(0xe1b0400f);	// movs r4, r15, lsl #0
-	ResetNZCV();
-	arm_Reg[3].I = 0;
-	arm_Reg[4].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[4].I, 0x1000 + 8);
-	ASSERT_NZCV_EQ(0);
-}
-
-TEST_F(AicaArmTest, CarryTest)
-{
-	PrepareOp(0xe1910022); // orrs r0, r1, r2, LSR #32
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x80000000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ASSERT_NZCV_EQ(C_FLAG); // C
-
-	PrepareOp(0xe1910822); // orrs r0, r1, r2, LSR #16
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x80008000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x8001);
-	ASSERT_NZCV_EQ(C_FLAG); // C
-
-	PrepareOp(0xe1910042); // orrs r0, r1, r2, ASR #32
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x80000000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xffffffff);
-	ASSERT_NZCV_EQ(N_FLAG | C_FLAG); // N,C
-
-	PrepareOp(0xe1910842); // orrs r0, r1, r2, ASR #16
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x00008000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ASSERT_NZCV_EQ(C_FLAG); // C
-	arm_Reg[RN_PSR_FLAGS].I &= ~NZCV_MASK;
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x00004000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ASSERT_NZCV_EQ(0); //
-
-	PrepareOp(0xe1910802); // orrs r0, r1, r2, LSL #16
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	arm_Reg[2].I = 0x00010001;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x10001);
-	ASSERT_NZCV_EQ(C_FLAG); // C
-}
-
-TEST_F(AicaArmTest, MemoryTest)
-{
-	PrepareOp(0xe5910004); // ldr r0, [r1, #4]
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x10000;
-	*(u32*)&aica_ram[0x10004] = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-
-	PrepareOp(0xe5010008); // str r0, [r1, #-8]
-	arm_Reg[0].I = 0xbaadcafe;
-	arm_Reg[1].I = 0x10008;
-	*(u32*)&aica_ram[0x10000] = 0;
-	RunOp();
-	ASSERT_EQ(*(u32*)&aica_ram[0x10000], 0xbaadcafe);
-
-	PrepareOp(0xe5b10004);	// ldr r0, [r1, #4]!
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x10000;
-	*(u32*)&aica_ram[0x10004] = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-	ASSERT_EQ(arm_Reg[1].I, 0x10004);
-
-	PrepareOp(0xe4110004);	// ldr r0, [r1], #-4
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 0x10004;
-	*(u32*)&aica_ram[0x10004] = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-	ASSERT_EQ(arm_Reg[1].I, 0x10000);
-
-	PrepareOp(0xe4900004);	// ldr r0, [r0], #4
-	arm_Reg[0].I = 0x10004;
-	*(u32*)&aica_ram[0x10004] = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-
-	PrepareOp(0xe5b00004);	// ldr r0, [r0, #4]!
-	arm_Reg[0].I = 0x10000;
-	*(u32*)&aica_ram[0x10000] = 0xbaadcafe;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0xbaadcafe);
-
-	PrepareOp(0xe51f0004);	// ldr r0, [r15, #-4]
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-
-	PrepareOp(0xe79000a4);	// ldr r0, [r0, r4, LSR #1]
-	arm_Reg[0].I = 0x1003;
-	arm_Reg[4].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-
-	PrepareOp(0xe7900084);	// ldr r0, [r0, r4, LSL #1]
-	arm_Reg[0].I = 0x1002;
-	arm_Reg[4].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-
-	PrepareOp(0xe7900024);	// ldr r0, [r0, r4, LSR #32]
-	arm_Reg[0].I = 0x1004;
-	arm_Reg[4].I = 0x12345678;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[4].I, 0x12345678);
-
-	PrepareOp(0xe7900044);	// ldr r0, [r0, r4, ASR #32]
-	arm_Reg[0].I = 0x1005;
-	arm_Reg[4].I = 0x80000000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[4].I, 0x80000000);
-
-	PrepareOp(0xe7920002);	// ldr r0,[r2,r2]
-	arm_Reg[0].I = 5;
-	arm_Reg[2].I = 0x1004 / 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[2].I, 0x1004 / 2);
-
-	PrepareOp(0xe7920063);	// ldr r0,[r2,r3, rrx]
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;	// set C
-	arm_Reg[0].I = 5;
-	arm_Reg[2].I = 0x1006;
-	arm_Reg[3].I = -4;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[2].I, 0x1006);
-	ASSERT_EQ(arm_Reg[3].I, -4);
-
-	// unaligned read
-	PrepareOp(0xe7900002);	// ldr r0,[r0,r2]
-	arm_Reg[0].I = 0x1004;
-	arm_Reg[2].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, (*(u32*)&aica_ram[0x1004]) >> 16 | (*(u32*)&aica_ram[0x1004]) << 16);
-	ASSERT_EQ(arm_Reg[2].I, 2);
-
-	PrepareOp(0xe69000a4);	// ldr r0,[r0],r4, lsr #1
-	arm_Reg[0].I = 0x1004;
-	arm_Reg[4].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[4].I, 2);
-
-	PrepareOp(0xe6920104);	// ldr r0,[r2],r4, lsl #2
-	arm_Reg[0].I = 0;
-	arm_Reg[2].I = 0x1004;
-	arm_Reg[4].I = 2;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[2].I, 0x1004 + 8);
-	ASSERT_EQ(arm_Reg[4].I, 2);
-
-	PrepareOp(0xe6920000);	// ldr r0,[r2],r0
-	arm_Reg[0].I = 123;
-	arm_Reg[2].I = 0x1004;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[2].I, 0x1004 + 123);
-
-	PrepareOp(0xe6920043);	// ldr r0,[r2],r3, asr #32
-	arm_Reg[0].I = 0;
-	arm_Reg[2].I = 0x1004;
-	arm_Reg[3].I = 0xc0000000;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[2].I, 0x1004 - 1);
-	ASSERT_EQ(arm_Reg[3].I, 0xc0000000);
-
-	PrepareOp(0xe6920063);	// ldr r0,[r2],r3, rrx
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;	// set C
-	arm_Reg[0].I = 5;
-	arm_Reg[2].I = 0x1004;
-	arm_Reg[3].I = 0xfffffffc;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, *(u32*)&aica_ram[0x1004]);
-	ASSERT_EQ(arm_Reg[2].I, 0x1002);
-	ASSERT_NZCV_EQ(C_FLAG); // C
-	ASSERT_EQ(arm_Reg[3].I, 0xfffffffc);
-
-	// unaligned read
-	PrepareOp(0xe6900002);	// ldr r0,[r0],r2
-	arm_Reg[0].I = 0x1006;
-	arm_Reg[2].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, (*(u32*)&aica_ram[0x1004]) >> 16 | (*(u32*)&aica_ram[0x1004]) << 16);
-	ASSERT_EQ(arm_Reg[2].I, 1);
-}
-
-TEST_F(AicaArmTest, PcRelativeTest)
-{
-	PrepareOp(0xe38f0010);	// orr r0, r15, #16
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x1008 + 16);
-
-	PrepareOp(0xe180011f); // orr r0, r15, LSL r1
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0x100C << 1);
-
-	PrepareOp(0xe28f5c7d); // add r5, r15, #32000
-	arm_Reg[5].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[5].I, 32000 + 0x1008);
-}
-
-TEST_F(AicaArmTest, ConditionalTest)
-{
-	PrepareOp(0x01a00001);	// moveq r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= Z_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0x11a00001);	// movne r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= Z_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-
-	PrepareOp(0x21a00001);	// movcs r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0x31a00001);	// movcc r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-
-	PrepareOp(0x41a00001);	// movmi r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0x51a00001);	// movpl r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-
-	PrepareOp(0x61a00001);	// movvs r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= V_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0x71a00001);	// movvc r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= V_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-
-	PrepareOp(0x81a00001);	// movhi r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= Z_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-
-	PrepareOp(0x91a00001);	// movls r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= C_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I = Z_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0xa1a00001);	// movge r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= V_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0xb1a00001);	// movlt r0, r1
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[RN_PSR_FLAGS].I |= V_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-
-	PrepareOp(0xc1a00001);	// movgt r0, r1
-	// Z==0 && N==V
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= Z_FLAG;
-	arm_Reg[0].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= V_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-
-	PrepareOp(0xd1a00001);	// movle r0, r1
-	// Z==1 || N!=V
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[1].I = 1;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-	arm_Reg[RN_PSR_FLAGS].I |= Z_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ResetNZCV();
-	arm_Reg[0].I = 0;
-	arm_Reg[RN_PSR_FLAGS].I |= V_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	arm_Reg[0].I = 0;
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	RunOp();
-	ASSERT_EQ(arm_Reg[0].I, 0);
-}
-
-TEST_F(AicaArmTest, JumpTest)
-{
-	PrepareOp(0xea00003e);	// b +248
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x1100);
-
-	PrepareOp(0xeb00003e);	// bl +248
-	arm_Reg[14].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x1100);
-	ASSERT_EQ(arm_Reg[14].I, 0x1004);
-
-	PrepareOp(0xe1a0f000);	// mov pc, r0
-	arm_Reg[0].I = 0x100;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x100);
-
-	PrepareOp(0xc1a0f000);	// movgt pc, r0
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= N_FLAG;
-	arm_Reg[0].I = 0x100;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x1004);
-	ResetNZCV();
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x100);
-
-	PrepareOp(0xe590f000); // ldr r15, [r0]
-	arm_Reg[0].I = 0x10000;
-	*(u32*)&aica_ram[0x10000] = 0xbaadcafc;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0xbaadcafc);
-
-	PrepareOp(0x1b00003e);	// blne +248
-	ResetNZCV();
-	arm_Reg[14].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x1100);
-	ASSERT_EQ(arm_Reg[14].I, 0x1004);
-	ResetNZCV();
-	arm_Reg[RN_PSR_FLAGS].I |= Z_FLAG;
-	arm_Reg[14].I = 0;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x1004);
-	ASSERT_EQ(arm_Reg[14].I, 0);
-}
-
-TEST_F(AicaArmTest, LdmStmTest)
-{
-	PrepareOp(0xe8bd8000);	// ldm sp!, {pc}
-	arm_Reg[13].I = 0x1100;
-	*(u32*)&aica_ram[0x1100] = 0x1234;
-	RunOp();
-	ASSERT_EQ(arm_Reg[R15_ARM_NEXT].I, 0x1234);
-
-	PrepareOp(0xe92d8000);	// stmdb sp!, {pc}
-	arm_Reg[13].I = 0x1104;
-	RunOp();
-	ASSERT_EQ(arm_Reg[13].I, 0x1100);
-	ASSERT_EQ(*(u32*)&aica_ram[0x1100], 0x1000 + 12);
-}
-
-TEST_F(AicaArmTest, RegAllocTest)
-{
-	u32 ops[] = {
-			0xe3a00000,	// mov r0, #0
-			0xe3a01001,	// mov r1, #1
-			0xe3a02002,	// mov r2, #2
-			0xe3a03003,	// mov r3, #3
-			0xe3a04004,	// mov r4, #4
-			0xe3a05005,	// mov r5, #5
-			0xe3a06006,	// mov r6, #6
-			0xe0800001,	// add r0, r0, r1
-			0xe0811002,	// add r1, r1, r2
-			0xe0822003,	// add r2, r2, r3
-			0xe0833004,	// add r3, r3, r4
-			0xe0844005,	// add r4, r4, r5
-			0xe0855006,	// add r5, r5, r6
-			0xe0866000,	// add r6, r6, r0
-	};
-	PrepareOps(ARRAY_SIZE(ops), ops);
-	for (int i = 0; i < 15; i++)
-		arm_Reg[i].I = 0;
-
-	RunOp();
-
-	ASSERT_EQ(arm_Reg[0].I, 1);
-	ASSERT_EQ(arm_Reg[1].I, 3);
-	ASSERT_EQ(arm_Reg[2].I, 5);
-	ASSERT_EQ(arm_Reg[3].I, 7);
-	ASSERT_EQ(arm_Reg[4].I, 9);
-	ASSERT_EQ(arm_Reg[5].I, 11);
-	ASSERT_EQ(arm_Reg[6].I, 7);
-}
-
-TEST_F(AicaArmTest, ConditionRegAllocTest)
-{
-	u32 ops1[] = {
-			0x03a0004d,	// moveq r0, #77
-			0xe1a01000	// mov r1, r0
-	};
-	PrepareOps(ARRAY_SIZE(ops1), ops1);
-	arm_Reg[0].I = 22;
-	arm_Reg[1].I = 22;
-	ResetNZCV();
-
-	RunOp();
-
-	ASSERT_EQ(arm_Reg[0].I, 22);
-	ASSERT_EQ(arm_Reg[1].I, 22);
-
-	u32 ops2[] = {
-			0x01a01000,	// moveq r1, r0
-			0xe1a02000	// mov r2, r0
-	};
-	PrepareOps(ARRAY_SIZE(ops2), ops2);
-	arm_Reg[0].I = 22;
-	arm_Reg[1].I = 0;
-	arm_Reg[2].I = 0;
-	ResetNZCV();
-
-	RunOp();
-
-	ASSERT_EQ(arm_Reg[0].I, 22);
-	ASSERT_EQ(arm_Reg[1].I, 0);
-	ASSERT_EQ(arm_Reg[2].I, 22);
-}
-}
diff --git a/tests/src/serialize_test.cpp b/tests/src/serialize_test.cpp
index ce6cb6d..0d57778 100644
--- a/tests/src/serialize_test.cpp
+++ b/tests/src/serialize_test.cpp
@@ -31,7 +31,7 @@ TEST_F(SerializeTest, SizeTest)
 	unsigned int total_size = 0;
 	void *data = nullptr;
 	ASSERT_TRUE(dc_serialize(&data, &total_size));
-	ASSERT_EQ(28145499u, total_size);
+	ASSERT_EQ(28145495u, total_size);
 }
 
 
diff --git a/tests/src/test_stubs.cpp b/tests/src/test_stubs.cpp
index 0f9243d..2894afe 100644
--- a/tests/src/test_stubs.cpp
+++ b/tests/src/test_stubs.cpp
@@ -2,7 +2,6 @@
 #include <unistd.h>
 #include "types.h"
 
-#ifndef __ANDROID__
 void os_DebugBreak()
 {
 #ifdef __linux__
@@ -32,7 +31,6 @@ void os_DoEvents()
 void os_CreateWindow()
 {
 }
-#endif
 
 #ifdef _WIN32
 #include <windows.h>
-- 
2.29.2

